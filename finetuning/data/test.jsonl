{"question":"Provide the documentation for the function according to task description.","answer":"Calculate the arithmetic mean of a list of numbers.\n\nArgs:\n    numbers: A list of numeric values to average\n\nReturns:\n    The arithmetic mean as a float\n\nRaises:\n    ValueError: If the input list is empty","context":"def calculate_average(numbers: list[float]) -> float:\n    if not numbers:\n        raise ValueError(\"Cannot calculate average of empty list\")\n    return sum(numbers) \/ len(numbers)"}
{"question":"Provide the documentation for the function according to task description.","answer":"Calculate the factorial of a non-negative integer.\n\nArgs:\n    n: The non-negative integer to calculate factorial for\n\nReturns:\n    The factorial of n\n\nRaises:\n    ValueError: If n is negative","context":"def calculate_factorial(n: int) -> int:\n    if n < 0:\n        raise ValueError(\"Factorial is not defined for negative numbers\")\n    if n == 0 or n == 1:\n        return 1\n    result = 1\n    for i in range(2, n + 1):\n        result *= i\n    return result"}
{"question":"Provide the documentation for the function according to task description.","answer":"Get the current UTC timestamp in milliseconds.\n\nReturns:\n    The current timestamp as an integer in milliseconds since epoch","context":"from datetime import datetime, timezone\n\ndef get_timestamp_milliseconds() -> int:\n    return int(datetime.now(timezone.utc).timestamp() * 1000)"}
{"question":"Provide the documentation for the function according to task description.","answer":"Calculate the percentage change between two values.\n\nArgs:\n    old_value: The original value\n    new_value: The new value\n\nReturns:\n    The percentage change as a float\n\nRaises:\n    ValueError: If old_value is zero","context":"def calculate_percentage_change(old_value: float, new_value: float) -> float:\n    if old_value == 0:\n        raise ValueError(\"Cannot calculate percentage change from zero\")\n    return ((new_value - old_value) \/ old_value) * 100"}
{"question":"Provide the documentation for the function according to task description.","answer":"Convert a snake_case string to camelCase.\n\nArgs:\n    snake_str: A string in snake_case format\n\nReturns:\n    The string converted to camelCase","context":"def convert_snake_to_camel(snake_str: str) -> str:\n    components = snake_str.split('_')\n    return components[0] + ''.join(x.title() for x in components[1:])"}
{"question":"Provide the documentation for the function according to task description.","answer":"A thread-safe cache implementation.\n\nThis class provides a simple thread-safe dictionary-like cache with get and set methods.\nAll operations are protected by a lock to ensure thread safety.","context":"import threading\nfrom typing import Any\n\nclass ThreadSafeCache:\n    def __init__(self):\n        self._cache = {}\n        self._lock = threading.Lock()\n    \n    def get(self, key: str, default: Any = None) -> Any:\n        with self._lock:\n            return self._cache.get(key, default)\n    \n    def set(self, key: str, value: Any) -> None:\n        with self._lock:\n            self._cache[key] = value"}
{"question":"Provide the documentation for the function according to task description.","answer":"Apply a discount function to a price with validation.\n\nArgs:\n    price: The original price\n    discount_func: A function that takes a price and returns the discounted price\n\nReturns:\n    The discounted price\n\nRaises:\n    ValueError: If the price is negative or if discount results in negative price","context":"from typing import Callable\n\ndef apply_discount(price: float, discount_func: Callable[[float], float]) -> float:\n    if price < 0:\n        raise ValueError(\"Price cannot be negative\")\n    discounted = discount_func(price)\n    if discounted < 0:\n        raise ValueError(\"Discount cannot result in negative price\")\n    return discounted"}
{"question":"Provide the documentation for the function according to task description.","answer":"Process items in batches using a provided function.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch\n    processor_func: Function that processes a batch and returns results\n\nReturns:\n    A list of all processed results\n\nRaises:\n    ValueError: If batch_size is not positive","context":"def batch_process(items: list, batch_size: int, processor_func: Callable) -> list:\n    if batch_size <= 0:\n        raise ValueError(\"Batch size must be positive\")\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i + batch_size]\n        results.extend(processor_func(batch))\n    return results"}
{"question":"Provide the documentation for the function according to task description.","answer":"Calculate the sample standard deviation of a list of numbers.\n\nArgs:\n    numbers: A list of numeric values\n\nReturns:\n    The sample standard deviation as a float\n\nRaises:\n    ValueError: If the list contains fewer than 2 numbers","context":"def calculate_standard_deviation(numbers: list[float]) -> float:\n    if len(numbers) < 2:\n        raise ValueError(\"Need at least 2 numbers to calculate standard deviation\")\n    mean = sum(numbers) \/ len(numbers)\n    variance = sum((x - mean) ** 2 for x in numbers) \/ (len(numbers) - 1)\n    return variance ** 0.5"}
{"question":"Provide the documentation for the function according to task description.","answer":"Normalize a string with various options.\n\nArgs:\n    text: The input string to normalize\n    lowercase: Convert to lowercase if True. Defaults to True\n    remove_special: Remove special characters if True. Defaults to False\n\nReturns:\n    The normalized string","context":"def normalize_string(text: str, lowercase: bool = True, remove_special: bool = False) -> str:\n    import re\n    result = text.strip()\n    if lowercase:\n        result = result.lower()\n    if remove_special:\n        result = re.sub(r'[^a-zA-Z0-9\\s]', '', result)\n    return result"}
{"question":"Provide the documentation for the function according to task description.","answer":"Create a dictionary by zipping two lists together.\n\nArgs:\n    keys: List of keys\n    values: List of values\n\nReturns:\n    A dictionary mapping keys to values\n\nRaises:\n    ValueError: If the lists have different lengths","context":"def zip_lists_to_dict(keys: list[str], values: list[any]) -> dict[str, any]:\n    if len(keys) != len(values):\n        raise ValueError(\"Keys and values must have the same length\")\n    return dict(zip(keys, values))"}
{"question":"Provide the documentation for the function according to task description.","answer":"Read and parse a JSON file.\n\nArgs:\n    filepath: Path to the JSON file to read\n\nReturns:\n    A dictionary containing the parsed JSON data\n\nRaises:\n    FileNotFoundError: If the specified file does not exist\n    ValueError: If the file contains invalid JSON","context":"import json\n\ndef read_json_file(filepath: str) -> dict:\n    try:\n        with open(filepath, 'r', encoding='utf-8') as f:\n            return json.load(f)\n    except FileNotFoundError:\n        raise FileNotFoundError(f\"File not found: {filepath}\")\n    except json.JSONDecodeError as e:\n        raise ValueError(f\"Invalid JSON in file: {e}\")"}
{"question":"Provide the documentation for the function according to task description.","answer":"Parse an XML string into an ElementTree element.\n\nArgs:\n    xml_string: The XML string to parse\n\nReturns:\n    The root Element of the parsed XML tree\n\nRaises:\n    ValueError: If the XML string is malformed","context":"import xml.etree.ElementTree as ET\n\ndef parse_xml_string(xml_string: str) -> ET.Element:\n    try:\n        return ET.fromstring(xml_string)\n    except ET.ParseError as e:\n        raise ValueError(f\"Invalid XML: {e}\")"}
{"question":"Provide the documentation for the function according to task description.","answer":"Truncate a string to a maximum length with optional suffix.\n\nArgs:\n    text: The string to truncate\n    max_length: The maximum allowed length\n    suffix: String to append when truncating. Defaults to '...'\n\nReturns:\n    The original string if under max_length, otherwise truncated with suffix","context":"def truncate_string(text: str, max_length: int, suffix: str = '...') -> str:\n    if len(text) <= max_length:\n        return text\n    return text[:max_length - len(suffix)] + suffix"}
{"question":"Provide the documentation for the function according to task description.","answer":"Count the frequency of each word in a text string.\n\nArgs:\n    text: The input text to analyze\n\nReturns:\n    A dictionary mapping each word to its occurrence count","context":"def count_word_frequency(text: str) -> dict[str, int]:\n    words = text.lower().split()\n    frequency = {}\n    for word in words:\n        word = word.strip('.,!?;:')\n        if word:\n            frequency[word] = frequency.get(word, 0) + 1\n    return frequency"}
{"question":"Provide the documentation for the function according to task description.","answer":"Remove duplicate items from a list.\n\nArgs:\n    items: The list to remove duplicates from\n    preserve_order: If True, maintain original order. If False, order is not guaranteed. Defaults to True\n\nReturns:\n    A new list with duplicates removed","context":"def remove_duplicates(items: list, preserve_order: bool = True) -> list:\n    if preserve_order:\n        seen = set()\n        result = []\n        for item in items:\n            if item not in seen:\n                seen.add(item)\n                result.append(item)\n        return result\n    return list(set(items))"}
{"question":"Provide the documentation for the function according to task description.","answer":"Add business days to a given date, excluding weekends.\n\nArgs:\n    start_date: The starting date\n    days: Number of business days to add\n\nReturns:\n    A new datetime object with the specified business days added","context":"from datetime import datetime, timedelta\n\ndef add_business_days(start_date: datetime, days: int) -> datetime:\n    current = start_date\n    days_added = 0\n    while days_added < days:\n        current += timedelta(days=1)\n        if current.weekday() < 5:\n            days_added += 1\n    return current"}
{"question":"Provide the documentation for the function according to task description.","answer":"Validate an email address format.\n\nArgs:\n    email: The email address string to validate\n\nReturns:\n    True if the email format is valid, False otherwise","context":"def validate_email(email: str) -> bool:\n    import re\n    pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'\n    return re.match(pattern, email) is not None"}
{"question":"Provide the documentation for the function according to task description.","answer":"Encode a string to Base64.\n\nArgs:\n    data: The string to encode\n\nReturns:\n    The Base64-encoded string","context":"import base64\n\ndef encode_base64(data: str) -> str:\n    return base64.b64encode(data.encode('utf-8')).decode('ascii')"}
{"question":"Provide the documentation for the function according to task description.","answer":"Parse a date string into a datetime object.\n\nArgs:\n    date_str: The date string to parse\n    format_str: The expected date format. Defaults to '%Y-%m-%d'\n\nReturns:\n    A datetime object representing the parsed date\n\nRaises:\n    ValueError: If the date string doesn't match the expected format","context":"from datetime import datetime\n\ndef parse_date_string(date_str: str, format_str: str = '%Y-%m-%d') -> datetime:\n    try:\n        return datetime.strptime(date_str, format_str)\n    except ValueError as e:\n        raise ValueError(f\"Invalid date format: {e}\")"}
{"question":"Provide the documentation for the function according to task description.","answer":"Set up a logger with file output.\n\nArgs:\n    name: Name of the logger\n    log_file: Path to the log file\n    level: Logging level. Defaults to logging.INFO\n\nReturns:\n    Configured logger instance","context":"import logging\n\ndef setup_logger(name: str, log_file: str, level: int = logging.INFO) -> logging.Logger:\n    logger = logging.getLogger(name)\n    logger.setLevel(level)\n    handler = logging.FileHandler(log_file)\n    handler.setFormatter(logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))\n    logger.addHandler(handler)\n    return logger"}
{"question":"Provide the documentation for the function according to task description.","answer":"Create a decorator that measures and prints function execution time.\n\nArgs:\n    func: The function to measure\n\nReturns:\n    A wrapped function that prints execution time before returning results","context":"import time\nfrom functools import wraps\n\ndef measure_execution_time(func: Callable) -> Callable:\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        start_time = time.time()\n        result = func(*args, **kwargs)\n        end_time = time.time()\n        print(f\"{func.__name__} took {end_time - start_time:.4f} seconds\")\n        return result\n    return wrapper"}
{"question":"Provide the documentation for the function according to task description.","answer":"Sanitize a filename by removing invalid characters.\n\nArgs:\n    filename: The filename to sanitize\n    max_length: Maximum allowed filename length. Defaults to 255\n\nReturns:\n    A sanitized filename safe for most file systems","context":"def sanitize_filename(filename: str, max_length: int = 255) -> str:\n    import re\n    sanitized = re.sub(r'[<>:\"\/\\\\|?*]', '_', filename)\n    sanitized = sanitized.strip('. ')\n    if len(sanitized) > max_length:\n        name, ext = os.path.splitext(sanitized)\n        sanitized = name[:max_length - len(ext)] + ext\n    return sanitized if sanitized else 'unnamed'"}
{"question":"Provide the documentation for the function according to task description.","answer":"Validate an IP address string and determine its version.\n\nArgs:\n    ip_string: The IP address string to validate\n\nReturns:\n    \"IPv4\" or \"IPv6\" if valid, None if invalid","context":"from typing import Union\nimport ipaddress\n\ndef validate_ip_address(ip_string: str) -> Union[str, None]:\n    try:\n        ip = ipaddress.ip_address(ip_string)\n        return \"IPv4\" if ip.version == 4 else \"IPv6\"\n    except ValueError:\n        return None"}
{"question":"Provide the documentation for the function according to task description.","answer":"Flatten a nested list structure into a single list.\n\nArgs:\n    nested_list: A list that may contain nested lists\n\nReturns:\n    A flat list containing all elements from the nested structure","context":"def flatten_nested_list(nested_list: list) -> list:\n    result = []\n    for item in nested_list:\n        if isinstance(item, list):\n            result.extend(flatten_nested_list(item))\n        else:\n            result.append(item)\n    return result"}
{"question":"Provide the documentation for the function according to task description.","answer":"Split a list into smaller chunks of specified size.\n\nArgs:\n    data: The list to split into chunks\n    chunk_size: The maximum size of each chunk\n\nReturns:\n    A list of lists, where each inner list is a chunk\n\nRaises:\n    ValueError: If chunk_size is not positive","context":"def chunk_list(data: list, chunk_size: int) -> list[list]:\n    if chunk_size <= 0:\n        raise ValueError(\"Chunk size must be positive\")\n    return [data[i:i + chunk_size] for i in range(0, len(data), chunk_size)]"}
{"question":"Provide the documentation for the function according to task description.","answer":"Hash a password using SHA-256.\n\nArgs:\n    password: The password to hash\n    salt: Optional salt to add to the password. Defaults to empty string\n\nReturns:\n    The hexadecimal hash string","context":"import hashlib\n\ndef hash_password(password: str, salt: str = '') -> str:\n    salted = password + salt\n    return hashlib.sha256(salted.encode()).hexdigest()"}
{"question":"Provide the documentation for the function according to task description.","answer":"Format a numeric amount as a currency string.\n\nArgs:\n    amount: The numeric amount to format\n    currency_symbol: The currency symbol to use. Defaults to '$'\n    decimal_places: Number of decimal places to display. Defaults to 2\n\nReturns:\n    A formatted currency string with thousands separators","context":"def format_currency(amount: float, currency_symbol: str = '$', decimal_places: int = 2) -> str:\n    return f\"{currency_symbol}{amount:,.{decimal_places}f}\""}
{"question":"Provide the documentation for the function according to task description.","answer":"Calculate the weighted average of values.\n\nArgs:\n    values: List of numeric values\n    weights: List of weights corresponding to each value\n\nReturns:\n    The weighted average as a float\n\nRaises:\n    ValueError: If lists have different lengths, are empty, or weights sum to zero","context":"def weighted_average(values: list[float], weights: list[float]) -> float:\n    if len(values) != len(weights):\n        raise ValueError(\"Values and weights must have the same length\")\n    if not values:\n        raise ValueError(\"Cannot calculate weighted average of empty list\")\n    total_weight = sum(weights)\n    if total_weight == 0:\n        raise ValueError(\"Sum of weights cannot be zero\")\n    return sum(v * w for v, w in zip(values, weights)) \/ total_weight"}
{"question":"Provide the documentation for the function according to task description.","answer":"Fetch data from a REST API endpoint.\n\nArgs:\n    url: The API endpoint URL to request\n    headers: Optional dictionary of HTTP headers to include\n    timeout: Maximum time to wait for response in seconds (default: 10)\n\nReturns:\n    Dictionary containing parsed JSON response data\n\nRaises:\n    ConnectionError: If the API request fails or returns non-200 status\n\nExample:\n    >>> data = fetch_api_data(\"https:\/\/api.example.com\/data\", {\"Authorization\": \"Bearer token\"})\n    >>> print(data[\"results\"])","context":"import requests\nfrom typing import Dict, Any, Optional\nfrom requests.exceptions import RequestException\n\ndef fetch_api_data(url: str, headers: Optional[Dict[str, str]] = None, timeout: int = 10) -> Dict[str, Any]:\n    try:\n        response = requests.get(url, headers=headers, timeout=timeout)\n        response.raise_for_status()\n        return response.json()\n    except RequestException as e:\n        raise ConnectionError(f\"API request failed: {e}\")"}
{"question":"Provide the documentation for the function according to task description.","answer":"Read JSON configuration from a file, with fallback to default settings.\n\nArgs:\n    file_path: Path to the JSON configuration file\n    default_settings: Optional default settings to return if file not found\n\nReturns:\n    Dictionary containing the parsed JSON configuration\n\nRaises:\n    ValueError: If the JSON file contains invalid JSON syntax\n    FileNotFoundError: If the file doesn't exist and no default settings provided\n\nExample:\n    >>> config = read_json_config('config.json', {'timeout': 30})\n    >>> print(config['timeout'])\n    30","context":"from typing import Optional\nimport json\n\ndef read_json_config(file_path: str, default_settings: Optional[dict] = None) -> dict:\n    try:\n        with open(file_path, 'r') as f:\n            config = json.load(f)\n    except FileNotFoundError:\n        if default_settings is None:\n            raise\n        return default_settings.copy()\n    except json.JSONDecodeError as e:\n        raise ValueError(f\"Invalid JSON in {file_path}: {e}\")\n    return config"}
{"question":"Provide the documentation for the function according to task description.","answer":"Extract email addresses from text with optional domain filtering.\n\nArgs:\n    text: Input text to search for email addresses\n    domain_filter: Optional domain suffix to filter results. If provided, only returns emails ending with this domain\n\nReturns:\n    List of extracted email addresses, filtered by domain if specified","context":"import re\nfrom typing import Optional\n\ndef extract_email_addresses(text: str, domain_filter: Optional[str] = None) -> list[str]:\n    email_pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n    emails = re.findall(email_pattern, text)\n    \n    if domain_filter:\n        filtered_emails = []\n        for email in emails:\n            if email.lower().endswith(domain_filter.lower()):\n                filtered_emails.append(email)\n        return filtered_emails\n    \n    return emails"}
{"question":"Provide the documentation for the function according to task description.","answer":"Filter a list of dictionaries to keep only specified keys in each dictionary.\n\nArgs:\n    data: List of dictionaries to filter\n    keys_to_keep: List of keys to preserve in each dictionary\n\nReturns:\n    A new list of dictionaries containing only the specified keys\n\nExample:\n    >>> data = [{'a': 1, 'b': 2, 'c': 3}, {'a': 4, 'd': 5}]\n    >>> filter_dict_list_by_keys(data, ['a', 'b'])\n    [{'a': 1, 'b': 2}, {'a': 4}]","context":"import json\nfrom typing import List, Dict, Any\n\ndef filter_dict_list_by_keys(data: List[Dict[str, Any]], keys_to_keep: List[str]) -> List[Dict[str, Any]]:\n    return [{key: item[key] for key in keys_to_keep if key in item} for item in data]"}
{"question":"Provide the documentation for the function according to task description.","answer":"Merge two dictionaries, updating the base dictionary with values from update dictionary.\n\nArgs:\n    base_dict: The base dictionary to merge into\n    update_dict: The dictionary containing updates\n    overwrite: Whether to overwrite existing keys in base_dict (default: True)\n\nReturns:\n    A new dictionary containing the merged key-value pairs","context":"def merge_dictionaries(base_dict: dict, update_dict: dict, overwrite: bool = True) -> dict:\n    result = base_dict.copy()\n    for key, value in update_dict.items():\n        if key not in result or overwrite:\n            result[key] = value\n    return result"}
{"question":"Provide the documentation for the function according to task description.","answer":"Calculate a future date by adding time components to a starting datetime.\n\nArgs:\n    start_date: Starting datetime object\n    days: Number of days to add. Defaults to 0\n    hours: Number of hours to add. Defaults to 0\n    minutes: Number of minutes to add. Defaults to 0\n\nReturns:\n    A new datetime object representing the future date\n\nRaises:\n    ValueError: If start_date is not a datetime object\n\nExample:\n    >>> from datetime import datetime\n    >>> start = datetime(2023, 1, 1, 12, 0)\n    >>> calculate_future_date(start, days=5, hours=3)\n    datetime(2023, 1, 6, 15, 0)","context":"from datetime import datetime, timedelta\nfrom typing import Optional\n\ndef calculate_future_date(start_date: datetime, days: int = 0, hours: int = 0, minutes: int = 0) -> datetime:\n    if not isinstance(start_date, datetime):\n        raise ValueError(\"start_date must be a datetime object\")\n    delta = timedelta(days=days, hours=hours, minutes=minutes)\n    return start_date + delta"}
{"question":"Provide the documentation for the function according to task description.","answer":"Create a decorator that retries a function on specified exceptions.\n\nArgs:\n    max_retries: Maximum number of retry attempts. Defaults to 3\n    delay: Base delay time in seconds between retries. Defaults to 1.0\n    exceptions: Tuple of exception types to catch and retry. Defaults to (Exception,)\n\nReturns:\n    A decorator function that wraps the target function with retry logic\n\nRaises:\n    Exception: The last caught exception if all retry attempts fail\n\nExample:\n    >>> @retry_on_exception(max_retries=3, delay=0.5, exceptions=(ConnectionError,))\n    >>> def unreliable_connection():\n    >>>     # function that might raise ConnectionError\n    >>>     pass","context":"from typing import Callable, Any\nimport time\n\ndef retry_on_exception(max_retries: int = 3, delay: float = 1.0, exceptions: tuple = (Exception,)) -> Callable:\n    def decorator(func: Callable) -> Callable:\n        def wrapper(*args: Any, **kwargs: Any) -> Any:\n            for attempt in range(max_retries):\n                try:\n                    return func(*args, **kwargs)\n                except exceptions as e:\n                    if attempt == max_retries - 1:\n                        raise e\n                    time.sleep(delay * (2 ** attempt))\n            return None\n        return wrapper\n    return decorator"}
{"question":"Provide the documentation for the function according to task description.","answer":"Load a JSON configuration file and validate required keys.\n\nArgs:\n    file_path: Path to the JSON configuration file\n    required_keys: List of keys that must be present in the configuration\n\nReturns:\n    Parsed configuration data as a dictionary, or None if loading fails\n\nRaises:\n    FileNotFoundError: If the configuration file does not exist\n    ValueError: If the file contains invalid JSON format\n    KeyError: If any required key is missing from the configuration\n\nExample:\n    >>> config = load_json_config('config.json', ['api_key', 'endpoint'])\n    >>> print(config['api_key'])","context":"from typing import List, Optional\nimport json\n\ndef load_json_config(file_path: str, required_keys: List[str]) -> Optional[dict]:\n    try:\n        with open(file_path, 'r') as config_file:\n            config_data = json.load(config_file)\n            for key in required_keys:\n                if key not in config_data:\n                    raise KeyError(f\"Missing required configuration key: {key}\")\n            return config_data\n    except FileNotFoundError:\n        raise FileNotFoundError(f\"Configuration file not found: {file_path}\")\n    except json.JSONDecodeError:\n        raise ValueError(f\"Invalid JSON format in file: {file_path}\")"}
{"question":"Provide the documentation for the function according to task description.","answer":"Make an HTTP GET request and return the JSON response.\n\nArgs:\n    url: The URL to make the request to\n    timeout: Maximum time to wait for the response in seconds (default: 30)\n\nReturns:\n    Dictionary containing the JSON response data\n\nRaises:\n    TimeoutError: If the request times out\n    ConnectionError: If the HTTP request fails for any reason\n\nExample:\n    >>> data = make_http_get_request(\"https:\/\/api.example.com\/data\")\n    >>> print(data[\"results\"])","context":"import requests\n\ndef make_http_get_request(url: str, timeout: int = 30) -> dict[str, any]:\n    try:\n        response = requests.get(url, timeout=timeout)\n        response.raise_for_status()\n        return response.json()\n    except requests.exceptions.Timeout:\n        raise TimeoutError(\"Request timed out\")\n    except requests.exceptions.RequestException as e:\n        raise ConnectionError(f\"HTTP request failed: {e}\")"}
{"question":"Provide the documentation for the function according to task description.","answer":"Parse a string value to a boolean or None.\n\nArgs:\n    value: String value to parse\n\nReturns:\n    True if value matches true_values, False if matches false_values, \n    None otherwise\n\nExample:\n    >>> parse_boolean_string('yes')\n    True\n    >>> parse_boolean_string('OFF')\n    False\n    >>> parse_boolean_string('maybe')\n    None","context":"from typing import Optional\n\ndef parse_boolean_string(value: str) -> Optional[bool]:\n    true_values = ['true', 'yes', '1', 'on']\n    false_values = ['false', 'no', '0', 'off']\n    normalized = value.strip().lower()\n    if normalized in true_values:\n        return True\n    elif normalized in false_values:\n        return False\n    return None"}
{"question":"Provide the documentation for the function according to task description.","answer":"Process a list of items asynchronously in batches.\n\nArgs:\n    items: List of items to process\n    process_func: Async function to process each item\n    batch_size: Number of items to process in each batch (default: 10)\n\nReturns:\n    List of processed items in original order\n\nRaises:\n    ValueError: If batch_size is not positive","context":"from typing import List, TypeVar, Callable\nimport asyncio\n\nT = TypeVar('T')\n\nasync def async_batch_processor(items: List[T], process_func: Callable[[T], T], batch_size: int = 10) -> List[T]:\n    if batch_size <= 0:\n        raise ValueError(\"Batch size must be positive\")\n    \n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i + batch_size]\n        tasks = [process_func(item) for item in batch]\n        batch_results = await asyncio.gather(*tasks)\n        results.extend(batch_results)\n    \n    return results"}
{"question":"Provide the documentation for the function according to task description.","answer":"Filter a dictionary to only include specified keys.\n\nArgs:\n    original_dict: The source dictionary to filter\n    keys_to_keep: List of keys that should be retained in the filtered dictionary\n\nReturns:\n    A new dictionary containing only the key-value pairs where the key is in keys_to_keep","context":"from typing import List, Dict\n\ndef filter_dict_by_keys(original_dict: Dict[str, int], keys_to_keep: List[str]) -> Dict[str, int]:\n    return {key: value for key, value in original_dict.items() if key in keys_to_keep}"}
{"question":"Provide the documentation for the function according to task description.","answer":"Count the number of occurrences of a specific character in a string.\n\nArgs:\n    text: The string to search within\n    target_char: The single character to count occurrences of\n\nRaises:\n    ValueError: If target_char is not a single character\n\nReturns:\n    The number of times target_char appears in the text","context":"def count_character_occurrences(text: str, target_char: str) -> int:\n    if len(target_char) != 1:\n        raise ValueError(\"Target character must be a single character\")\n    return text.count(target_char)"}
{"question":"Provide the documentation for the function according to task description.","answer":"Process items in batches of specified size.\n\nArgs:\n    items: List of items to process in batches\n    batch_size: Number of items per batch (default: 10)\n\nYields:\n    Lists of items in sequential batches\n\nRaises:\n    ValueError: If batch_size is not positive\n\nExample:\n    >>> items = ['a', 'b', 'c', 'd', 'e']\n    >>> for batch in batch_process_items(items, 2):\n    ...     print(batch)\n    ['a', 'b']\n    ['c', 'd']\n    ['e']","context":"from typing import Generator, List\n\ndef batch_process_items(items: List[str], batch_size: int = 10) -> Generator[List[str], None, None]:\n    if batch_size <= 0:\n        raise ValueError(\"Batch size must be positive\")\n    \n    for i in range(0, len(items), batch_size):\n        yield items[i:i + batch_size]"}
{"question":"Provide the documentation for the function according to task description.","answer":"Add days to a given date string.\n\nArgs:\n    start_date: A date string in YYYY-MM-DD format\n    days: Number of days to add (can be negative to subtract)\n\nReturns:\n    A date string in YYYY-MM-DD format representing the new date","context":"from datetime import datetime, timedelta\n\ndef add_days_to_date(start_date: str, days: int) -> str:\n    date_obj = datetime.strptime(start_date, '%Y-%m-%d')\n    new_date = date_obj + timedelta(days=days)\n    return new_date.strftime('%Y-%m-%d')"}
{"question":"Provide the documentation for the function according to task description.","answer":"Merge two dictionaries into a new dictionary.\n\nArgs:\n    dict1: First dictionary to merge\n    dict2: Second dictionary to merge\n\nReturns:\n    New dictionary containing all key-value pairs from both input dictionaries,\n    with dict2 values taking precedence for duplicate keys","context":"def merge_dictionaries(dict1: dict, dict2: dict) -> dict:\n    result = dict1.copy()\n    result.update(dict2)\n    return result"}
{"question":"Provide the documentation for the function according to task description.","answer":"Parse JSON response and validate required keys.\n\nArgs:\n    response_text: JSON string to parse\n    expected_keys: List of keys that must be present in the parsed JSON object\n\nReturns:\n    Parsed JSON data as dictionary if valid, None otherwise\n\nRaises:\n    ValueError: If response is not valid JSON or not a JSON object\n    KeyError: If any expected key is missing from the parsed data\n\nExample:\n    >>> parse_json_response('{\"name\": \"John\", \"age\": 30}', [\"name\", \"age\"])\n    {'name': 'John', 'age': 30}","context":"import json\nfrom typing import Optional\n\ndef parse_json_response(response_text: str, expected_keys: list[str]) -> Optional[dict[str, any]]:\n    try:\n        data = json.loads(response_text)\n        if not isinstance(data, dict):\n            raise ValueError(\"Response is not a JSON object\")\n        for key in expected_keys:\n            if key not in data:\n                raise KeyError(f\"Missing expected key: {key}\")\n        return data\n    except json.JSONDecodeError as e:\n        raise ValueError(f\"Invalid JSON format: {e}\") from e"}
{"question":"Provide the documentation for the function according to task description.","answer":"Find duplicates in a list of strings.\n\nArgs:\n    items: List of strings to check for duplicates\n    case_sensitive: Whether to consider case when comparing strings (default False)\n\nReturns:\n    List of duplicate strings found in the input list","context":"from typing import List, Optional\n\ndef find_duplicates(items: List[str], case_sensitive: bool = False) -> List[str]:\n    seen = set()\n    duplicates = set()\n    for item in items:\n        key = item if case_sensitive else item.lower()\n        if key in seen:\n            duplicates.add(item)\n        else:\n            seen.add(key)\n    return list(duplicates)"}
{"question":"Provide the documentation for the function according to task description.","answer":"Create a decorator that retries a function on specified exceptions.\n\nArgs:\n    max_attempts: Maximum number of retry attempts. Defaults to 3\n    delay: Delay in seconds between retries. Defaults to 1.0\n    exceptions: Tuple of exception types to catch and retry on. Defaults to (Exception,)\n\nReturns:\n    A decorator function that wraps the target function with retry logic\n\nRaises:\n    The last exception encountered if all retry attempts fail\n\nExample:\n    >>> @retry_on_exception(max_attempts=3, delay=0.5)\n    >>> def unreliable_function():\n    >>>     import random\n    >>>     if random.random() < 0.7:\n    >>>         raise ConnectionError(\"Temporary failure\")\n    >>>     return \"Success\"\n    >>> \n    >>> result = unreliable_function()  # Will retry up to 3 times","context":"from typing import Callable, TypeVar, Any\nimport functools\n\nT = TypeVar('T')\n\ndef retry_on_exception(max_attempts: int = 3, delay: float = 1.0, \n                      exceptions: tuple[type[Exception], ...] = (Exception,)) -> Callable[[Callable[..., T]], Callable[..., T]]:\n    def decorator(func: Callable[..., T]) -> Callable[..., T]:\n        @functools.wraps(func)\n        def wrapper(*args: Any, **kwargs: Any) -> T:\n            import time\n            last_exception = None\n            for attempt in range(max_attempts):\n                try:\n                    return func(*args, **kwargs)\n                except exceptions as e:\n                    last_exception = e\n                    if attempt < max_attempts - 1:\n                        time.sleep(delay)\n            raise last_exception\n        return wrapper\n    return decorator"}
{"question":"Provide the documentation for the function according to task description.","answer":"Process items in batches using a processing function.\n\nArgs:\n    items: List of items to process\n    process_func: Function that processes a single item\n    batch_size: Number of items to process in each batch. Defaults to 10\n\nRaises:\n    ValueError: If batch_size is not positive\n\nReturns:\n    List of processed items in the same order as input\n\nExample:\n    >>> numbers = [1, 2, 3, 4, 5, 6]\n    >>> batch_process(numbers, lambda x: x * 2, batch_size=3)\n    [2, 4, 6, 8, 10, 12]","context":"from typing import Callable, List, TypeVar\n\nT = TypeVar('T')\n\ndef batch_process(items: List[T], process_func: Callable[[T], T], batch_size: int = 10) -> List[T]:\n    if batch_size <= 0:\n        raise ValueError(\"Batch size must be positive\")\n    \n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i + batch_size]\n        processed_batch = [process_func(item) for item in batch]\n        results.extend(processed_batch)\n    return results"}
{"question":"Provide the documentation for the function according to task description.","answer":"Extract email addresses from text with optional domain filtering.\n\nArgs:\n    text: The input text to search for email addresses\n    domain_filter: Optional domain suffix to filter results (e.g., '@example.com')\n\nReturns:\n    List of email addresses found in the text, optionally filtered by domain\n\nExample:\n    >>> extract_emails('Contact: john@example.com, mary@test.org')\n    ['john@example.com', 'mary@test.org']\n    >>> extract_emails('Contact: john@example.com, mary@test.org', '@example.com')\n    ['john@example.com']","context":"import re\nfrom typing import List, Optional\n\ndef extract_emails(text: str, domain_filter: Optional[str] = None) -> List[str]:\n    email_pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n    emails = re.findall(email_pattern, text)\n    if domain_filter:\n        filtered_emails = [email for email in emails if email.endswith(domain_filter)]\n        return filtered_emails\n    return emails"}
{"question":"Provide the documentation for the function according to task description.","answer":"Load JSON configuration from a file or return default if file not found.\n\nArgs:\n    filepath: Path to the JSON configuration file\n    default_config: Default configuration to return if file is not found\n\nReturns:\n    Dictionary containing the loaded configuration or default values\n\nRaises:\n    ValueError: If the file contains invalid JSON\n\nExample:\n    >>> config = load_json_config('config.json', {'debug': False})\n    >>> print(config['debug'])\n    False","context":"import json\n\ndef load_json_config(filepath: str, default_config: dict[str, any]) -> dict[str, any]:\n    try:\n        with open(filepath, 'r', encoding='utf-8') as f:\n            config = json.load(f)\n    except FileNotFoundError:\n        config = default_config\n    except json.JSONDecodeError:\n        raise ValueError(f\"Invalid JSON in config file: {filepath}\")\n    return config"}
{"question":"Provide the documentation for the function according to task description.","answer":"Calculate compound interest for a given principal amount.\n\nArgs:\n    principal: Initial investment amount (must be positive)\n    rate: Annual interest rate (as decimal, cannot be negative)\n    years: Time period in years (cannot be negative)\n    compounding_periods: Number of times interest is compounded per year (default: 1)\n\nReturns:\n    Final amount after compound interest\n\nRaises:\n    ValueError: If principal is not positive, rate is negative, or years is negative\n\nExample:\n    >>> calculate_compound_interest(1000, 0.05, 10, 1)\n    1628.894626777442\n    >>> calculate_compound_interest(1000, 0.05, 10, 12)\n    1647.00949769027","context":"def calculate_compound_interest(principal: float, rate: float, years: int, compounding_periods: int = 1) -> float:\n    if principal <= 0:\n        raise ValueError(\"Principal amount must be positive\")\n    if rate < 0:\n        raise ValueError(\"Interest rate cannot be negative\")\n    if years < 0:\n        raise ValueError(\"Time period cannot be negative\")\n    \n    return principal * (1 + rate \/ compounding_periods) ** (compounding_periods * years)"}
{"question":"Provide the documentation for the function according to task description.","answer":"Add business days to a given date, skipping non-business days.\n\nArgs:\n    start_date: Starting datetime\n    days_to_add: Number of business days to add\n    business_days: List of weekday integers to consider as business days (0=Monday, 6=Sunday), defaults to weekdays\n\nReturns:\n    Datetime after adding the specified business days","context":"from datetime import datetime, timedelta\n\ndef add_business_days(start_date: datetime, days_to_add: int, business_days: List[int] = [0, 1, 2, 3, 4]) -> datetime:\n    current_date = start_date\n    days_added = 0\n    while days_added < days_to_add:\n        current_date += timedelta(days=1)\n        if current_date.weekday() in business_days:\n            days_added += 1\n    return current_date"}
{"question":"Provide the documentation for the function according to task description.","answer":"Filter a CSV file by column value and return matching rows.\n\nArgs:\n    csv_file: Path to the CSV file to read\n    column_name: Name of the column to filter by\n    filter_value: Value to match in the specified column\n\nReturns:\n    A list of dictionaries representing rows that match the filter criteria, \n    where each dictionary maps column names to values","context":"import csv\nfrom typing import List, Dict\n\ndef filter_csv_by_column(csv_file: str, column_name: str, filter_value: str) -> List[Dict[str, str]]:\n    filtered_rows = []\n    with open(csv_file, 'r', newline='') as file:\n        reader = csv.DictReader(file)\n        for row in reader:\n            if row.get(column_name) == filter_value:\n                filtered_rows.append(row)\n    return filtered_rows"}
{"question":"Provide the documentation for the function according to task description.","answer":"Load JSON configuration from file, returning default if file not found.\n\nArgs:\n    file_path: Path to the JSON configuration file\n    default_config: Default configuration to return if file not found. Defaults to empty dict\n\nReturns:\n    Dictionary containing the loaded configuration or default if file not found\n\nRaises:\n    ValueError: If the JSON file contains invalid JSON syntax\n\nExamples:\n    >>> config = load_json_config('config.json', {'default': True})\n    >>> config['default']\n    True","context":"import json\nfrom typing import Any\n\ndef load_json_config(file_path: str, default_config: dict[str, Any] = None) -> dict[str, Any]:\n    if default_config is None:\n        default_config = {}\n    try:\n        with open(file_path, 'r') as f:\n            return json.load(f)\n    except FileNotFoundError:\n        return default_config\n    except json.JSONDecodeError as e:\n        raise ValueError(f\"Invalid JSON in config file: {e}\")"}
{"question":"Provide the documentation for the function according to task description.","answer":"Parse URL query parameters into a dictionary.\n\nArgs:\n    url: The URL string to parse for query parameters\n\nReturns:\n    Dictionary where keys are parameter names and values are lists of parameter values\n\nExample:\n    >>> parse_query_params('http:\/\/example.com?name=john&age=30&name=doe')\n    {'name': ['john', 'doe'], 'age': ['30']}","context":"def parse_query_params(url: str) -> dict[str, list[str]]:\n    from urllib.parse import urlparse, parse_qs\n    parsed = urlparse(url)\n    return parse_qs(parsed.query)"}
{"question":"Provide the documentation for the function according to task description.","answer":"Load JSON data from a file.\n\nArgs:\n    file_path: Path to the JSON file to load\n\nReturns:\n    Parsed JSON data as a dictionary, or None if file doesn't exist\n\nRaises:\n    ValueError: If the file contains invalid JSON format\n\nExample:\n    >>> data = load_json_file(\"config.json\")\n    >>> if data:\n    ...     print(data.get(\"setting\"))\n    ... else:\n    ...     print(\"Config file not found\")","context":"from typing import Optional\nimport json\n\ndef load_json_file(file_path: str) -> Optional[dict]:\n    try:\n        with open(file_path, 'r') as file:\n            return json.load(file)\n    except FileNotFoundError:\n        return None\n    except json.JSONDecodeError:\n        raise ValueError(\"Invalid JSON format in file\")"}
{"question":"Provide the documentation for the function according to task description.","answer":"Calculate the geometric mean of a list of positive numbers.\n\nArgs:\n    numbers: A list of positive floating-point numbers\n\nReturns:\n    The geometric mean as a float\n\nRaises:\n    ValueError: If the input list is empty or contains non-positive numbers\n\nExample:\n    >>> calculate_geometric_mean([2.0, 8.0])\n    4.0\n    >>> calculate_geometric_mean([1.0, 3.0, 9.0])\n    3.0","context":"def calculate_geometric_mean(numbers: list[float]) -> float:\n    if not numbers:\n        raise ValueError(\"Input list cannot be empty\")\n    product = 1.0\n    for num in numbers:\n        if num <= 0:\n            raise ValueError(\"All numbers must be positive\")\n        product *= num\n    return product ** (1 \/ len(numbers))"}
{"question":"Provide the documentation for the function according to task description.","answer":"Parse URL query parameters into a dictionary.\n\nExtracts the query string from a URL and converts it to a dictionary\nof parameter names to single string values (using the first value when\nmultiple values exist for the same parameter).\n\nArgs:\n    url: URL string containing query parameters\n\nReturns:\n    Dictionary mapping parameter names to their string values\n\nExample:\n    >>> parse_query_params(\"https:\/\/example.com?name=john&age=30\")\n    {'name': 'john', 'age': '30'}","context":"def parse_query_params(url: str) -> dict[str, str]:\n    from urllib.parse import urlparse, parse_qs\n    parsed = urlparse(url)\n    query_params = parse_qs(parsed.query)\n    return {k: v[0] for k, v in query_params.items()}"}
{"question":"Provide the documentation for the function according to task description.","answer":"Extract all unique email addresses from a text string.\n\nUses a regular expression pattern to find email addresses and returns\nonly unique matches.\n\nArgs:\n    text: The input text to search for email addresses\n\nReturns:\n    A list of unique email addresses found in the text\n\nExample:\n    >>> extract_email_addresses(\"Contact us at info@example.com or support@example.org\")\n    ['info@example.com', 'support@example.org']","context":"import re\nfrom typing import Optional\n\ndef extract_email_addresses(text: str) -> list[str]:\n    email_pattern = r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}'\n    matches = re.findall(email_pattern, text)\n    return list(set(matches))"}
{"question":"Provide the documentation for the function according to task description.","answer":"Read CSV file and convert to a list of dictionaries.\n\nArgs:\n    file_path: Path to the CSV file\n    delimiter: Field delimiter character (default: ',')\n    encoding: File encoding (default: 'utf-8')\n\nReturns:\n    List of dictionaries where each dictionary represents a row with column headers as keys\n\nRaises:\n    ValueError: If file_path is empty\n    FileNotFoundError: If the specified file does not exist\n    IOError: If any other I\/O error occurs while reading the file\n\nExample:\n    >>> data = read_csv_to_dicts('data.csv')\n    >>> print(data[0]['column_name'])","context":"import csv\nfrom typing import List, Dict, Optional\n\ndef read_csv_to_dicts(file_path: str, delimiter: str = ',', encoding: str = 'utf-8') -> List[Dict[str, str]]:\n    if not file_path:\n        raise ValueError(\"File path cannot be empty\")\n    \n    data = []\n    try:\n        with open(file_path, 'r', encoding=encoding) as csvfile:\n            reader = csv.DictReader(csvfile, delimiter=delimiter)\n            for row in reader:\n                data.append(dict(row))\n    except FileNotFoundError:\n        raise FileNotFoundError(f\"File not found: {file_path}\")\n    except Exception as e:\n        raise IOError(f\"Error reading CSV file: {str(e)}\")\n    \n    return data"}
{"question":"Provide the documentation for the function according to task description.","answer":"Filter even numbers from a list of integers.\n\nArgs:\n    numbers: List of integers to filter\n\nReturns:\n    List containing only the even integers from the input\n\nRaises:\n    TypeError: If any element in the input list is not an integer","context":"def filter_even_numbers(numbers: list[int]) -> list[int]:\n    if not all(isinstance(x, int) for x in numbers):\n        raise TypeError(\"All elements must be integers\")\n    return [x for x in numbers if x % 2 == 0]"}
{"question":"Provide the documentation for the function according to task description.","answer":"Calculate the Euclidean distance between two 2D points.\n\nArgs:\n    point1: First point as (x, y) tuple\n    point2: Second point as (x, y) tuple\n\nReturns:\n    The Euclidean distance between the points\n\nRaises:\n    ValueError: If either point does not contain exactly 2 coordinates\n\nExample:\n    >>> calculate_distance((0, 0), (3, 4))\n    5.0","context":"def calculate_distance(point1: tuple[float, float], point2: tuple[float, float]) -> float:\n    import math\n    if len(point1) != 2 or len(point2) != 2:\n        raise ValueError(\"Points must be 2D coordinates\")\n    return math.sqrt((point2[0] - point1[0])**2 + (point2[1] - point1[1])**2)"}
{"question":"Provide the documentation for the function according to task description.","answer":"Read CSV file and convert to list of dictionaries.\n\nArgs:\n    file_path: Path to the CSV file\n    delimiter: Field delimiter character. Defaults to comma\n\nReturns:\n    A list of dictionaries where keys are column headers and values are row data\n\nRaises:\n    ValueError: If file path does not end with .csv extension\n    FileNotFoundError: If the specified file path does not exist\n\nExample:\n    >>> data = read_csv_to_dicts('data.csv')\n    >>> print(data[0]['column_name'])","context":"import csv\nfrom typing import List, Dict\n\ndef read_csv_to_dicts(file_path: str, delimiter: str = ',') -> List[Dict[str, str]]:\n    if not file_path.endswith('.csv'):\n        raise ValueError(\"File must be a CSV file\")\n    try:\n        with open(file_path, 'r', newline='') as csvfile:\n            reader = csv.DictReader(csvfile, delimiter=delimiter)\n            return list(reader)\n    except FileNotFoundError:\n        raise FileNotFoundError(f\"CSV file not found at path: {file_path}\")"}
{"question":"Provide the documentation for the function according to task description.","answer":"Parse a CSV line into individual fields.\n\nArgs:\n    line: The CSV line string to parse\n    delimiter: Field delimiter character (default: ',')\n    quote_char: Quote character for escaped fields (default: '\"')\n\nReturns:\n    A list of parsed string fields\n\nRaises:\n    ValueError: If delimiter or quote_char are not single characters\n\nExample:\n    >>> parse_csv_line('a,b,c')\n    ['a', 'b', 'c']\n    >>> parse_csv_line('\"a,b\",c', delimiter=',', quote_char='\"')\n    ['a,b', 'c']","context":"def parse_csv_line(line: str, delimiter: str = ',', quote_char: str = '\"') -> list[str]:\n    if not line:\n        return []\n    if len(delimiter) != 1:\n        raise ValueError(\"Delimiter must be a single character\")\n    if len(quote_char) != 1:\n        raise ValueError(\"Quote character must be a single character\")\n    \n    result = []\n    current_field = \"\"\n    in_quotes = False\n    \n    for char in line:\n        if char == quote_char:\n            in_quotes = not in_quotes\n        elif char == delimiter and not in_quotes:\n            result.append(current_field)\n            current_field = \"\"\n        else:\n            current_field += char\n    \n    result.append(current_field)\n    return result"}
{"question":"Provide the documentation for the function according to task description.","answer":"Extract phone numbers from text using pattern matching.\n\nArgs:\n    text: Input string that may contain a phone number\n\nReturns:\n    Formatted phone number string in (XXX) XXX-XXXX format, or None if no match found","context":"import re\nfrom typing import Optional\n\ndef extract_phone_number(text: str) -> Optional[str]:\n    phone_pattern = r'\\(?(\\d{3})\\)?[-.\\s]?(\\d{3})[-.\\s]?(\\d{4})'\n    match = re.search(phone_pattern, text)\n    if match:\n        return f\"({match.group(1)}) {match.group(2)}-{match.group(3)}\"\n    return None"}
{"question":"Provide the documentation for the function according to task description.","answer":"Format a phone number to international standard with country code.\n\nArgs:\n    phone: String containing phone number digits and optional formatting\n    country_code: Country dialing code with '+' prefix. Defaults to \"+1\"\n\nReturns:\n    Formatted phone number string in format: \"+1 (XXX) XXX-XXXX\"\n\nRaises:\n    ValueError: If phone number doesn't contain exactly 10 digits\n\nExample:\n    >>> format_phone_number(\"555-123-4567\")\n    '+1 (555) 123-4567'\n    >>> format_phone_number(\"442071234567\", \"+44\")\n    '+44 (207) 123-4567'","context":"def format_phone_number(phone: str, country_code: str = \"+1\") -> str:\n    digits = ''.join(filter(str.isdigit, phone))\n    if len(digits) != 10:\n        raise ValueError(\"Phone number must contain exactly 10 digits\")\n    return f\"{country_code} ({digits[:3]}) {digits[3:6]}-{digits[6:]}\""}
{"question":"Provide the documentation for the function according to task description.","answer":"Rotate a matrix 90 degrees clockwise.\n\nArgs:\n    matrix: A 2D list of integers to rotate\n\nReturns:\n    A new 2D list representing the rotated matrix\n\nExample:\n    >>> rotate_matrix_clockwise([[1, 2, 3], [4, 5, 6]])\n    [[4, 1], [5, 2], [6, 3]]","context":"def rotate_matrix_clockwise(matrix: list[list[int]]) -> list[list[int]]:\n    if not matrix or len(matrix) == 0:\n        return []\n    rows, cols = len(matrix), len(matrix[0])\n    rotated = [[0] * rows for _ in range(cols)]\n    for i in range(rows):\n        for j in range(cols):\n            rotated[j][rows - 1 - i] = matrix[i][j]\n    return rotated"}
{"question":"Provide the documentation for the function according to task description.","answer":"Generate a list of upcoming dates starting from a given date.\n\nArgs:\n    start_date: String representing the starting date\n    num_days: Number of consecutive days to generate\n    date_format: Format string for date parsing and output (default: \"%Y-%m-%d\")\n\nReturns:\n    List of formatted date strings for the upcoming days\n\nRaises:\n    ValueError: If num_days is not positive or start_date format is invalid\n\nExample:\n    >>> get_upcoming_days(\"2023-01-01\", 3)\n    ['2023-01-01', '2023-01-02', '2023-01-03']","context":"from datetime import datetime, timedelta\nfrom typing import List\n\ndef get_upcoming_days(start_date: str, num_days: int, date_format: str = \"%Y-%m-%d\") -> List[str]:\n    if num_days <= 0:\n        raise ValueError(\"num_days must be positive\")\n    \n    try:\n        current = datetime.strptime(start_date, date_format)\n    except ValueError:\n        raise ValueError(f\"start_date must match format {date_format}\")\n    \n    upcoming_days = []\n    for i in range(num_days):\n        next_day = current + timedelta(days=i)\n        upcoming_days.append(next_day.strftime(date_format))\n    \n    return upcoming_days"}
{"question":"Provide the documentation for the function according to task description.","answer":"Validate whether an email address matches standard format requirements.\n\nArgs:\n    email: A string containing the email address to validate\n\nReturns:\n    True if the email format is valid, False otherwise\n\nExample:\n    >>> validate_email_format('test@example.com')\n    True\n    >>> validate_email_format('invalid-email')\n    False","context":"def validate_email_format(email: str) -> bool:\n    import re\n    pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'\n    if not isinstance(email, str) or not email:\n        return False\n    return bool(re.fullmatch(pattern, email))"}
{"question":"Provide the documentation for the function according to task description.","answer":"Count word frequency in a text string.\n\nArgs:\n    text: Input text to analyze\n\nReturns:\n    Dictionary mapping words to their frequency counts","context":"def count_word_frequency(text: str) -> dict[str, int]:\n    words = text.lower().split()\n    frequency = {}\n    for word in words:\n        cleaned_word = word.strip('.,!?;:\"')\n        if cleaned_word:\n            frequency[cleaned_word] = frequency.get(cleaned_word, 0) + 1\n    return frequency"}
{"question":"Provide the documentation for the function according to task description.","answer":"Extract phone numbers from text using a regular expression pattern.\n\nArgs:\n    text: The input text to search for phone numbers\n    pattern: Regular expression pattern to match phone numbers. Defaults to standard US format\n\nRaises:\n    TypeError: If text is not a string\n\nReturns:\n    List of matched phone number strings\n\nExample:\n    >>> extract_phone_numbers(\"Call me at 555-123-4567 or 888-999-0000\")\n    ['555-123-4567', '888-999-0000']","context":"import re\n\ndef extract_phone_numbers(text: str, pattern: str = r'\\b\\d{3}-\\d{3}-\\d{4}\\b') -> list[str]:\n    if not isinstance(text, str):\n        raise TypeError(\"Text must be a string\")\n    \n    matches = re.findall(pattern, text)\n    return matches"}
{"question":"Provide the documentation for the function according to task description.","answer":"Read a CSV file and convert it to a list of dictionaries.\n\nArgs:\n    filepath: Path to the CSV file to read\n    delimiter: Delimiter character for CSV parsing (default: ',')\n\nReturns:\n    A list of dictionaries where each dictionary represents a row with column headers as keys\n\nRaises:\n    FileNotFoundError: If the specified CSV file does not exist\n\nExample:\n    >>> data = read_csv_to_dicts(\"data.csv\")\n    >>> print(data[0][\"column_name\"])","context":"import csv\nfrom typing import List, Dict\n\ndef read_csv_to_dicts(filepath: str, delimiter: str = ',') -> List[Dict[str, str]]:\n    data = []\n    try:\n        with open(filepath, 'r', newline='', encoding='utf-8') as file:\n            reader = csv.DictReader(file, delimiter=delimiter)\n            for row in reader:\n                data.append(row)\n        return data\n    except FileNotFoundError:\n        raise FileNotFoundError(f\"CSV file not found: {filepath}\")"}
{"question":"Provide the documentation for the function according to task description.","answer":"Merge two dictionaries with optional overwrite behavior.\n\nArgs:\n    dict1: First dictionary to merge\n    dict2: Second dictionary to merge\n    overwrite: Whether to overwrite existing keys from dict1 with values from dict2.\n        Defaults to True\n\nReturns:\n    A new dictionary containing the merged key-value pairs\n\nExample:\n    >>> d1 = {'a': 1, 'b': 2}\n    >>> d2 = {'b': 3, 'c': 4}\n    >>> merge_dictionaries(d1, d2)\n    {'a': 1, 'b': 3, 'c': 4}\n    >>> merge_dictionaries(d1, d2, overwrite=False)\n    {'a': 1, 'b': 2, 'c': 4}","context":"def merge_dictionaries(dict1: dict[str, any], dict2: dict[str, any], overwrite: bool = True) -> dict[str, any]:\n    result = dict1.copy()\n    for key, value in dict2.items():\n        if key in result and not overwrite:\n            continue\n        result[key] = value\n    return result"}
{"question":"Provide the documentation for the function according to task description.","answer":"Extract email addresses from text with optional domain filtering.\n\nArgs:\n    text: The input text to search for email addresses\n    domain_filter: Optional domain suffix to filter results (e.g., '@example.com')\n\nReturns:\n    List of unique email addresses found in the text\n\nExample:\n    >>> text = \"Contact us at info@company.com or support@company.com\"\n    >>> extract_emails(text)\n    ['info@company.com', 'support@company.com']\n    >>> extract_emails(text, '@company.com')\n    ['info@company.com', 'support@company.com']","context":"from typing import List, Optional\nimport re\n\ndef extract_emails(text: str, domain_filter: Optional[str] = None) -> List[str]:\n    email_pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n    emails = re.findall(email_pattern, text)\n    if domain_filter:\n        emails = [email for email in emails if email.endswith(domain_filter)]\n    return list(set(emails))"}
{"question":"Provide the documentation for the function according to task description.","answer":"Convert a naive datetime from one timezone to another.\n\nArgs:\n    dt: Naive datetime object to convert\n    from_tz: Source timezone offset as string (e.g., '+5', '-3')\n    to_tz: Target timezone offset as string (e.g., '+8', '-2')\n\nReturns:\n    Naive datetime object converted to target timezone\n\nRaises:\n    ValueError: If input datetime has timezone info or timezone format is invalid\n\nExample:\n    >>> dt = datetime(2023, 1, 1, 12, 0, 0)\n    >>> convert_timezone(dt, '+0', '+5')\n    datetime.datetime(2023, 1, 1, 17, 0, 0)","context":"from datetime import datetime, timezone, timedelta\n\ndef convert_timezone(dt: datetime, from_tz: str, to_tz: str) -> datetime:\n    if dt.tzinfo is not None:\n        raise ValueError(\"Input datetime must be naive (no timezone info)\")\n    \n    try:\n        from_zone = timezone(timedelta(hours=int(from_tz)))\n        to_zone = timezone(timedelta(hours=int(to_tz)))\n    except ValueError:\n        raise ValueError(\"Timezone must be in format like '+5', '-3'\")\n    \n    localized_dt = dt.replace(tzinfo=from_zone)\n    converted_dt = localized_dt.astimezone(to_zone)\n    return converted_dt.replace(tzinfo=None)"}
{"question":"Provide the documentation for the function according to task description.","answer":"Calculate the number of business days between two dates, excluding weekends and holidays.\n\nArgs:\n    start_date: The starting date of the period\n    end_date: The ending date of the period\n    holidays: Optional list of holiday dates to exclude. Defaults to None\n\nReturns:\n    The number of business days between start_date and end_date\n\nRaises:\n    ValueError: If start_date is after end_date\n\nExample:\n    >>> from datetime import datetime\n    >>> start = datetime(2023, 12, 1)  # Friday\n    >>> end = datetime(2023, 12, 5)    # Tuesday\n    >>> holidays = [datetime(2023, 12, 4)]  # Monday holiday\n    >>> calculate_business_days(start, end, holidays)\n    2","context":"from datetime import datetime, timedelta\nfrom typing import Optional\n\ndef calculate_business_days(start_date: datetime, end_date: datetime, holidays: Optional[list[datetime]] = None) -> int:\n    if start_date > end_date:\n        raise ValueError(\"Start date must be before end date\")\n    \n    holidays = holidays or []\n    holiday_dates = {h.date() for h in holidays}\n    \n    current = start_date\n    business_days = 0\n    \n    while current <= end_date:\n        if current.weekday() < 5 and current.date() not in holiday_dates:\n            business_days += 1\n        current += timedelta(days=1)\n    \n    return business_days"}
{"question":"Provide the documentation for the function according to task description.","answer":"Read CSV file and convert its contents to a list of dictionaries.\n\nArgs:\n    filename: Path to the CSV file\n    delimiter: Character used to separate fields. Defaults to comma\n    encoding: File encoding. Defaults to 'utf-8'\n\nReturns:\n    List of dictionaries where keys are column headers and values are row data\n\nRaises:\n    FileNotFoundError: If the specified file does not exist\n    UnicodeDecodeError: If the file cannot be decoded with the specified encoding","context":"import csv\nfrom typing import List, Dict\n\ndef read_csv_to_dicts(filename: str, delimiter: str = ',', encoding: str = 'utf-8') -> List[Dict[str, str]]:\n    result = []\n    try:\n        with open(filename, 'r', encoding=encoding) as file:\n            reader = csv.DictReader(file, delimiter=delimiter)\n            for row in reader:\n                result.append(dict(row))\n    except FileNotFoundError:\n        raise FileNotFoundError(f\"File {filename} not found\")\n    except UnicodeDecodeError:\n        raise UnicodeDecodeError(f\"Unable to decode file {filename} with encoding {encoding}\")\n    return result"}
{"question":"Provide the documentation for the function according to task description.","answer":"Calculate the next occurrence of a specific weekday from a given date.\n\nArgs:\n    start_date: The starting date to calculate from\n    weekday: Integer representing the target weekday (0=Monday, 6=Sunday)\n    include_start: If True and start_date is already the target weekday, return start_date\n\nReturns:\n    The next occurrence of the specified weekday\n\nRaises:\n    ValueError: If weekday is not between 0 and 6\n\nExample:\n    >>> from datetime import datetime\n    >>> get_next_weekday(datetime(2023, 10, 15), 0)  # Next Monday from Sunday\n    datetime(2023, 10, 16)","context":"from datetime import datetime, timedelta\nfrom typing import Optional\n\ndef get_next_weekday(start_date: datetime, weekday: int, include_start: bool = False) -> datetime:\n    if weekday < 0 or weekday > 6:\n        raise ValueError(\"Weekday must be between 0 (Monday) and 6 (Sunday)\")\n    \n    if include_start and start_date.weekday() == weekday:\n        return start_date\n    \n    days_ahead = weekday - start_date.weekday()\n    if days_ahead <= 0:\n        days_ahead += 7\n    return start_date + timedelta(days=days_ahead)"}
{"question":"Provide the documentation for the function according to task description.","answer":"Filter even numbers from a list of integers.\n\nArgs:\n    numbers: A list of integers to filter\n\nReturns:\n    A list containing only the even integers from the input list\n\nRaises:\n    TypeError: If the input is not a list\n\nExample:\n    >>> filter_even_numbers([1, 2, 3, 4, 5])\n    [2, 4]","context":"from typing import List, Optional\n\ndef filter_even_numbers(numbers: List[int]) -> List[int]:\n    if not isinstance(numbers, list):\n        raise TypeError(\"Input must be a list\")\n    return [num for num in numbers if num % 2 == 0]"}
{"question":"Provide the documentation for the function according to task description.","answer":"Calculate a future date by adding days and hours to a base date.\n\nArgs:\n    base_date: Starting datetime object (defaults to current time if None)\n    days: Number of days to add\n    hours: Number of hours to add\n\nReturns:\n    New datetime object representing the future date\n\nRaises:\n    TypeError: If base_date is provided but not a datetime object\n\nExample:\n    >>> calculate_future_date(days=5, hours=12)\n    datetime(2023, 10, 15, 12, 30, 45)  # Current date + 5 days 12 hours","context":"from typing import Optional\nfrom datetime import datetime, timedelta\n\ndef calculate_future_date(base_date: Optional[datetime] = None, days: int = 0, hours: int = 0) -> datetime:\n    if base_date is None:\n        base_date = datetime.now()\n    if not isinstance(base_date, datetime):\n        raise TypeError(\"base_date must be a datetime object\")\n    return base_date + timedelta(days=days, hours=hours)"}
{"question":"Provide the documentation for the function according to task description.","answer":"Execute an operation with retry logic for handling exceptions.\n\nArgs:\n    operation: Callable that takes no arguments and returns a value\n    max_attempts: Maximum number of retry attempts. Defaults to 3\n    delay: Delay in seconds between retry attempts. Defaults to 1.0\n\nReturns:\n    The result of the successful operation\n\nRaises:\n    Exception: Re-raises the last exception if all attempts fail\n    RuntimeError: If an unexpected error occurs in the retry logic\n\nExample:\n    >>> result = retry_operation(lambda: risky_api_call(), max_attempts=5, delay=2.0)\n    >>> print(result)","context":"from typing import Callable, List, TypeVar\n\nT = TypeVar('T')\n\ndef retry_operation(operation: Callable[[], T], max_attempts: int = 3, delay: float = 1.0) -> T:\n    import time\n    for attempt in range(max_attempts):\n        try:\n            return operation()\n        except Exception as e:\n            if attempt == max_attempts - 1:\n                raise e\n            time.sleep(delay)\n    raise RuntimeError(\"Unexpected error in retry operation\")"}
{"question":"Provide the documentation for the function according to task description.","answer":"Parse a string in ISO 8601 date format (YYYY-MM-DD) into a date object.\n\nArgs:\n    date_string: String representing a date in YYYY-MM-DD format\n\nReturns:\n    A datetime.date object representing the parsed date\n\nRaises:\n    ValueError: If the input string does not match the expected ISO date format\n\nExample:\n    >>> parse_iso_date(\"2023-12-25\")\n    datetime.date(2023, 12, 25)","context":"def parse_iso_date(date_string: str) -> datetime.date:\n    try:\n        return datetime.datetime.strptime(date_string, \"%Y-%m-%d\").date()\n    except ValueError:\n        raise ValueError(f\"Invalid ISO date format: {date_string}\")"}
{"question":"Provide the documentation for the function according to task description.","answer":"Count the frequency of each character in a string.\n\nArgs:\n    text: String to analyze for character frequency\n\nReturns:\n    Dictionary mapping each character to its frequency count","context":"def count_character_frequency(text: str) -> dict[str, int]:\n    frequency = {}\n    for char in text:\n        if char in frequency:\n            frequency[char] += 1\n        else:\n            frequency[char] = 1\n    return frequency"}
{"question":"Provide the documentation for the function according to task description.","answer":"Parse a query string into a dictionary of key-value pairs.\n\nArgs:\n    query: The query string to parse\n\nReturns:\n    Dictionary containing parsed key-value parameters","context":"def parse_query_string(query: str) -> dict[str, str]:\n    if not query:\n        return {}\n    params = {}\n    pairs = query.split('&')\n    for pair in pairs:\n        if '=' in pair:\n            key, value = pair.split('=', 1)\n            params[key] = value\n    return params"}
{"question":"Provide the documentation for the function according to task description.","answer":"Filter strings based on length constraints.\n\nArgs:\n    strings: List of strings to filter\n    min_length: Minimum allowed string length. Defaults to 1\n    max_length: Maximum allowed string length. If None, no upper limit\n\nReturns:\n    List of strings that meet the length criteria\n\nRaises:\n    ValueError: If min_length is negative or max_length is less than min_length\n\nExample:\n    >>> filter_strings_by_length(['a', 'ab', 'abc'], min_length=2, max_length=3)\n    ['ab', 'abc']","context":"from typing import List, Optional\n\ndef filter_strings_by_length(strings: List[str], min_length: int = 1, max_length: Optional[int] = None) -> List[str]:\n    if min_length < 0:\n        raise ValueError(\"min_length cannot be negative\")\n    if max_length is not None and max_length < min_length:\n        raise ValueError(\"max_length cannot be less than min_length\")\n    \n    return [s for s in strings if len(s) >= min_length and (max_length is None or len(s) <= max_length)]"}
{"question":"Provide the documentation for the function according to task description.","answer":"Add days to a given date string and return the result.\n\nArgs:\n    start_date: String representing the starting date\n    days_to_add: Number of days to add (can be negative to subtract)\n    date_format: Format string for input and output dates. Defaults to \"%Y-%m-%d\"\n\nReturns:\n    String representing the new date in the specified format\n\nRaises:\n    ValueError: If the date format is invalid or date values are incorrect","context":"from datetime import datetime, timedelta\n\ndef add_days_to_date(start_date: str, days_to_add: int, date_format: str = \"%Y-%m-%d\") -> str:\n    try:\n        date_obj = datetime.strptime(start_date, date_format)\n        new_date = date_obj + timedelta(days=days_to_add)\n        return new_date.strftime(date_format)\n    except ValueError as e:\n        raise ValueError(f\"Invalid date format or value: {e}\")"}
{"question":"Provide the documentation for the function according to task description.","answer":"Parse query parameters from a URL string.\n\nArgs:\n    url: The URL string containing query parameters\n\nReturns:\n    A dictionary containing the first value for each query parameter\n\nExample:\n    >>> parse_query_params(\"https:\/\/example.com?name=john&age=30\")\n    {'name': 'john', 'age': '30'}","context":"def parse_query_params(url: str) -> dict[str, str]:\n    from urllib.parse import urlparse, parse_qs\n    parsed = urlparse(url)\n    query_dict = parse_qs(parsed.query)\n    return {k: v[0] for k, v in query_dict.items() if v}"}
{"question":"Provide the documentation for the function according to task description.","answer":"Parse log file using a regex pattern to extract structured data.\n\nArgs:\n    log_file_path: Path to the log file to parse\n    pattern: Regex pattern with named groups for data extraction\n    max_lines: Maximum number of lines to read from the file (default: 1000)\n\nReturns:\n    List of dictionaries containing parsed log data with line numbers, content, and matched groups\n\nRaises:\n    FileNotFoundError: If the specified log file does not exist\n    ValueError: If the file cannot be decoded with UTF-8 encoding\n\nExample:\n    >>> result = parse_log_file('app.log', r'(?P<timestamp>\\d{4}-\\d{2}-\\d{2}) (?P<level>\\w+): (?P<message>.+)')\n    >>> print(result[0]['matches']['level'])\n    'INFO'","context":"def parse_log_file(log_file_path: str, pattern: str, max_lines: int = 1000) -> list[dict[str, str]]:\n    import re\n    import csv\n    from io import StringIO\n    \n    try:\n        with open(log_file_path, 'r', encoding='utf-8') as file:\n            lines = [next(file) for _ in range(max_lines)]\n    except FileNotFoundError:\n        raise FileNotFoundError(f\"Log file not found: {log_file_path}\")\n    except UnicodeDecodeError:\n        raise ValueError(\"Unable to decode file with UTF-8 encoding\")\n    \n    compiled_pattern = re.compile(pattern)\n    parsed_data = []\n    \n    for line_number, line in enumerate(lines, 1):\n        match = compiled_pattern.search(line)\n        if match:\n            parsed_data.append({\n                'line_number': line_number,\n                'content': line.strip(),\n                'matches': match.groupdict()\n            })\n    \n    return parsed_data"}
{"question":"Provide the documentation for the function according to task description.","answer":"Extract all email addresses from a text string.\n\nArgs:\n    text: The input text to search for email addresses\n\nReturns:\n    List of found email addresses, or None if no emails found or invalid input","context":"import re\nfrom typing import Optional\n\ndef extract_email_addresses(text: str) -> Optional[list[str]]:\n    if not text or not isinstance(text, str):\n        return None\n    email_pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n    matches = re.findall(email_pattern, text)\n    return matches if matches else None"}
{"question":"Provide the documentation for the function according to task description.","answer":"Fetch JSON data from a URL with retry logic.\n\nArgs:\n    url: The URL to fetch JSON data from\n    max_retries: Maximum number of retry attempts (default: 3)\n    timeout: Request timeout in seconds (default: 5.0)\n\nReturns:\n    dict: The parsed JSON response data\n\nRaises:\n    aiohttp.ClientError: If HTTP request fails after all retries\n    asyncio.TimeoutError: If request times out after all retries\n\nExample:\n    >>> data = await fetch_json_with_retry('https:\/\/api.example.com\/data')","context":"async def fetch_json_with_retry(url: str, max_retries: int = 3, timeout: float = 5.0) -> dict:\n    import aiohttp\n    import asyncio\n    retries = 0\n    while retries <= max_retries:\n        try:\n            async with aiohttp.ClientSession() as session:\n                async with session.get(url, timeout=timeout) as response:\n                    response.raise_for_status()\n                    return await response.json()\n        except (aiohttp.ClientError, asyncio.TimeoutError):\n            retries += 1\n            if retries > max_retries:\n                raise\n            await asyncio.sleep(1 * retries)"}
{"question":"Provide the documentation for the function according to task description.","answer":"Group a list of dictionaries by a specified key.\n\nArgs:\n    items: List of dictionaries to group\n    key: Key to use for grouping the dictionaries\n\nReturns:\n    Dictionary mapping key values to lists of dictionaries containing that key value\n\nRaises:\n    KeyError: If the specified key is not present in the dictionary items\n\nExample:\n    >>> data = [{'name': 'Alice', 'dept': 'HR'}, {'name': 'Bob', 'dept': 'IT'}]\n    >>> group_by_key(data, 'dept')\n    {'HR': [{'name': 'Alice', 'dept': 'HR'}], 'IT': [{'name': 'Bob', 'dept': 'IT'}]}","context":"from typing import List, Dict\n\ndef group_by_key(items: List[Dict[str, str]], key: str) -> Dict[str, List[Dict[str, str]]]:\n    if not items:\n        return {}\n    if key not in items[0]:\n        raise KeyError(f\"Key '{key}' not found in dictionary items\")\n    \n    grouped = {}\n    for item in items:\n        group_value = item[key]\n        if group_value not in grouped:\n            grouped[group_value] = []\n        grouped[group_value].append(item)\n    return grouped"}
{"question":"Provide the documentation for the function according to task description.","answer":"Fetch multiple URLs concurrently using asynchronous requests.\n\nArgs:\n    urls: List of URLs to fetch\n    timeout: Request timeout in seconds for each URL. Defaults to 30\n\nReturns:\n    Dictionary mapping each URL to a result dictionary with keys:\n        - status: Either \"success\", \"timeout\", or \"error\"\n        - data: Response text for successful requests, None for timeouts, \n                or error message for other errors\n\nRaises:\n    This function does not raise exceptions itself, but captures and returns\n    errors in the result dictionary for each individual URL","context":"import asyncio\nfrom typing import List, Dict, Any\nimport aiohttp\n\nasync def fetch_multiple_urls(urls: List[str], timeout: int = 30) -> Dict[str, Any]:\n    results = {}\n    async with aiohttp.ClientSession() as session:\n        tasks = []\n        for url in urls:\n            task = asyncio.create_task(_fetch_url(session, url, timeout))\n            tasks.append((url, task))\n        \n        for url, task in tasks:\n            try:\n                response = await task\n                results[url] = {\"status\": \"success\", \"data\": response}\n            except asyncio.TimeoutError:\n                results[url] = {\"status\": \"timeout\", \"data\": None}\n            except aiohttp.ClientError as e:\n                results[url] = {\"status\": \"error\", \"data\": str(e)}\n    \n    return results\n\nasync def _fetch_url(session: aiohttp.ClientSession, url: str, timeout: int) -> str:\n    async with session.get(url, timeout=timeout) as response:\n        response.raise_for_status()\n        return await response.text()"}
{"question":"Provide the documentation for the function according to task description.","answer":"Read a JSON file and parse its contents.\n\nArgs:\n    file_path: Path to the JSON file to read\n    encoding: Text encoding to use when reading the file. Defaults to 'utf-8'\n\nReturns:\n    Parsed JSON data (dict, list, or other JSON-compatible types)\n\nRaises:\n    FileNotFoundError: If the specified file does not exist\n    ValueError: If the file contains invalid JSON format\n\nExample:\n    >>> data = read_json_file('config.json')\n    >>> print(data['setting'])","context":"import json\nfrom typing import Any\n\ndef read_json_file(file_path: str, encoding: str = 'utf-8') -> Any:\n    try:\n        with open(file_path, 'r', encoding=encoding) as file:\n            return json.load(file)\n    except FileNotFoundError:\n        raise FileNotFoundError(f\"File not found: {file_path}\")\n    except json.JSONDecodeError as e:\n        raise ValueError(f\"Invalid JSON format: {e}\")"}
{"question":"Provide the documentation for the function according to task description.","answer":"Calculate a date by adding days to a start date.\n\nArgs:\n    start_date: The starting date string to calculate from\n    days: Number of days to add (can be negative for subtraction)\n    date_format: Format string for input and output dates (default: \"%Y-%m-%d\")\n\nReturns:\n    The calculated end date as a formatted string\n\nRaises:\n    ValueError: If the start_date format is invalid or calculation results in overflow\n\nExample:\n    >>> calculate_date_range(\"2023-01-01\", 30)\n    '2023-01-31'\n    >>> calculate_date_range(\"2023-12-31\", -1)\n    '2023-12-30'","context":"from datetime import datetime, timedelta\nfrom typing import Optional\n\ndef calculate_date_range(start_date: str, days: int, date_format: str = \"%Y-%m-%d\") -> Optional[str]:\n    try:\n        start = datetime.strptime(start_date, date_format)\n        end_date = start + timedelta(days=days)\n        return end_date.strftime(date_format)\n    except ValueError:\n        raise ValueError(f\"Invalid date format. Expected format: {date_format}\")\n    except OverflowError:\n        raise ValueError(\"Date calculation resulted in overflow\")"}
{"question":"Provide the documentation for the function according to task description.","answer":"Fetch JSON data from a URL with optional timeout and headers.\n\nArgs:\n    url: The URL to fetch JSON data from\n    timeout: Request timeout in seconds (default: 10)\n    headers: Optional HTTP headers to include in the request\n\nReturns:\n    Dictionary containing the parsed JSON response\n\nRaises:\n    TimeoutError: If the request times out\n    ConnectionError: If the request fails for any other reason\n\nExample:\n    >>> data = fetch_json_data(\"https:\/\/api.example.com\/data\", timeout=5)\n    >>> print(data[\"key\"])","context":"def fetch_json_data(url: str, timeout: int = 10, headers: dict[str, str] | None = None) -> dict:\n    import requests\n    from requests.exceptions import RequestException, Timeout\n    try:\n        response = requests.get(url, timeout=timeout, headers=headers)\n        response.raise_for_status()\n        return response.json()\n    except Timeout:\n        raise TimeoutError(f\"Request to {url} timed out\")\n    except RequestException as e:\n        raise ConnectionError(f\"Failed to fetch data: {e}\")"}
{"question":"Provide the documentation for the function according to task description.","answer":"Read a JSON file and parse its contents into a Python dictionary.\n\nArgs:\n    filepath: Path to the JSON file to read\n    encoding: Text encoding to use (defaults to 'utf-8')\n\nReturns:\n    A dictionary containing the parsed JSON data\n\nRaises:\n    FileNotFoundError: If the specified file does not exist\n    ValueError: If the file contains invalid JSON format\n\nExample:\n    >>> data = read_json_file('config.json')\n    >>> print(data['version'])\n    1.0","context":"from typing import Dict, Any\nimport json\n\ndef read_json_file(filepath: str, encoding: str = 'utf-8') -> Dict[str, Any]:\n    try:\n        with open(filepath, 'r', encoding=encoding) as file:\n            return json.load(file)\n    except FileNotFoundError:\n        raise FileNotFoundError(f\"File not found: {filepath}\")\n    except json.JSONDecodeError:\n        raise ValueError(f\"Invalid JSON format in file: {filepath}\")"}
{"question":"Provide the documentation for the function according to task description.","answer":"Validate an email address format.\n\nArgs:\n    email: The email address string to validate\n\nReturns:\n    True if the email format is valid, False otherwise\n\nRaises:\n    TypeError: If the input is not a string","context":"def validate_email_address(email: str) -> bool:\n    if not isinstance(email, str):\n        raise TypeError(\"Email must be a string\")\n    if \"@\" not in email:\n        return False\n    local_part, domain = email.split(\"@\", 1)\n    if not local_part or not domain:\n        return False\n    if \".\" not in domain:\n        return False\n    return True"}
{"question":"Provide the documentation for the function according to task description.","answer":"Read JSON data from a file.\n\nArgs:\n    filepath: Path to the JSON file\n\nReturns:\n    Dictionary containing the parsed JSON data\n\nRaises:\n    FileNotFoundError: If the specified file does not exist\n    ValueError: If the file contains invalid JSON format\n\nExample:\n    >>> data = read_json_file('config.json')\n    >>> print(data['setting'])","context":"def read_json_file(filepath: str) -> dict:\n    import json\n    try:\n        with open(filepath, 'r') as file:\n            return json.load(file)\n    except FileNotFoundError:\n        raise FileNotFoundError(f\"File {filepath} not found\")\n    except json.JSONDecodeError:\n        raise ValueError(f\"Invalid JSON format in {filepath}\")"}
{"question":"Provide the documentation for the function according to task description.","answer":"Fetch data from a REST API endpoint.\n\nArgs:\n    url: The API endpoint URL to fetch data from\n    headers: Optional dictionary of HTTP headers to include in the request\n    timeout: Maximum time in seconds to wait for the request to complete (default: 10)\n\nReturns:\n    Dictionary containing the parsed JSON response from the API\n\nRaises:\n    Timeout: If the request exceeds the specified timeout duration\n    ConnectionError: If any other network or HTTP error occurs during the request\n\nExample:\n    >>> data = fetch_api_data(\"https:\/\/api.example.com\/data\", {\"Authorization\": \"Bearer token\"})\n    >>> print(data[\"results\"])","context":"from typing import Dict, Any, Optional\nimport requests\nfrom requests.exceptions import RequestException, Timeout\n\ndef fetch_api_data(url: str, headers: Optional[Dict[str, str]] = None, timeout: int = 10) -> Dict[str, Any]:\n    try:\n        response = requests.get(url, headers=headers, timeout=timeout)\n        response.raise_for_status()\n        return response.json()\n    except Timeout:\n        raise Timeout(f\"Request to {url} timed out after {timeout} seconds\")\n    except RequestException as e:\n        raise ConnectionError(f\"Failed to fetch data from {url}: {e}\")"}
{"question":"Provide the documentation for the function according to task description.","answer":"Calculate geometric properties of a circle given its radius.\n\nArgs:\n    radius: The radius of the circle\n\nReturns:\n    A dictionary containing calculated properties with keys:\n        - 'area': The area of the circle\n        - 'circumference': The circumference of the circle\n        - 'diameter': The diameter of the circle\n\nRaises:\n    ValueError: If radius is not a positive number\n\nExample:\n    >>> calculate_circle_properties(5.0)\n    {'area': 78.53981633974483, 'circumference': 31.41592653589793, 'diameter': 10.0}","context":"def calculate_circle_properties(radius: float) -> dict[str, float]:\n    import math\n    if radius <= 0:\n        raise ValueError(\"Radius must be a positive number\")\n    return {\n        'area': math.pi * radius ** 2,\n        'circumference': 2 * math.pi * radius,\n        'diameter': 2 * radius\n    }"}
{"question":"Provide the documentation for the function according to task description.","answer":"Count word frequencies in a text string.\n\nArgs:\n    text: The input text to analyze for word frequencies\n\nReturns:\n    A dictionary mapping each word to its frequency count in the text\n\nExample:\n    >>> count_word_frequencies(\"Hello world! Hello everyone.\")\n    {'hello': 2, 'world': 1, 'everyone': 1}","context":"def count_word_frequencies(text: str) -> dict[str, int]:\n    words = text.lower().split()\n    frequencies = {}\n    for word in words:\n        cleaned_word = word.strip('.,!?;:\"')\n        if cleaned_word:\n            frequencies[cleaned_word] = frequencies.get(cleaned_word, 0) + 1\n    return frequencies"}
{"question":"Provide the documentation for the function according to task description.","answer":"Filter a list using a predicate function.\n\nArgs:\n    items: List of items to filter\n    predicate: Function that returns True for items to include\n\nRaises:\n    TypeError: If predicate is not callable\n\nReturns:\n    A new list containing only items that satisfy the predicate condition\n\nExample:\n    >>> numbers = [1, 2, 3, 4, 5]\n    >>> filter_list_by_predicate(numbers, lambda x: x % 2 == 0)\n    [2, 4]","context":"from typing import List, TypeVar\n\nT = TypeVar('T')\n\ndef filter_list_by_predicate(items: List[T], predicate: callable) -> List[T]:\n    if not callable(predicate):\n        raise TypeError(\"Predicate must be a callable function\")\n    return [item for item in items if predicate(item)]"}
{"question":"Provide the documentation for the function according to task description.","answer":"Validate an email address format using regular expression.\n\nArgs:\n    email: The email address to validate\n\nReturns:\n    True if the email matches the validation pattern, False otherwise\n\nExample:\n    >>> validate_email_address(\"user@example.com\")\n    True\n    >>> validate_email_address(\"invalid.email@\")\n    False","context":"from typing import Any\nimport re\n\ndef validate_email_address(email: str) -> bool:\n    pattern = r'^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$'\n    return bool(re.fullmatch(pattern, email))"}
{"question":"Provide the documentation for the function according to task description.","answer":"Convert datetime string between timezones.\n\nArgs:\n    datetime_str: ISO 8601 formatted string to convert\n    from_tz: Source timezone name\n    to_tz: Target timezone name\n\nReturns:\n    Converted datetime string in ISO 8601 format\n\nRaises:\n    ValueError: If input datetime format is invalid or timezone is unknown\n\nExample:\n    >>> convert_timezone('2023-01-01T12:00:00', 'Europe\/London', 'Asia\/Tokyo')\n    '2023-01-01T21:00:00+09:00'","context":"def convert_timezone(datetime_str: str, from_tz: str, to_tz: str) -> str:\n    from datetime import datetime\n    import pytz\n    try:\n        naive_dt = datetime.fromisoformat(datetime_str)\n    except ValueError:\n        raise ValueError(\"Invalid datetime format, use ISO 8601\")\n    try:\n        from_zone = pytz.timezone(from_tz)\n    except pytz.UnknownTimeZoneError:\n        raise ValueError(f\"Unknown timezone: {from_tz}\")\n    try:\n        to_zone = pytz.timezone(to_tz)\n    except pytz.UnknownTimeZoneError:\n        raise ValueError(f\"Unknown timezone: {to_tz}\")\n    localized_dt = from_zone.localize(naive_dt)\n    converted_dt = localized_dt.astimezone(to_zone)\n    return converted_dt.isoformat()"}
{"question":"Provide the documentation for the function according to task description.","answer":"Read CSV file and convert rows to dictionaries.\n\nArgs:\n    file_path: Path to the CSV file\n    delimiter: Character used to separate fields. Defaults to ','\n    has_header: Whether the first row contains headers. Defaults to True\n\nReturns:\n    List of dictionaries where each dictionary represents a row, with keys from headers or generated column names\n\nRaises:\n    FileNotFoundError: If the specified file does not exist\n\nExample:\n    >>> read_csv_to_dict('data.csv')\n    [{'name': 'Alice', 'age': '30'}, {'name': 'Bob', 'age': '25'}]\n    \n    >>> read_csv_to_dict('no_header.csv', has_header=False)\n    [{'col0': 'Alice', 'col1': '30'}, {'col0': 'Bob', 'col1': '25'}]","context":"import csv\n\ndef read_csv_to_dict(file_path: str, delimiter: str = ',', has_header: bool = True) -> list[dict[str, str]]:\n    try:\n        with open(file_path, 'r', newline='') as f:\n            reader = csv.reader(f, delimiter=delimiter)\n            rows = list(reader)\n    except FileNotFoundError:\n        raise FileNotFoundError(f\"File not found: {file_path}\")\n    \n    if not rows:\n        return []\n    \n    headers = rows[0] if has_header else [f'col{i}' for i in range(len(rows[0]))]\n    start_index = 1 if has_header else 0\n    return [dict(zip(headers, row)) for row in rows[start_index:]]"}
{"question":"Provide the documentation for the function according to task description.","answer":"Read CSV file and return its contents as a list of dictionaries.\n\nArgs:\n    file_path: Path to the CSV file\n    delimiter: Character used to separate fields. Defaults to ','\n    encoding: Text encoding for the file. Defaults to 'utf-8'\n\nReturns:\n    List of dictionaries where each dictionary represents a row with column headers as keys and row values as strings\n\nRaises:\n    ValueError: If the specified file cannot be found\n    RuntimeError: If there's an error parsing the CSV content\n\nExample:\n    >>> read_csv_to_dicts('data.csv')\n    [{'Name': 'Alice', 'Age': '30'}, {'Name': 'Bob', 'Age': '25'}]","context":"import csv\nfrom typing import List, Dict\n\ndef read_csv_to_dicts(file_path: str, delimiter: str = ',', encoding: str = 'utf-8') -> List[Dict[str, str]]:\n    try:\n        with open(file_path, 'r', encoding=encoding) as f:\n            reader = csv.DictReader(f, delimiter=delimiter)\n            return [row for row in reader]\n    except FileNotFoundError:\n        raise ValueError(f\"File not found: {file_path}\")\n    except csv.Error as e:\n        raise RuntimeError(f\"CSV parsing error: {str(e)}\")"}
{"question":"Provide the documentation for the function according to task description.","answer":"Filter dictionaries from a list where specified key meets minimum value.\n\nArgs:\n    data: List of dictionaries to filter\n    key: Key to check in each dictionary\n    min_value: Minimum threshold value for the specified key\n\nReturns:\n    Filtered list of dictionaries containing only entries where key value >= min_value\n\nRaises:\n    KeyError: If any dictionary in the input list is missing the specified key\n\nExample:\n    >>> data = [{'score': 4.5}, {'score': 3.8}, {'score': 4.0}]\n    >>> filter_dicts_by_value(data, 'score', 4.0)\n    [{'score': 4.5}, {'score': 4.0}]","context":"def filter_dicts_by_value(data: list[dict], key: str, min_value: float) -> list[dict]:\n    import sys\n    if not all(key in d for d in data):\n        raise KeyError(f\"Key '{key}' missing from one or more dictionaries\")\n    return [item for item in data if item[key] >= min_value]"}
{"question":"Provide the documentation for the function according to task description.","answer":"Read a value from a JSON file using the specified key.\n\nArgs:\n    file_path: Path to the JSON file\n    key: Key to look up in the JSON data\n    default: Value to return if key is not found (defaults to None)\n\nReturns:\n    Value associated with the key or default if key not found. Type matches JSON data or default type\n\nRaises:\n    FileNotFoundError: If specified file does not exist\n    ValueError: If file contains invalid JSON format\n\nExample:\n    >>> read_json_key('config.json', 'timeout', 30)\n    30","context":"import json\nfrom typing import Any\n\ndef read_json_key(file_path: str, key: str, default: Any = None) -> Any:\n    try:\n        with open(file_path, 'r') as f:\n            data = json.load(f)\n        return data.get(key, default)\n    except FileNotFoundError:\n        raise FileNotFoundError(f\"File {file_path} not found\")\n    except json.JSONDecodeError:\n        raise ValueError(\"Invalid JSON format\")"}
{"question":"Provide the documentation for the function according to task description.","answer":"Calculate the entropy of a list of numerical data.\n\nArgs:\n    data: List of numerical values to calculate entropy for\n    base: Logarithm base to use (default: 2.0)\n\nReturns:\n    Entropy value in the specified base\n\nRaises:\n    ValueError: If input data is empty\n    ValueError: If base is less than or equal to 0\n\nExample:\n    >>> calculate_entropy([1.0, 2.0, 2.0, 3.0])\n    1.5","context":"def calculate_entropy(data: list[float], base: float = 2.0) -> float:\n    from collections import Counter\n    import math\n    \n    if not data:\n        raise ValueError(\"Input data cannot be empty\")\n    if base <= 0:\n        raise ValueError(\"Base must be greater than 0\")\n    \n    counts = Counter(data)\n    total = len(data)\n    probabilities = [count \/ total for count in counts.values()]\n    entropy = -sum(p * math.log(p, base) for p in probabilities)\n    return entropy"}
{"question":"Provide the documentation for the function according to task description.","answer":"Read and parse a JSONL file into Python dictionaries.\n\nProcesses each non-empty line of the file as a separate JSON object.\n\nArgs:\n    file_path: Path to the JSONL file to read\n    encoding: Text encoding to use for file reading (default: 'utf-8')\n\nReturns:\n    List of parsed JSON objects as dictionaries\n\nRaises:\n    RuntimeError: If file cannot be found or JSON parsing fails\n\nExample:\n    >>> data = read_jsonl('data.jsonl')\n    >>> print(len(data))","context":"def read_jsonl(file_path: str, encoding: str = 'utf-8') -> list[dict]:\n    import json\n    try:\n        with open(file_path, 'r', encoding=encoding) as f:\n            return [json.loads(line.strip()) for line in f if line.strip()]\n    except (FileNotFoundError, json.JSONDecodeError) as e:\n        raise RuntimeError(f\"Failed to read JSONL: {str(e)}\") from e"}
{"question":"Provide the documentation for the function according to task description.","answer":"Decorate a function to enforce rate limiting.\n\nAllows up to `max_calls` invocations within any sliding `period` second window. When\nthe rate limit is exceeded, calls will sleep until the oldest call exits the time\nwindow.\n\nArgs:\n    max_calls: Maximum number of allowed calls within the time period\n    period: Length of the rate limiting window in seconds\n\nReturns:\n    A decorator that applies rate limiting to the wrapped function\n\nExample:\n    >>> @rate_limited(max_calls=5, period=10)\n    ... def api_call():\n    ...     # Implementation would go here","context":"import time\nfrom functools import wraps\nfrom typing import Callable\n\ndef rate_limited(max_calls: int, period: float) -> Callable:\n    def decorator(func: Callable) -> Callable:\n        timestamps = []\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            nonlocal timestamps\n            now = time.time()\n            timestamps = [t for t in timestamps if t > now - period]\n            if len(timestamps) >= max_calls:\n                sleep_time = timestamps[0] + period - now\n                time.sleep(sleep_time)\n            result = func(*args, **kwargs)\n            timestamps.append(time.time())\n            return result\n        return wrapper\n    return decorator"}
{"question":"Provide the documentation for the function according to task description.","answer":"Validate a phone number against international and US format specifications.\n\nArgs:\n    number: Phone number string to validate. Leading\/trailing whitespace is ignored\n\nReturns:\n    True if the number matches valid phone number patterns, False otherwise\n\nRaises:\n    ValueError: If input is not a string\n\nExample:\n    >>> validate_phone_number(\"+123456789012345\")\n    True\n    >>> validate_phone_number(\"(555) 123-4567\")\n    True\n    >>> validate_phone_number(\"invalid\")\n    False\n\nNotes:\n    - Validates E.164 international format (optional '+' followed by 1-15 digits)\n    - Validates common US formats with optional parentheses, hyphens, dots or spaces","context":"import re\n\ndef validate_phone_number(number: str) -> bool:\n    pattern = r'^\\+?[1-9]\\d{1,14}$|^\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4}$'\n    if not isinstance(number, str):\n        raise ValueError(\"Input must be a string\")\n    return bool(re.fullmatch(pattern, number.strip()))"}
{"question":"Provide the documentation for the function according to task description.","answer":"Parse a date string using multiple possible formats.\n\nAttempts to parse the input string using each format in the provided list until a\nvalid match is found. Default formats are [\"%Y-%m-%d\", \"%d\/%m\/%Y\"].\n\nArgs:\n    date_str: String representation of date to parse\n    formats: List of format strings to try (defaults to YYYY-MM-DD and DD\/MM\/YYYY)\n\nReturns:\n    datetime object representing the parsed date\n\nRaises:\n    ValueError: If no format in the list successfully parses the date string\n\nExample:\n    >>> parse_date_string(\"2023-10-05\")\n    datetime.datetime(2023, 10, 5, 0, 0)\n    >>> parse_date_string(\"05\/10\/2023\", [\"%d\/%m\/%Y\"])\n    datetime.datetime(2023, 10, 5, 0, 0)","context":"from datetime import datetime\n\ndef parse_date_string(date_str: str, formats: list[str] = [\"%Y-%m-%d\", \"%d\/%m\/%Y\"]) -> datetime:\n    for fmt in formats:\n        try:\n            return datetime.strptime(date_str, fmt)\n        except ValueError:\n            continue\n    raise ValueError(f\"Date string '{date_str}' doesn't match any supported formats: {formats}\")"}
{"question":"Provide the documentation for the function according to task description.","answer":"Calculate the age based on birthdate.\n\nArgs:\n    birthdate: Date of birth to calculate age from\n\nReturns:\n    Integer representing age in years\n\nRaises:\n    ValueError: If birthdate is in the future\n\nExample:\n    >>> from datetime import date\n    >>> calculate_age(date(1990, 5, 15))  # assuming today is 2024-05-20\n    34","context":"from datetime import date\n\ndef calculate_age(birthdate: date) -> int:\n    today = date.today()\n    if birthdate > today:\n        raise ValueError(\"Birthdate cannot be in the future\")\n    age = today.year - birthdate.year\n    if (today.month, today.day) < (birthdate.month, birthdate.day):\n        age -= 1\n    return age"}
{"question":"Provide the documentation for the function according to task description.","answer":"Parse an ISO 8601 formatted datetime string with timezone handling.\n\nArgs:\n    datetime_str: String containing ISO formatted datetime\n    default_tz: Optional timezone to use if input string lacks timezone information\n\nReturns:\n    Timezone-aware datetime object (either parsed from string or using default_tz)\n\nRaises:\n    ValueError: If input string is not valid ISO format\n\nExample:\n    >>> parse_iso_datetime('2023-01-01T12:00', default_tz=timezone.utc)\n    datetime.datetime(2023, 1, 1, 12, 0, tzinfo=datetime.timezone.utc)","context":"from datetime import datetime, timezone\nfrom typing import Optional\n\ndef parse_iso_datetime(datetime_str: str, default_tz: Optional[timezone] = None) -> datetime:\n    try:\n        dt = datetime.fromisoformat(datetime_str)\n    except ValueError as e:\n        raise ValueError(f\"Invalid ISO format string: {datetime_str}\") from e\n    if dt.tzinfo is None:\n        return dt.replace(tzinfo=default_tz)\n    return dt"}
{"question":"Provide the documentation for the function according to task description.","answer":"Read lines from a gzipped file.\n\nArgs:\n    file_path: Path to the gzipped file\n\nYields:\n    Stripped strings from each line in the file\n\nRaises:\n    ValueError: If file is not a valid gzip file\n    FileNotFoundError: If the specified file does not exist\n\nExample:\n    >>> for line in read_gzipped_lines('data.txt.gz'):\n    ...     print(line)","context":"from typing import Generator\nimport gzip\n\ndef read_gzipped_lines(file_path: str) -> Generator[str, None, None]:\n    try:\n        with gzip.open(file_path, 'rt') as f:\n            for line in f:\n                yield line.strip()\n    except gzip.BadGzipFile:\n        raise ValueError(\"File is not a valid gzip file\")\n    except FileNotFoundError:\n        raise"}
{"question":"Provide the documentation for the function according to task description.","answer":"Calculate the moving average of a dataset using a specified window size.\n\nArgs:\n    data: List of numeric values to process\n    window_size: Number of consecutive elements to average in each window\n\nReturns:\n    List containing moving averages for each valid window position\n\nRaises:\n    ValueError: If window size is not positive\n    ValueError: If data length is smaller than window size\n\nExample:\n    >>> calculate_moving_average([1.0, 2.0, 3.0, 4.0], 2)\n    [1.5, 2.5, 3.5]","context":"def calculate_moving_average(data: list[float], window_size: int) -> list[float]:\n    if window_size <= 0:\n        raise ValueError(\"Window size must be positive\")\n    if len(data) < window_size:\n        raise ValueError(\"Insufficient data points for window size\")\n    return [sum(data[i:i+window_size])\/window_size for i in range(len(data)-window_size+1)]"}
{"question":"Provide the documentation for the function according to task description.","answer":"Calculate the percentile rank of a value within a dataset.\n\nArgs:\n    data: Dataset of numerical values\n    value: Value to calculate percentile rank for\n    decimal_places: Number of decimal places to round result (None returns unrounded value)\n\nReturns:\n    Percentile rank as float between 0-100\n\nRaises:\n    ValueError: If dataset is empty or decimal_places is negative\n\nExample:\n    >>> calculate_percentile_rank([1, 2, 3, 4], 3)\n    75.0\n    >>> calculate_percentile_rank([5, 1, 7], 5, None)\n    66.66666666666666","context":"from typing import Optional, List\n\ndef calculate_percentile_rank(data: List[float], value: float, decimal_places: Optional[int] = 2) -> float:\n    if not data:\n        raise ValueError(\"Dataset cannot be empty\")\n    if decimal_places is not None and decimal_places < 0:\n        raise ValueError(\"Decimal places must be non-negative\")\n    \n    sorted_data = sorted(data)\n    count = sum(1 for x in sorted_data if x <= value)\n    percentile = (count \/ len(sorted_data)) * 100\n    \n    if decimal_places is None:\n        return percentile\n    return round(percentile, decimal_places)"}
{"question":"Provide the documentation for the function according to task description.","answer":"Read CSV file into a list of dictionaries.\n\nArgs:\n    file_path: Path to the CSV file\n    delimiter: Field delimiter character. Defaults to ','\n    has_header: Whether the CSV contains a header row. Defaults to True\n\nReturns:\n    List of dictionaries where keys are column headers and values are row data\n\nRaises:\n    FileNotFoundError: If the specified file does not exist\n    ValueError: If CSV parsing fails due to invalid format\n\nExample:\n    >>> data = read_csv_to_dicts('data.csv')\n    >>> data = read_csv_to_dicts('data.csv', has_header=False)","context":"import csv\nfrom typing import List, Dict\n\ndef read_csv_to_dicts(file_path: str, delimiter: str = ',', has_header: bool = True) -> List[Dict[str, str]]:\n    try:\n        with open(file_path, 'r', newline='') as f:\n            reader = csv.reader(f, delimiter=delimiter)\n            if has_header:\n                headers = next(reader)\n            else:\n                headers = [f'col_{i}' for i in range(len(next(reader)))]\n                f.seek(0)\n            return [dict(zip(headers, row)) for row in reader]\n    except FileNotFoundError:\n        raise\n    except csv.Error as e:\n        raise ValueError(f\"CSV parsing error: {str(e)}\") from e"}
{"question":"Provide the documentation for the function according to task description.","answer":"Calculate the number of business days between two dates.\n\nExcludes weekends (Saturday and Sunday) and specified holidays. Dates are adjusted to the given timezone if provided.\n\nArgs:\n    start: Start datetime (inclusive)\n    end: End datetime (inclusive)\n    holidays: List of non-business days to exclude. Defaults to empty list\n    timezone: Optional timezone name to convert datetimes before calculation. Defaults to None\n\nReturns:\n    Number of business days between start and end (inclusive)\n\nRaises:\n    ValueError: If start date occurs after end date\n\nExample:\n    >>> start = datetime(2023, 10, 1)  # Sunday\n    >>> end = datetime(2023, 10, 7)    # Saturday\n    >>> holidays = [datetime(2023, 10, 2)]  # Monday\n    >>> calculate_business_days(start, end, holidays, timezone='UTC')\n    4","context":"from datetime import datetime, timedelta\nfrom typing import List, Optional\nimport pytz\n\ndef calculate_business_days(start: datetime, end: datetime, holidays: List[datetime] = [], timezone: Optional[str] = None) -> int:\n    if start > end:\n        raise ValueError(\"Start date must be before end date\")\n    \n    if timezone:\n        tz = pytz.timezone(timezone)\n        start = start.astimezone(tz)\n        end = end.astimezone(tz)\n    \n    current = start\n    count = 0\n    \n    while current <= end:\n        if current.weekday() < 5 and current not in holidays:\n            count += 1\n        current += timedelta(days=1)\n    \n    return count"}
{"question":"Provide the documentation for the function according to task description.","answer":"Selective reverse a string while preserving specified characters.\n\nReverses the order of characters in a string while keeping specified characters in their\noriginal positions. Non-preserved characters are reversed in order while preserved\ncharacters maintain their original positions.\n\nArgs:\n    s: The input string to process\n    preserve_chars: Characters to preserve in original positions. Case handling depends\n        on case_sensitive parameter. Defaults to empty tuple\n    case_sensitive: Whether to consider character case when preserving. Defaults to True\n\nReturns:\n    The modified string with non-preserved characters reversed\n\nRaises:\n    TypeError: If preserve_chars is not an iterable\n\nExample:\n    >>> selective_reverse('abc123def', preserve_chars=('1','2','3'))\n    'fed123cba'\n    >>> selective_reverse('aBcDeF', preserve_chars=('B','D'), case_sensitive=False)\n    'FeDcBa'","context":"from typing import Iterable\n\ndef selective_reverse(s: str, preserve_chars: Iterable[str] = (), case_sensitive: bool = True) -> str:\n    if not isinstance(preserve_chars, Iterable):\n        raise TypeError(\"preserve_chars must be an iterable\")\n    preserved = set(preserve_chars) if case_sensitive else {c.lower() for c in preserve_chars}\n    buffer = [c for c in s if (c if case_sensitive else c.lower()) not in preserved]\n    buffer.reverse()\n    result = []\n    idx = 0\n    for char in s:\n        if (char if case_sensitive else char.lower()) in preserved:\n            result.append(char)\n        else:\n            result.append(buffer[idx])\n            idx += 1\n    return ''.join(result)"}
{"question":"Provide the documentation for the function according to task description.","answer":"Calculate CRC-32 checksum for given data using polynomial division.\n\nArgs:\n    data: Input bytes to compute checksum for\n    polynomial: CRC polynomial to use (defaults to standard CRC-32 polynomial 0xEDB88320)\n\nReturns:\n    Computed 32-bit checksum as integer\n\nExample:\n    >>> calculate_checksum(b'hello world')\n    222957957\n    >>> calculate_checksum(b'data', polynomial=0x04C11DB7)\n    1815237614","context":"def calculate_checksum(data: bytes, polynomial: int = 0xEDB88320) -> int:\n    crc = 0xFFFFFFFF\n    for byte in data:\n        crc ^= byte\n        for _ in range(8):\n            crc = (crc >> 1) ^ (polynomial & -(crc & 1))\n    return crc ^ 0xFFFFFFFF"}
{"question":"Provide the documentation for the function according to task description.","answer":"Format a Unix timestamp into a timezone-aware datetime string.\n\nArgs:\n    seconds: Unix timestamp in seconds\n    timezone: Timezone name (e.g. 'US\/Pacific') using pytz conventions, defaults to UTC\n\nReturns:\n    String formatted as 'YYYY-MM-DD HH:MM:SS Timezone'\n\nRaises:\n    pytz.exceptions.UnknownTimeZoneError: If invalid timezone is provided\n\nExample:\n    >>> format_timestamp(0, 'UTC')\n    '1970-01-01 00:00:00 UTC'","context":"def format_timestamp(seconds: float, timezone: str = 'UTC') -> str:\n    from datetime import datetime, timezone as tz, timedelta\n    import pytz\n    base_time = datetime.fromtimestamp(seconds, tz=tz.utc)\n    return base_time.astimezone(pytz.timezone(timezone)).strftime('%Y-%m-%d %H:%M:%S %Z')"}
{"question":"Provide the documentation for the function according to task description.","answer":"Yield items in batches of specified size.\n\nArgs:\n    items: List of items to batch\n    batch_size: Number of items per batch. Defaults to 10\n\nYields:\n    List containing current batch of items\n\nRaises:\n    ValueError: If batch_size is not positive\n\nExample:\n    >>> items = [1, 2, 3, 4, 5]\n    >>> for batch in batch_process(items, 2):\n    ...     print(batch)\n    [1, 2]\n    [3, 4]\n    [5]","context":"from typing import Generator\n\ndef batch_process(items: list, batch_size: int = 10) -> Generator[list, None, None]:\n    if batch_size <= 0:\n        raise ValueError(\"Batch size must be positive\")\n    for i in range(0, len(items), batch_size):\n        yield items[i:i + batch_size]"}
{"question":"Provide the documentation for the function according to task description.","answer":"Fetch JSON data from a URL asynchronously with retry logic.\n\nArgs:\n    url: URL to fetch JSON data from\n    timeout: Maximum request timeout duration in seconds (default: 5.0)\n    retries: Number of retry attempts after initial failure (default: 2)\n\nReturns:\n    Parsed JSON data from the response\n\nRaises:\n    aiohttp.ClientError: If request fails after all retries due to client-side errors\n    TimeoutError: If request times out after all retries\n\nExample:\n    >>> async def example():\n    ...     data = await async_fetch_json('https:\/\/api.example.com\/data', retries=3)\n    ...     return data","context":"async def async_fetch_json(url: str, timeout: float = 5.0, retries: int = 2):\n    import aiohttp\n    from asyncio import sleep\n    for attempt in range(retries + 1):\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=timeout)) as session:\n                async with session.get(url) as response:\n                    return await response.json()\n        except (aiohttp.ClientError, TimeoutError):\n            if attempt == retries:\n                raise\n            await sleep(1.5 ** attempt)"}
{"question":"Provide the documentation for the function according to task description.","answer":"Parse a date string using multiple possible formats.\n\nAttempts to parse the input string using various datetime formats. Tries each\nformat in order until a successful parse is achieved. Uses default formats\nif none are provided.\n\nArgs:\n    date_str: String representing a date to parse\n    formats: Optional list of format strings to try (uses default formats if None)\n\nReturns:\n    Parsed datetime object\n\nRaises:\n    ValueError: If the date string doesn't match any supported format\n\nExample:\n    >>> parse_date('2023-10-05')\n    datetime.datetime(2023, 10, 5, 0, 0)\n    >>> parse_date('10\/05\/2023', ['%m\/%d\/%Y'])","context":"def parse_date(date_str: str, formats: list[str] | None = None) -> datetime:\n    from datetime import datetime\n    from typing import Optional\n    default_formats = ['%Y-%m-%d', '%d\/%m\/%Y', '%m\/%d\/%Y']\n    for fmt in formats or default_formats:\n        try:\n            return datetime.strptime(date_str, fmt)\n        except ValueError:\n            continue\n    raise ValueError(f\"Date string '{date_str}' doesn't match any supported formats\")"}
{"question":"Provide the documentation for the function according to task description.","answer":"Calculate percentiles for a dataset using linear interpolation.\n\nArgs:\n    data: List of numerical values to analyze\n    percentiles: List of percentile values to compute (0-100)\n\nReturns:\n    Dictionary mapping percentile values to computed results\n\nRaises:\n    ValueError: If input data is empty or percentiles are outside 0-100 range\n\nExample:\n    >>> calculate_percentiles([1, 2, 3, 4], [25.0, 50.0, 75.0])\n    {25.0: 1.75, 50.0: 2.5, 75.0: 3.25}","context":"def calculate_percentiles(data: list[float], percentiles: list[float]) -> dict[float, float]:\n    if not data:\n        raise ValueError(\"Data cannot be empty\")\n    if any(p < 0 or p > 100 for p in percentiles):\n        raise ValueError(\"Percentiles must be between 0 and 100\")\n    sorted_data = sorted(data)\n    n = len(sorted_data)\n    results = {}\n    for p in percentiles:\n        index = (p\/100) * (n - 1)\n        lower = int(index)\n        fraction = index - lower\n        if lower == n - 1:\n            results[p] = sorted_data[-1]\n        else:\n            results[p] = sorted_data[lower] + fraction * (sorted_data[lower+1] - sorted_data[lower])\n    return results"}
{"question":"Provide the documentation for the function according to task description.","answer":"Count the number of lines in a file.\n\nArgs:\n    filename: Path to the file to count lines in\n\nReturns:\n    Number of lines in the file\n\nRaises:\n    FileNotFoundError: If the specified file does not exist\n    RuntimeError: If there's an error reading the file\n\nExample:\n    >>> count_file_lines('data.txt')\n    3","context":"def count_file_lines(filename: str) -> int:\n    try:\n        with open(filename, 'r') as f:\n            return len(f.readlines())\n    except FileNotFoundError:\n        raise\n    except IOError as e:\n        raise RuntimeError(f\"File read error: {e}\") from e"}
{"question":"Provide the documentation for the function according to task description.","answer":"Read a specific key from a JSON file.\n\nArgs:\n    file_path: Path to the JSON file\n    key: Key to retrieve from the JSON data\n\nReturns:\n    The value associated with the requested key\n\nRaises:\n    FileNotFoundError: If the specified file does not exist\n    KeyError: If the specified key is not found in the JSON file\n\nExample:\n    >>> read_json_key('config.json', 'api_key')","context":"import json\nfrom typing import Any\n\ndef read_json_key(file_path: str, key: str) -> Any:\n    try:\n        with open(file_path, 'r', encoding='utf-8') as f:\n            data = json.load(f)\n            return data[key]\n    except FileNotFoundError:\n        raise FileNotFoundError(f\"File {file_path} not found\")\n    except KeyError:\n        raise KeyError(f\"Key '{key}' not found in JSON file\")"}
{"question":"Provide the documentation for the function according to task description.","answer":"Calculate a simple moving average using a sliding window of fixed size.\n\nArgs:\n    values: List of numerical values to process\n    window: Size of the moving window (must be positive and <= values length)\n\nReturns:\n    List of moving averages where each element is the average of window consecutive values\n\nRaises:\n    ValueError: If window size is invalid (<=0 or larger than input length)\n\nExample:\n    >>> calculate_moving_average([1.0, 2.0, 3.0, 4.0], 2)\n    [1.5, 2.5, 3.5]","context":"def calculate_moving_average(values: list[float], window: int) -> list[float]:\n    if window <= 0 or window > len(values):\n        raise ValueError(\"Invalid window size\")\n    \n    return [sum(values[i:i+window])\/window for i in range(len(values)-window+1)]"}
{"question":"Provide the documentation for the function according to task description.","answer":"Generate batches of items from an iterable.\n\nArgs:\n    data: Input iterable to batch\n    batch_size: Size of each batch\n\nRaises:\n    ValueError: If batch_size is not a positive integer\n\nYields:\n    Lists of items from the input data, each of size batch_size (last batch may be smaller)\n\nExample:\n    >>> data = [1, 2, 3, 4, 5]\n    >>> for batch in batch_generator(data, 2):\n    ...     print(batch)\n    [1, 2]\n    [3, 4]\n    [5]","context":"from typing import Iterable\n\ndef batch_generator(data: Iterable, batch_size: int):\n    if batch_size <= 0:\n        raise ValueError(\"Batch size must be positive\")\n    batch = []\n    for item in data:\n        batch.append(item)\n        if len(batch) == batch_size:\n            yield batch\n            batch = []\n    if batch:\n        yield batch"}
{"question":"Provide the documentation for the function according to task description.","answer":"Read CSV file into a list of dictionaries.\n\nArgs:\n    file_path: Path to the CSV file\n    delimiter: Field delimiter character (default ',')\n    has_header: Flag indicating if first row contains headers (default True)\n\nReturns:\n    List of dictionaries where keys are column headers and values are strings\n\nRaises:\n    FileNotFoundError: If specified file does not exist\n    ValueError: If any row has inconsistent column count\n\nExample:\n    >>> data = read_csv_to_dicts('data.csv')\n    >>> # For CSV with header \"name,age\" and row \"Alice,30\"\n    >>> # Returns [{'name': 'Alice', 'age': '30'}]","context":"import os\nfrom typing import List, Dict\n\ndef read_csv_to_dicts(file_path: str, delimiter: str = ',', has_header: bool = True) -> List[Dict[str, str]]:\n    if not os.path.exists(file_path):\n        raise FileNotFoundError(f\"File {file_path} not found\")\n    \n    with open(file_path, 'r') as f:\n        lines = [line.strip() for line in f.readlines()]\n    \n    if not lines:\n        return []\n    \n    headers = lines[0].split(delimiter) if has_header else [f\"col_{i}\" for i in range(len(lines[0].split(delimiter)))]\n    results = []\n    \n    for line in lines[1 if has_header else 0:]:\n        values = line.split(delimiter)\n        if len(values) != len(headers):\n            raise ValueError(\"Column count mismatch in CSV row\")\n        results.append(dict(zip(headers, values)))\n    \n    return results"}
{"question":"Provide the documentation for the function according to task description.","answer":"Calculate average values for groups in a dataset.\n\nArgs:\n    data: List of dictionaries containing grouping and value data\n    group_key: Key in the dictionaries used to group items\n    value_key: Key in the dictionaries whose values will be averaged\n\nReturns:\n    Dictionary mapping group keys to their calculated averages\n\nRaises:\n    KeyError: If any data item is missing the specified group_key or value_key\n\nExample:\n    >>> data = [\n    ...     {'group': 'X', 'value': 10},\n    ...     {'group': 'X', 'value': 20},\n    ...     {'group': 'Y', 'value': 5}\n    ... ]\n    >>> calculate_group_averages(data, 'group', 'value')\n    {'X': 15.0, 'Y': 5.0}","context":"from typing import List, Dict\nfrom collections import defaultdict\n\ndef calculate_group_averages(data: List[Dict[str, float]], group_key: str, value_key: str) -> Dict[str, float]:\n    grouped = defaultdict(list)\n    for item in data:\n        if group_key not in item or value_key not in item:\n            raise KeyError(f\"Missing required key in data item: {item}\")\n        grouped[item[group_key]].append(item[value_key])\n    return {k: sum(v)\/len(v) for k, v in grouped.items()}"}
{"question":"Provide the documentation for the function according to task description.","answer":"Fetch URL content with retry mechanism for failed requests.\n\nArgs:\n    url: URL to fetch\n    retries: Number of retry attempts. Defaults to 3.\n    timeout: Timeout in seconds for each request. Defaults to 5.0.\n    backoff: Backoff multiplier between attempts. Defaults to 1.5.\n\nReturns:\n    The response text content\n\nRaises:\n    ConnectionError: If all retry attempts fail\n\nExample:\n    >>> import asyncio\n    >>> asyncio.run(fetch_with_retry('https:\/\/example.com'))","context":"import aiohttp\nimport asyncio\nfrom typing import Awaitable\n\nasync def fetch_with_retry(url: str, retries: int = 3, timeout: float = 5.0, backoff: float = 1.5) -> str:\n    async with aiohttp.ClientSession() as session:\n        for attempt in range(retries):\n            try:\n                async with session.get(url, timeout=timeout) as response:\n                    response.raise_for_status()\n                    return await response.text()\n            except (aiohttp.ClientError, asyncio.TimeoutError) as e:\n                if attempt == retries - 1:\n                    raise ConnectionError(f\"Failed after {retries} attempts: {str(e)}\")\n                await asyncio.sleep(backoff * (attempt + 1))\n        raise RuntimeError(\"Unexpected error in retry logic\")"}
{"question":"Provide the documentation for the function according to task description.","answer":"Calculate the moving average over a specified window.\n\nArgs:\n    data: List of numerical values to process\n    window_size: Size of the averaging window\n\nReturns:\n    List of averaged values for each valid window position\n\nRaises:\n    ValueError: If window_size is not positive or exceeds data length\n\nExample:\n    >>> calculate_moving_average([1.0, 2.0, 3.0, 4.0], 2)\n    [1.5, 2.5, 3.5]","context":"def calculate_moving_average(data: list[float], window_size: int) -> list[float]:\n    if window_size <= 0:\n        raise ValueError(\"Window size must be positive\")\n    if window_size > len(data):\n        raise ValueError(\"Insufficient data points for window size\")\n    return [sum(data[i:i+window_size])\/window_size for i in range(len(data)-window_size+1)]"}
{"question":"Provide the documentation for the function according to task description.","answer":"Read a large CSV file in manageable chunks to avoid memory overload.\n\nArgs:\n    filepath: Path to the CSV file\n    chunk_size: Number of rows per chunk (default 1000)\n\nReturns:\n    Iterator yielding lists of dictionaries where each dictionary represents a row\n\nRaises:\n    FileNotFoundError: If specified file cannot be found\n\nExample:\n    >>> for chunk in read_large_csv('big_data.csv'):\n    ...     process_data(chunk)","context":"import csv\nfrom typing import Iterator\n\ndef read_large_csv(filepath: str, chunk_size: int = 1000) -> Iterator[list[dict]]:\n    try:\n        with open(filepath, 'r', newline='') as f:\n            reader = csv.DictReader(f)\n            chunk = []\n            for row in reader:\n                chunk.append(row)\n                if len(chunk) == chunk_size:\n                    yield chunk\n                    chunk = []\n            if chunk:\n                yield chunk\n    except FileNotFoundError:\n        raise FileNotFoundError(f\"File {filepath} not found\") from None"}
{"question":"Provide the documentation for the function according to task description.","answer":"Rename files in a directory with sequential numbering.\n\nArgs:\n    directory: Target directory containing files to rename\n    prefix: New filename prefix to use for all files\n    extension: File extension to use for renamed files. Defaults to \"txt\"\n\nReturns:\n    Number of files successfully renamed\n\nRaises:\n    NotADirectoryError: If the provided directory path is invalid\n\nExample:\n    >>> batch_rename_files(\"\/path\/to\/files\", \"archive_\", \"log\")","context":"def batch_rename_files(directory: str, prefix: str, extension: str = \"txt\") -> int:\n    import os\n    import shutil\n    if not os.path.isdir(directory):\n        raise NotADirectoryError(f\"{directory} is not a valid directory\")\n    count = 0\n    for filename in os.listdir(directory):\n        src = os.path.join(directory, filename)\n        if os.path.isfile(src):\n            new_name = f\"{prefix}{count}.{extension}\"\n            dest = os.path.join(directory, new_name)\n            shutil.move(src, dest)\n            count += 1\n    return count"}
{"question":"Provide the documentation for the function according to task description.","answer":"Parse a URL query string into a dictionary of parameter lists.\n\nValidates that the query string starts with '?' character. Uses urllib.parse.parse_qs\nto split parameters into lists of values.\n\nArgs:\n    query: Query string to parse (must start with '?')\n\nReturns:\n    Dictionary mapping parameter names to lists of string values\n\nRaises:\n    ValueError: If input string doesn't start with '?'\n\nExample:\n    >>> parse_query_string('?name=John&age=30')\n    {'name': ['John'], 'age': ['30']}","context":"def parse_query_string(query: str) -> dict[str, list[str]]:\n    from urllib.parse import parse_qs\n    if not query.startswith('?'):\n        raise ValueError(\"Query string must start with '?'\")\n    return parse_qs(query[1:])"}
{"question":"Provide the documentation for the function according to task description.","answer":"Calculate time slots between start and end times at specified intervals.\n\nArgs:\n    start: Starting datetime of the time slots\n    end: Ending datetime (exclusive upper bound)\n    interval: Time difference between consecutive slots\n\nReturns:\n    List of datetime objects representing generated time slots\n\nRaises:\n    ValueError: If start time is not before end time\n\nExample:\n    >>> start = datetime(2023, 1, 1, 9, 0)\n    >>> end = datetime(2023, 1, 1, 10, 0)\n    >>> calculate_time_slots(start, end, timedelta(minutes=30))\n    [datetime(2023, 1, 1, 9, 0), datetime(2023, 1, 1, 9, 30)]","context":"from datetime import datetime, timedelta\n\ndef calculate_time_slots(start: datetime, end: datetime, interval: timedelta) -> List[datetime]:\n    if start >= end:\n        raise ValueError(\"Start time must be before end time\")\n    \n    slots = []\n    current = start\n    while current < end:\n        slots.append(current)\n        current += interval\n    return slots"}
{"question":"Provide the documentation for the function according to task description.","answer":"Calculate the confidence interval for a dataset using z-score method.\n\nArgs:\n    data: List of numerical values\n    confidence_level: Confidence level between 0.9 and 0.99 (default: 0.95)\n\nReturns:\n    Lower and upper bounds of the confidence interval rounded to 3 decimals\n\nRaises:\n    ValueError: If data is empty or confidence level is not between 0.9 and 0.99\n\nExample:\n    >>> calculate_confidence_interval([2.5, 3.0, 3.5], 0.95)\n    (2.434, 3.566)","context":"from math import sqrt\nfrom typing import List\nfrom statistics import mean, stdev\n\ndef calculate_confidence_interval(data: List[float], confidence_level: float = 0.95) -> tuple[float, float]:\n    if not data:\n        raise ValueError(\"Cannot calculate confidence interval for empty dataset\")\n    if confidence_level < 0.9 or confidence_level > 0.99:\n        raise ValueError(\"Confidence level must be between 0.9 and 0.99\")\n    \n    n = len(data)\n    z = {0.9: 1.645, 0.95: 1.96, 0.99: 2.576}[confidence_level]\n    sample_mean = mean(data)\n    sample_stdev = stdev(data)\n    margin = z * (sample_stdev \/ sqrt(n))\n    return (round(sample_mean - margin, 3), round(sample_mean + margin, 3))"}
{"question":"Provide the documentation for the function according to task description.","answer":"Calculate the percentile value from a list of numerical data using linear interpolation.\n\nArgs:\n    data: List of numerical values to calculate percentile from\n    percentile: The percentile to calculate (0-100 inclusive)\n\nReturns:\n    The calculated percentile value as a float\n\nRaises:\n    ValueError: If input data is empty or percentile is outside 0-100 range\n\nExample:\n    >>> calculate_percentile([1, 2, 3, 4, 5], 50)\n    3.0","context":"from typing import List\n\ndef calculate_percentile(data: List[float], percentile: float) -> float:\n    if not data:\n        raise ValueError(\"Input data cannot be empty\")\n    if not (0 <= percentile <= 100):\n        raise ValueError(\"Percentile must be between 0 and 100\")\n    \n    sorted_data = sorted(data)\n    index = (len(sorted_data) - 1) * percentile \/ 100\n    lower = int(index)\n    fraction = index - lower\n    \n    if lower == len(sorted_data) - 1:\n        return sorted_data[-1]\n    \n    return sorted_data[lower] * (1 - fraction) + sorted_data[lower + 1] * fraction"}
{"question":"Provide the documentation for the function according to task description.","answer":"Calculate the simple moving average of a data series.\n\nArgs:\n    values: List of numerical values to process\n    window_size: Size of the moving window to calculate averages\n\nReturns:\n    List of moving averages with length len(values) - window_size + 1\n\nRaises:\n    ValueError: If window size is not positive\n    ValueError: If window size exceeds the number of data points\n\nExample:\n    >>> calculate_moving_average([1.0, 2.0, 3.0, 4.0], 2)\n    [1.5, 2.5, 3.5]","context":"from typing import List\n\ndef calculate_moving_average(values: List[float], window_size: int) -> List[float]:\n    if window_size <= 0:\n        raise ValueError(\"Window size must be positive\")\n    if len(values) < window_size:\n        raise ValueError(\"Window size exceeds data length\")\n    \n    return [\n        sum(values[i:i+window_size]) \/ window_size\n        for i in range(len(values) - window_size + 1)\n    ]"}
{"question":"Provide the documentation for the function according to task description.","answer":"Merge two dictionaries recursively with optional overwrite control.\n\nArgs:\n    base: Base dictionary that will be updated\n    update: Dictionary containing values to merge\n    overwrite: Whether to overwrite existing keys in base (default: False)\n\nReturns:\n    New dictionary containing merged values from both inputs\n\nExample:\n    >>> base = {'a': 1, 'b': {'x': 2}}\n    >>> update = {'b': {'y': 3}, 'c': 4}\n    >>> merge_dictionaries(base, update)\n    {'a': 1, 'b': {'x': 2, 'y': 3}, 'c': 4}\n    >>> merge_dictionaries(base, update, True)\n    {'a': 1, 'b': {'y': 3}, 'c': 4}","context":"def merge_dictionaries(base: dict, update: dict, overwrite: bool = False) -> dict:\n    merged = base.copy()\n    for key, value in update.items():\n        if key in merged and isinstance(merged[key], dict) and isinstance(value, dict):\n            merged[key] = merge_dictionaries(merged[key], value, overwrite)\n        else:\n            if overwrite or key not in merged:\n                merged[key] = value\n    return merged"}
{"question":"Provide the documentation for the function according to task description.","answer":"Merge two JSON files into a single output file.\n\nArgs:\n    input_path1: Path to first input JSON file\n    input_path2: Path to second input JSON file\n    output_path: Path where merged JSON will be written\n    merge_strategy: Determines how key conflicts are resolved ('overwrite' or 'combine').\n        'combine' merges lists or creates list of values. Defaults to 'overwrite'\n\nRaises:\n    FileNotFoundError: If either input file cannot be found\n\nReturns:\n    None\n\nExample:\n    >>> merge_json_files('data1.json', 'data2.json', 'merged.json', merge_strategy='combine')\n\nWhen merge_strategy is 'combine':\n- If both values are lists, they are merged\n- If values are different types, they are combined into a list\n- Non-list values are combined into a two-element list\nResult is written to the specified output path.","context":"import json\n\ndef merge_json_files(input_path1: str, input_path2: str, output_path: str, merge_strategy: str = 'overwrite') -> None:\n    try:\n        with open(input_path1, 'r') as f1:\n            data1 = json.load(f1)\n        with open(input_path2, 'r') as f2:\n            data2 = json.load(f2)\n    except FileNotFoundError as e:\n        raise FileNotFoundError(f\"Missing input file: {e.filename}\") from e\n    \n    merged = data1.copy()\n    for key in data2:\n        if key in merged and merge_strategy == 'combine':\n            if isinstance(merged[key], list) and isinstance(data2[key], list):\n                merged[key].extend(data2[key])\n            else:\n                merged[key] = [merged[key], data2[key]]\n        else:\n            merged[key] = data2[key]\n    \n    with open(output_path, 'w') as f:\n        json.dump(merged, f, indent=2)"}
{"question":"Provide the documentation for the function according to task description.","answer":"Calculate the percentile value from a dataset using specified interpolation method.\n\nArgs:\n    data: Dataset of float values\n    percentile: Percentile to compute between 0 and 100\n    method: Interpolation method to use ('linear' or 'nearest'). Defaults to 'linear'\n\nReturns:\n    The calculated percentile value\n\nRaises:\n    ValueError: If input data is empty or percentile is not in [0, 100] range\n\nExample:\n    >>> calculate_percentile([10.0, 20.0, 30.0, 40.0], 25)\n    17.5\n    >>> calculate_percentile([10.0, 20.0, 30.0, 40.0], 25, 'nearest')\n    20.0","context":"def calculate_percentile(data: list[float], percentile: float, method: str = 'linear') -> float:\n    if not data:\n        raise ValueError(\"Input data cannot be empty\")\n    if percentile < 0 or percentile > 100:\n        raise ValueError(\"Percentile must be between 0 and 100\")\n    \n    sorted_data = sorted(data)\n    n = len(sorted_data)\n    index = (percentile \/ 100) * (n - 1)\n    \n    if method == 'nearest':\n        return sorted_data[round(index)]\n    else:\n        lower = int(index \/\/ 1)\n        upper = lower + 1\n        weight = index - lower\n        if upper >= n:\n            return sorted_data[lower]\n        return sorted_data[lower] * (1 - weight) + sorted_data[upper] * weight"}
{"question":"Provide the documentation for the function according to task description.","answer":"Check if a string matches all provided regular expression patterns.\n\nArgs:\n    text: String to validate\n    patterns: List of regular expression patterns to match against\n\nReturns:\n    True if text matches all patterns using fullmatch, False otherwise\n\nRaises:\n    ValueError: If any pattern is invalid regex syntax\n\nExample:\n    >>> validate_string_with_patterns(\"test123\", [\"test.*\", \".*123\"])\n    True\n    >>> validate_string_with_patterns(\"test\", [\"test$\", \"[a-z]+\"])\n    True\n    >>> validate_string_with_patterns(\"test123\", [\"test\", \"123\"])\n    False","context":"from typing import List\nimport re\n\ndef validate_string_with_patterns(text: str, patterns: List[str]) -> bool:\n    for pattern in patterns:\n        try:\n            if not re.fullmatch(pattern, text):\n                return False\n        except re.error:\n            raise ValueError(f\"Invalid regex pattern: {pattern}\")\n    return True"}
{"question":"Provide the documentation for the function according to task description.","answer":"Validate a file's header signature and size limit.\n\nArgs:\n    file_path: Path to the file to validate\n    expected_header: Expected byte sequence at the start of the file\n    size_limit: Maximum allowed file size in bytes (default 1MB)\n\nReturns:\n    True if file has matching header and is under size limit, False otherwise\n\nRaises:\n    RuntimeError: If file access fails during validation\n\nExample:\n    >>> validate_file_signature('data.bin', b'PK\\x03\\x04', 2_097_152)","context":"def validate_file_signature(file_path: str, expected_header: bytes, size_limit: int = 1048576) -> bool:\n    try:\n        with open(file_path, 'rb') as f:\n            header = f.read(len(expected_header))\n            if header != expected_header:\n                return False\n            f.seek(0, 2)\n            file_size = f.tell()\n            return file_size <= size_limit\n    except IOError as e:\n        raise RuntimeError(f\"File validation failed: {str(e)}\") from e"}
{"question":"Provide the documentation for the function according to task description.","answer":"Calculate the age in years based on birthdate and reference date.\n\nArgs:\n    birthdate: Date of birth\n    as_of: Reference date for calculation. Defaults to current datetime if None\n\nReturns:\n    Integer representing age in years\n\nRaises:\n    ValueError: If birthdate is after the reference date\n\nExample:\n    >>> birth = datetime(2000, 5, 15)\n    >>> calculate_age(birth, datetime(2024, 5, 14))\n    23\n    >>> calculate_age(birth, datetime(2024, 5, 16))\n    24","context":"from datetime import datetime\n\ndef calculate_age(birthdate: datetime, as_of: datetime | None = None) -> int:\n    reference_date = as_of or datetime.now()\n    if birthdate > reference_date:\n        raise ValueError(\"Birthdate cannot be in the future\")\n    age = reference_date.year - birthdate.year\n    if (reference_date.month, reference_date.day) < (birthdate.month, birthdate.day):\n        age -= 1\n    return age"}
{"question":"Provide the documentation for the function according to task description.","answer":"Generate a secure random password.\n\nArgs:\n    length: Length of the password (minimum 8). Defaults to 12\n\nReturns:\n    Generated password containing letters, digits, and punctuation\n\nRaises:\n    ValueError: If length is less than 8\n\nExample:\n    >>> generate_password()\n    'hG4@kL9!vZq3'\n    >>> generate_password(10)\n    'dR5%fT7^Y2'","context":"def generate_password(length: int = 12) -> str:\n    import secrets\n    import string\n    if length < 8:\n        raise ValueError(\"Password length must be at least 8\")\n    characters = string.ascii_letters + string.digits + string.punctuation\n    return ''.join(secrets.choice(characters) for _ in range(length))"}
{"question":"Provide the documentation for the function according to task description.","answer":"Group a list of dictionaries by a specified key.\n\nArgs:\n    items: List of dictionaries to group\n    key: Key to group by\n\nRaises:\n    KeyError: If any item is missing the specified key\n\nReturns:\n    Dictionary mapping key values to lists of corresponding items\n\nExample:\n    >>> items = [{'id': 1, 'category': 'A'}, {'id': 2, 'category': 'B'}, {'id': 3, 'category': 'A'}]\n    >>> group_by_key(items, 'category')\n    {'A': [{'id': 1, 'category': 'A'}, {'id': 3, 'category': 'A'}], 'B': [{'id': 2, 'category': 'B'}]}","context":"from collections import defaultdict\nfrom typing import List, Dict, Any\n\ndef group_by_key(items: List[Dict[str, Any]], key: str) -> Dict[Any, List[Dict[str, Any]]]:\n    if not all(key in item for item in items):\n        raise KeyError(f\"Missing '{key}' in one or more items\")\n    groups = defaultdict(list)\n    for item in items:\n        groups[item[key]].append(item)\n    return dict(groups)"}
{"question":"Provide the documentation for the function according to task description.","answer":"Filter a list of dictionaries based on numeric values in a specified key.\n\nArgs:\n    data: List of dictionaries to filter\n    target_key: Key in dictionaries to check for numeric values\n    min_value: Optional minimum allowed value (inclusive)\n    max_value: Optional maximum allowed value (inclusive)\n\nReturns:\n    List of dictionaries where target_key's value meets the numeric criteria\n\nRaises:\n    KeyError: If target_key is not present in any dictionary\n    TypeError: If target_key's value is not numeric\n\nExample:\n    >>> data = [{'id': 1, 'score': 85}, {'id': 2, 'score': 105}]\n    >>> filter_numeric_values(data, 'score', min_value=90, max_value=100)\n    [{'id': 1, 'score': 85}]","context":"def filter_numeric_values(data: list[dict], target_key: str, min_value: float = None, max_value: float = None) -> list[dict]:\n    filtered = []\n    for item in data:\n        if target_key not in item:\n            raise KeyError(f\"Key '{target_key}' not found in dictionary\")\n        value = item[target_key]\n        if not isinstance(value, (int, float)):\n            raise TypeError(\"Target value must be numeric\")\n        if min_value is not None and value < min_value:\n            continue\n        if max_value is not None and value > max_value:\n            continue\n        filtered.append(item)\n    return filtered"}
{"question":"Provide the documentation for the function according to task description.","answer":"Calculate age based on birthdate and optional reference date.\n\nArgs:\n    birthdate: Date of birth in specified format\n    date_format: Format string for dates (defaults to YYYY-MM-DD)\n    reference_date: Optional date to calculate age at (uses current date if not provided)\n\nReturns:\n    The calculated age in years as an integer\n\nRaises:\n    ValueError: If date parsing fails or birthdate is in the future\n\nExample:\n    >>> calculate_age(\"1990-07-15\")\n    33\n    >>> calculate_age(\"15\/07\/1990\", \"%d\/%m\/%Y\", \"31\/10\/2023\")\n    33","context":"def calculate_age(birthdate: str, date_format: str = \"%Y-%m-%d\", reference_date: str | None = None) -> int:\n    from datetime import datetime\n    try:\n        birth = datetime.strptime(birthdate, date_format)\n        ref_date = datetime.now() if not reference_date else datetime.strptime(reference_date, date_format)\n        if birth > ref_date:\n            raise ValueError(\"Birthdate cannot be in the future\")\n        return (ref_date - birth).days \/\/ 365\n    except ValueError as e:\n        raise ValueError(f\"Invalid date format: {str(e)}\") from e"}
{"question":"Provide the documentation for the function according to task description.","answer":"Calculate the average age of users.\n\nArgs:\n    users: List of user dictionaries containing 'age' keys\nReturns:\n    Average age as a floating-point number\nRaises:\n    ValueError: If the user list is empty\n    ValueError: If any age is negative\nExample:\n    >>> users = [{'age': 25}, {'age': 30}]\n    >>> calculate_average_age(users)\n    27.5","context":"def calculate_average_age(users: list[dict[str, int]]) -> float:\n    if not users:\n        raise ValueError(\"User list cannot be empty\")\n    ages = [u['age'] for u in users]\n    if any(age < 0 for age in ages):\n        raise ValueError(\"Ages cannot be negative\")\n    return sum(ages) \/ len(users)"}
{"question":"Provide the documentation for the function according to task description.","answer":"Check if a string is a palindrome after removing non-alphanumeric characters and ignoring case.\n\nArgs:\n    s: String to check for palindrome property\n\nReturns:\n    True if the cleaned string is a palindrome, False otherwise\n\nRaises:\n    TypeError: If input is not a string\n\nExample:\n    >>> is_palindrome(\"A man, a plan, a canal: Panama\")\n    True\n    >>> is_palindrome(\"hello123\")\n    False","context":"import re\n\ndef is_palindrome(s: str) -> bool:\n    if not isinstance(s, str):\n        raise TypeError(\"Input must be a string\")\n    cleaned = re.sub(r'[^\\w]', '', s).lower()\n    return cleaned == cleaned[::-1]"}
{"question":"Provide the documentation for the function according to task description.","answer":"Parse a datetime string and ensure it has timezone information.\n\nParses various datetime string formats using dateutil.parser. If no timezone\ninformation is detected in the input string, UTC timezone is added.\n\nArgs:\n    dt_str: String representing a datetime in any recognizable format\n\nReturns:\n    datetime object with timezone information (UTC if none was present)\n\nRaises:\n    ValueError: If input string cannot be parsed as valid datetime\n\nExample:\n    >>> parse_datetime_with_timezone(\"2023-07-15 14:30\")\n    datetime.datetime(2023, 7, 15, 14, 30, tzinfo=<UTC>)\n    >>> parse_datetime_with_timezone(\"2023-07-15T14:30-05:00\")\n    datetime.datetime(2023, 7, 15, 14, 30, tzinfo=tzoffset(None, -18000))","context":"from datetime import datetime\nfrom dateutil.parser import parse\nfrom pytz import UTC\n\ndef parse_datetime_with_timezone(dt_str: str) -> datetime:\n    try:\n        dt = parse(dt_str)\n        if dt.tzinfo is None:\n            return dt.replace(tzinfo=UTC)\n        return dt\n    except ValueError as e:\n        raise ValueError(f\"Invalid datetime format: {dt_str}\") from e"}
{"question":"Provide the documentation for the function according to task description.","answer":"Read CSV file and return its contents as a list of dictionaries.\n\nEach dictionary represents a row in the CSV file, with headers as keys\nand string values for all fields.\n\nArgs:\n    file_path: Path to the CSV file to read\n\nReturns:\n    List of dictionaries where each dictionary represents a CSV row,\n    with headers as keys and string values\n\nRaises:\n    ValueError: If the specified file cannot be found\n    ValueError: If a CSV parsing error occurs\n\nExample:\n    >>> data = read_csv_to_dicts('data.csv')\n    >>> print(data[0]['column_name'])  # Access first row's column value","context":"import csv\nfrom typing import List, Dict\n\ndef read_csv_to_dicts(file_path: str) -> List[Dict[str, str]]:\n    try:\n        with open(file_path, 'r', newline='') as f:\n            reader = csv.DictReader(f)\n            return [row for row in reader]\n    except FileNotFoundError:\n        raise ValueError(f\"File {file_path} not found\")\n    except csv.Error as e:\n        raise ValueError(f\"CSV parsing error: {str(e)}\")"}
{"question":"Provide the documentation for the function according to task description.","answer":"Read CSV file and return data as list of dictionaries.\n\nArgs:\n    file_path: Path to CSV file\n    delimiter: Field delimiter character\n    has_headers: Whether the CSV contains header row\n\nReturns:\n    List of dictionaries where each dict represents a row with column names as keys.\n    Uses 'col_1', 'col_2' etc as keys when no headers present.\n\nRaises:\n    FileNotFoundError: If specified file path doesn't exist\n\nExample:\n    >>> read_csv_to_dicts('data.csv')\n    [{'header1': 'value1', 'header2': 'value2'}]\n\n    >>> read_csv_to_dicts('data.csv', has_headers=False)\n    [{'col_1': 'value1', 'col_2': 'value2'}]","context":"import csv\n\ndef read_csv_to_dicts(file_path: str, delimiter: str = ',', has_headers: bool = True) -> list[dict[str, str]]:\n    try:\n        with open(file_path, 'r') as f:\n            reader = csv.DictReader(f, delimiter=delimiter) if has_headers else csv.reader(f, delimiter=delimiter)\n            if has_headers:\n                return list(reader)\n            headers = [f'col_{i+1}' for i in range(len(next(reader)))]\n            f.seek(0)\n            return [dict(zip(headers, row)) for row in csv.reader(f, delimiter=delimiter)]\n    except FileNotFoundError:\n        raise FileNotFoundError(f\"File {file_path} not found\")"}
{"question":"Provide the documentation for the function according to task description.","answer":"Read CSV file and convert to list of dictionaries.\n\nParses CSV file using first row as headers. Each row becomes a dictionary\nwith header-value pairs.\n\nArgs:\n    file_path: Path to the CSV file\n    delimiter: Character used to separate fields (default: ',')\n\nReturns:\n    List of dictionaries where each represents a CSV row, with keys\n    from the header row\n\nRaises:\n    FileNotFoundError: If specified file path does not exist\n    ValueError: If CSV parsing fails due to invalid format\n\nExample:\n    >>> data = read_csv_to_dicts('data.csv')\n    >>> print(data[0]['column_name'])","context":"def read_csv_to_dicts(file_path: str, delimiter: str = ',') -> list[dict[str, str]]:\n    import csv\n    try:\n        with open(file_path, 'r', newline='') as f:\n            return list(csv.DictReader(f, delimiter=delimiter))\n    except FileNotFoundError:\n        raise FileNotFoundError(f\"CSV file not found at {file_path}\") from None\n    except csv.Error as e:\n        raise ValueError(f\"CSV parsing error: {str(e)}\") from None"}
{"question":"Provide the documentation for the function according to task description.","answer":"Calculate BMI using weight and height.\n\nArgs:\n    weight_kg: Weight in kilograms\n    height_m: Height in meters\n\nReturns:\n    BMI value as a float\n\nRaises:\n    ValueError: If height is zero or negative","context":"def calculate_bmi(weight_kg: float, height_m: float) -> float:\n    if height_m <= 0:\n        raise ValueError(\"Height must be positive\")\n    return weight_kg \/ (height_m ** 2)"}
{"question":"Provide the documentation for the function according to task description.","answer":"Validate a password against security requirements.\n\nArgs:\n    password: The password string to validate\n    min_length: Minimum required password length (default: 8)\n    require_special: Require at least one special character (default: True)\n\nReturns:\n    True if password meets all requirements, False otherwise\n\nExample:\n    >>> validate_password('SecurePass123!')\n    True\n    >>> validate_password('weak', min_length=6)\n    False","context":"def validate_password(password: str, min_length: int = 8, require_special: bool = True) -> bool:\n    import re\n    if len(password) < min_length:\n        return False\n    if require_special and not re.search(r'[!@#$%^&*(),.?\":{}|<>]', password):\n        return False\n    if not re.search(r'\\d', password):\n        return False\n    return True"}
{"question":"Provide the documentation for the function according to task description.","answer":"Count the number of lines in a file.\n\nArgs:\n    file_path: Path to the file to count lines in\n    encoding: Text encoding to use when reading the file\n\nReturns:\n    Total number of lines in the file\n\nRaises:\n    FileNotFoundError: If the specified file cannot be found\n    ValueError: If the file contains invalid characters for the specified encoding\n\nExample:\n    >>> count_file_lines('data.txt')\n    42","context":"def count_file_lines(file_path: str, encoding: str = 'utf-8') -> int:\n    try:\n        with open(file_path, 'r', encoding=encoding) as f:\n            return sum(1 for line in f)\n    except FileNotFoundError:\n        raise FileNotFoundError(f\"File {file_path} not found\") from None\n    except UnicodeDecodeError:\n        raise ValueError(\"File contains invalid characters for encoding\") from None"}
{"question":"Provide the documentation for the function according to task description.","answer":"Parse ISO 8601 duration string into component time parts.\n\nArgs:\n    duration_str: ISO 8601 duration string to parse\n\nReturns:\n    Dictionary containing duration components with integer values (years, months, days, hours, minutes, seconds)\n\nRaises:\n    ValueError: If input string does not match ISO 8601 duration format\n\nExample:\n    >>> parse_iso8601_duration(\"P3Y6M4DT12H30M5S\")\n    {'years': 3, 'months': 6, 'days': 4, 'hours': 12, 'minutes': 30, 'seconds': 5}","context":"def parse_iso8601_duration(duration_str: str) -> dict[str, int]:\n    from datetime import timedelta\n    import re\n    \n    pattern = r\"P(?:(\\d+)Y)?(?:(\\d+)M)?(?:(\\d+)D)?T(?:(\\d+)H)?(?:(\\d+)M)?(?:(\\d+)S)?\"\n    match = re.fullmatch(pattern, duration_str)\n    if not match:\n        raise ValueError(\"Invalid ISO 8601 duration format\")\n    \n    parts = match.groups()\n    return {\n        \"years\": int(parts[0]) if parts[0] else 0,\n        \"months\": int(parts[1]) if parts[1] else 0,\n        \"days\": int(parts[2]) if parts[2] else 0,\n        \"hours\": int(parts[3]) if parts[3] else 0,\n        \"minutes\": int(parts[4]) if parts[4] else 0,\n        \"seconds\": int(parts[5]) if parts[5] else 0\n    }"}
{"question":"Provide the documentation for the function according to task description.","answer":"Calculate age based on birthdate and reference date.\n\nArgs:\n    birthdate: Date of birth\n    as_of: Reference date for calculation. Defaults to today's date\n\nReturns:\n    Integer age in years\n\nRaises:\n    ValueError: If reference date is earlier than birthdate\n\nExample:\n    >>> from datetime import date\n    >>> calculate_age(date(2000, 7, 15), date(2023, 3, 20))\n    22\n    >>> calculate_age(date(2000, 7, 15), date(2023, 8, 1))\n    23","context":"from datetime import date\n\ndef calculate_age(birthdate: date, as_of: date = date.today()) -> int:\n    if as_of < birthdate:\n        raise ValueError(\"As_of date cannot be before birthdate\")\n    age = as_of.year - birthdate.year\n    if (as_of.month, as_of.day) < (birthdate.month, birthdate.day):\n        age -= 1\n    return age"}
{"question":"Provide the documentation for the function according to task description.","answer":"Check if the given email address is valid.\n\nArgs:\n    email: Email address to validate\n\nReturns:\n    True if the email is valid, False otherwise\n\nRaises:\n    TypeError: If input is not a string\n\nExample:\n    >>> is_valid_email('user@example.com')\n    True\n    >>> is_valid_email('invalid.email')\n    False","context":"import re\n\ndef is_valid_email(email: str) -> bool:\n    if not isinstance(email, str):\n        raise TypeError(\"Input must be a string\")\n    pattern = r'^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$'\n    return bool(re.fullmatch(pattern, email))"}
{"question":"Provide the documentation for the function according to task description.","answer":"Read CSV file into a list of dictionaries.\n\nArgs:\n    file_path: Path to the CSV file\n    delimiter: Optional field delimiter (default is comma)\n\nReturns:\n    List of dictionaries where keys are field names and values are row data as strings\n\nRaises:\n    ValueError: If the specified file cannot be found\n\nExample:\n    >>> data = read_csv_to_dicts('data.csv')\n    >>> tab_data = read_csv_to_dicts('data.tsv', delimiter='\\t')","context":"import csv\nfrom typing import List, Dict\n\ndef read_csv_to_dicts(file_path: str, delimiter: str = ',') -> List[Dict[str, str]]:\n    try:\n        with open(file_path, 'r', newline='') as f:\n            reader = csv.DictReader(f, delimiter=delimiter)\n            return [row for row in reader]\n    except FileNotFoundError:\n        raise ValueError(f\"File {file_path} not found\")"}
{"question":"Provide the documentation for the function according to task description.","answer":"Validate text against multiple regular expression patterns.\n\nArgs:\n    text: Input text to validate\n    patterns: List of regular expressions to match against the text\n\nReturns:\n    True if text matches all patterns, False otherwise\n\nRaises:\n    ValueError: If any pattern is an invalid regular expression\n\nExample:\n    >>> validate_string_patterns(\"Password123\", [r\"\\d\", r\"[a-z]\"])\n    True\n    >>> validate_string_patterns(\"PASSWORD\", [r\"[a-z]\"])\n    False","context":"import re\nfrom typing import List\n\ndef validate_string_patterns(text: str, patterns: List[str]) -> bool:\n    for pattern in patterns:\n        try:\n            compiled = re.compile(pattern)\n            if not compiled.search(text):\n                return False\n        except re.error:\n            raise ValueError(f\"Invalid regex pattern: {pattern}\")\n    return True"}
{"question":"Provide the documentation for the function according to task description.","answer":"Calculate the moving average of a list using a specified window size.\n\nArgs:\n    values: List of numerical values to process\n    window_size: Size of the averaging window. Must be positive and not exceed input length\n\nReturns:\n    List containing moving averages for each valid window position\n\nRaises:\n    ValueError: If window_size is not positive or exceeds input length\n\nExample:\n    >>> calculate_moving_average([1.0, 2.0, 3.0, 4.0], 2)\n    [1.5, 2.5, 3.5]","context":"from typing import List\n\ndef calculate_moving_average(values: List[float], window_size: int) -> List[float]:\n    if window_size <= 0 or window_size > len(values):\n        raise ValueError(\"Invalid window size\")\n    return [sum(values[i:i+window_size])\/window_size \n            for i in range(len(values)-window_size+1)]"}
{"question":"Provide the documentation for the function according to task description.","answer":"Fetch user data from an API endpoint with retry logic.\n\nRetrieves user data from the specified URL. Implements exponential backoff retry\nmechanism for handling HTTP errors and timeouts.\n\nArgs:\n    url: Base API endpoint URL\n    user_id: ID of the user to retrieve\n    max_retries: Maximum number of retry attempts (default: 3)\n    backoff_factor: Multiplier for exponential backoff delay (default: 0.5)\n\nReturns:\n    Dictionary containing user data from the response\n\nRaises:\n    HTTPError: If HTTP request fails after all retries\n    Timeout: If request times out after all retries\n    RuntimeError: If unexpected error occurs in retry logic\n\nExample:\n    >>> fetch_user_data('https:\/\/api.example.com', 42, max_retries=2)\n    {'id': 42, 'username': 'example_user'}","context":"import requests\nimport time\nfrom requests.exceptions import HTTPError, Timeout\n\ndef fetch_user_data(url: str, user_id: int, max_retries: int = 3, backoff_factor: float = 0.5) -> dict:\n    for attempt in range(max_retries + 1):\n        try:\n            response = requests.get(f\"{url}\/users\/{user_id}\", timeout=5)\n            response.raise_for_status()\n            return response.json()\n        except (HTTPError, Timeout) as e:\n            if attempt == max_retries:\n                raise\n            time.sleep(backoff_factor * (2 ** attempt))\n    raise RuntimeError(\"Unexpected error in retry logic\")"}
{"question":"Provide the documentation for the function according to task description.","answer":"Convert a datetime between specified timezones.\n\nArgs:\n    dt: Timezone-aware datetime object to convert\n    from_tz: Source timezone name\n    to_tz: Target timezone name\n\nReturns:\n    Converted datetime object in target timezone\n\nRaises:\n    AttributeError: If naive datetime object is received\n    pytz.exceptions.UnknownTimeZoneError: If invalid timezone name is provided\n\nExample:\n    >>> dt = datetime(2023, 1, 1, 12, 0, tzinfo=pytz.utc)\n    >>> convert_timezone(dt, 'UTC', 'Europe\/Paris')\n    datetime.datetime(2023, 1, 1, 13, 0, tzinfo=<DstTzInfo 'Europe\/Paris' CET+1:00:00 STD>)","context":"import pytz\nfrom datetime import datetime\n\ndef convert_timezone(dt: datetime, from_tz: str, to_tz: str) -> datetime:\n    if dt.tzinfo is None:\n        raise AttributeError(\"Naive datetime object received\")\n    \n    from_zone = pytz.timezone(from_tz)\n    to_zone = pytz.timezone(to_tz)\n    localized_dt = from_zone.localize(dt) if dt.tzinfo is None else dt.astimezone(from_zone)\n    return localized_dt.astimezone(to_zone)"}
{"question":"Provide the documentation for the function according to task description.","answer":"Filter a list of dictionaries based on a key's value range.\n\nArgs:\n    data: List of dictionaries to filter\n    key: Key to check in each dictionary\n    min_val: Minimum allowed value. Defaults to 0.0\n    max_val: Maximum allowed value. Defaults to 100.0\n\nReturns:\n    List[Dict]: Filtered list of dictionaries where key's value is within range\n\nRaises:\n    ValueError: If input data is empty or key is missing in dictionaries\n\nExample:\n    >>> data = [{'temp': 25.6}, {'temp': 32.1}, {'temp': 15.3}]\n    >>> filter_dicts_by_value(data, 'temp', 20.0, 30.0)\n    [{'temp': 25.6}, {'temp': 15.3}]","context":"from typing import List, Dict\n\ndef filter_dicts_by_value(data: List[Dict], key: str, min_val: float = 0.0, max_val: float = 100.0) -> List[Dict]:\n    if not data or key not in data[0]:\n        raise ValueError(\"Invalid data or missing key in dictionaries\")\n    return [d for d in data if min_val <= d.get(key, 0.0) <= max_val]"}
{"question":"Provide the documentation for the function according to task description.","answer":"Generate a checksum for a file using the specified hashing algorithm.\n\nArgs:\n    filepath: Path to the file to checksum\n    algorithm: Hashing algorithm to use (default: 'sha256')\n    chunk_size: Number of bytes to read at a time (default: 8192)\n\nReturns:\n    The hexadecimal digest string of the file's checksum\n\nRaises:\n    FileNotFoundError: If the file does not exist\n    PermissionError: If lacking file access permissions\n    RuntimeError: If any other error occurs during processing\n\nExample:\n    >>> generate_file_checksum('data.txt')\n    'a1b2c3...'\n    >>> generate_file_checksum('large_file.bin', chunk_size=65536)\n    'd4e5f6...'","context":"import hashlib\n\ndef generate_file_checksum(filepath: str, algorithm: str = 'sha256', chunk_size: int = 8192) -> str:\n    hasher = hashlib.new(algorithm)\n    try:\n        with open(filepath, 'rb') as f:\n            while chunk := f.read(chunk_size):\n                hasher.update(chunk)\n        return hasher.hexdigest()\n    except FileNotFoundError:\n        raise\n    except PermissionError:\n        raise\n    except Exception as e:\n        raise RuntimeError(f\"Checksum generation failed: {e}\")"}
{"question":"Provide the documentation for the function according to task description.","answer":"Calculate the percentile value from a list of numerical data.\n\nArgs:\n    data: Numerical data to calculate percentile from\n    percentile: The percentile to calculate (0-100 inclusive)\n\nReturns:\n    The calculated percentile value\n\nRaises:\n    ValueError: If input data is empty or percentile is not between 0 and 100\n\nExample:\n    >>> calculate_percentile([1, 2, 3, 4, 5], 50)\n    3.0","context":"from typing import Union\n\ndef calculate_percentile(data: list[float], percentile: float) -> float:\n    if not data:\n        raise ValueError(\"Input data cannot be empty\")\n    if not (0 <= percentile <= 100):\n        raise ValueError(\"Percentile must be between 0 and 100\")\n    \n    sorted_data = sorted(data)\n    n = len(sorted_data)\n    index = (n - 1) * percentile \/ 100\n    \n    try:\n        import numpy as np\n        return float(np.percentile(sorted_data, percentile))\n    except ImportError:\n        lower = int(index \/\/ 1)\n        upper = lower + 1\n        weight = index % 1\n        if upper >= n:\n            return sorted_data[lower]\n        return sorted_data[lower] * (1 - weight) + sorted_data[upper] * weight"}
{"question":"Provide the documentation for the function according to task description.","answer":"Retry an HTTP request function multiple times with exponential backoff.\n\nArgs:\n    max_retries: Maximum number of retry attempts. Defaults to 3\n    delay: Initial delay between retries in seconds. Defaults to 1.0\n\nReturns:\n    A decorator that wraps the request function with retry logic\n\nRaises:\n    RequestException: If all retries fail due to HTTP errors\n    TimeoutError: If all retries fail due to timeout\n\nExample:\n    >>> @retry_http_request(max_retries=2, delay=0.5)\n    ... def make_api_call(url):\n    ...     response = requests.get(url)\n    ...     response.raise_for_status()\n    ...     return response.json()","context":"import time\nfrom typing import Callable, TypeVar, Optional\nfrom requests.exceptions import RequestException\n\nT = TypeVar('T')\n\ndef retry_http_request(max_retries: int = 3, delay: float = 1.0) -> Callable[[Callable[..., T]], Callable[..., T]]:\n    def decorator(func: Callable[..., T]) -> Callable[..., T]:\n        def wrapper(*args, **kwargs) -> Optional[T]:\n            attempts = 0\n            while attempts <= max_retries:\n                try:\n                    return func(*args, **kwargs)\n                except (RequestException, TimeoutError) as e:\n                    attempts += 1\n                    if attempts > max_retries:\n                        raise\n                    time.sleep(delay * (2 ** attempts))\n            return None\n        return wrapper\n    return decorator"}
{"question":"Provide the documentation for the function according to task description.","answer":"Calculate the cryptographic hash of a file's contents.\n\nArgs:\n    file_path: Path to the file to hash\n    algorithm: Hash algorithm to use (default: sha256)\n\nReturns:\n    Hexadecimal digest string of the file's contents\n\nRaises:\n    FileNotFoundError: If the specified file does not exist\n    ValueError: If the specified algorithm is not supported\n\nExample:\n    >>> calculate_file_hash('data.txt')\n    '9f86d081884c7d659a2feaa0c55ad015a3bf4f1b2b0b822cd15d6c15b0f00a08'\n    >>> calculate_file_hash('image.png', 'md5')\n    'd41d8cd98f00b204e9800998ecf8427e'","context":"import hashlib\n\ndef calculate_file_hash(file_path: str, algorithm: str = \"sha256\") -> str:\n    try:\n        hasher = hashlib.new(algorithm)\n        with open(file_path, 'rb') as f:\n            while chunk := f.read(4096):\n                hasher.update(chunk)\n        return hasher.hexdigest()\n    except FileNotFoundError:\n        raise\n    except ValueError:\n        raise ValueError(f\"Unsupported hash algorithm: {algorithm}\")"}
{"question":"Provide the documentation for the function according to task description.","answer":"Load and parse a JSON file.\n\nArgs:\n    file_path: Path to the JSON file\n\nReturns:\n    Parsed JSON data as list of dictionaries or a single dictionary\n\nRaises:\n    FileNotFoundError: If the specified file does not exist\n    ValueError: If the file contains invalid JSON","context":"import json\nfrom typing import Any\nfrom json import JSONDecodeError\n\ndef load_json_file(file_path: str) -> list[dict[str, Any]] | dict[str, Any]:\n    try:\n        with open(file_path, 'r', encoding='utf-8') as f:\n            return json.load(f)\n    except FileNotFoundError:\n        raise FileNotFoundError(f\"JSON file not found at {file_path}\")\n    except JSONDecodeError:\n        raise ValueError(\"Invalid JSON format in file\")"}
{"question":"Provide the documentation for the function according to task description.","answer":"Calculate age from birthdate to reference date.\n\nArgs:\n    birthdate: Date of birth (must be timezone-aware)\n    reference: Reference date to calculate age at (must be timezone-aware)\n\nReturns:\n    Approximate age in years calculated using days difference (floor division by 365)\n\nRaises:\n    ValueError: If either date lacks timezone information\n    ValueError: If birthdate is after reference date\n\nExample:\n    >>> from datetime import datetime, timezone\n    >>> birth = datetime(2000, 1, 1, tzinfo=timezone.utc)\n    >>> ref = datetime(2020, 1, 1, tzinfo=timezone.utc)\n    >>> calculate_age(birth, ref)\n    20","context":"from datetime import datetime\n\ndef calculate_age(birthdate: datetime, reference: datetime) -> int:\n    if birthdate.tzinfo is None or reference.tzinfo is None:\n        raise ValueError(\"Both dates must be timezone-aware\")\n    if birthdate > reference:\n        raise ValueError(\"Birthdate cannot be in the future\")\n    delta = reference - birthdate\n    return delta.days \/\/ 365"}
{"question":"Provide the documentation for the function according to task description.","answer":"Check if a string is a palindrome.\n\nProcesses the input string by optionally removing non-alphanumeric characters and ignoring case before checking if it reads the same forwards and backwards.\n\nArgs:\n    s: String to check\n    ignore_case: Whether to ignore case differences (default: True)\n    strip_non_alnum: Whether to remove non-alphanumeric characters (default: True)\n\nReturns:\n    True if the processed string is a palindrome, False otherwise\n\nExample:\n    >>> is_palindrome(\"A man, a plan, a canal: Panama\")\n    True\n    >>> is_palindrome(\"RaceCar\", ignore_case=False)\n    False\n    >>> is_palindrome(\"12321!\")\n    True","context":"import re\n\ndef is_palindrome(s: str, ignore_case: bool = True, strip_non_alnum: bool = True) -> bool:\n    processed = s\n    if strip_non_alnum:\n        processed = re.sub(r'[^a-zA-Z0-9]', '', processed)\n    if ignore_case:\n        processed = processed.lower()\n    return processed == processed[::-1]"}
{"question":"Provide the documentation for the function according to task description.","answer":"Calculate aggregated sales totals grouped by a specified key.\n\nIterate through the list of sales records and sum the numeric values identified by `value_key` for each group defined by `group_by`. Raises a `ValueError` if a record is missing required keys or contains an invalid amount value.\n\nArgs:\n    sales: List of sales records, each a dictionary containing arbitrary data\n    group_by: Key used to group records (default \"region\")\n    value_key: Key whose value is summed for each group (default \"amount\")\n\nReturns:\n    Dictionary mapping each group to the total summed amount as a float\n\nRaises:\n    ValueError: If a record is missing the `group_by` or `value_key` keys, or if the amount cannot be converted to a float\n\nExample:\n    >>> sales = [\n    ...     {\"region\": \"North\", \"amount\": 100},\n    ...     {\"region\": \"South\", \"amount\": 150},\n    ...     {\"region\": \"North\", \"amount\": 200}\n    ... ]\n    >>> aggregate_sales(sales)\n    {'North': 300.0, 'South': 150.0}","context":"from typing import Any, Dict, List\n\ndef aggregate_sales(sales: List[Dict[str, Any]], *, group_by: str = \"region\", value_key: str = \"amount\") -> Dict[str, float]:\n    result: Dict[str, float] = {}\n    for record in sales:\n        if group_by not in record or value_key not in record:\n            raise ValueError(f\"Record missing required keys: {record}\")\n        group = str(record[group_by])\n        try:\n            amount = float(record[value_key])\n        except (TypeError, ValueError) as e:\n            raise ValueError(f\"Invalid amount value in record: {record}\") from e\n        result[group] = result.get(group, 0.0) + amount\n    return result"}
{"question":"Provide the documentation for the function according to task description.","answer":"Read a CSV file and return its rows as a list of dictionaries.\n\nArgs:\n    file_path: Path to the CSV file to read\n    delimiter: Character used to separate fields in the CSV. Defaults to ','\n\nReturns:\n    A list of dictionaries mapping column names to their string values for each row\n\nRaises:\n    FileNotFoundError: If the file does not exist at the given path\n    ValueError: If the CSV file is empty or does not contain a header row","context":"def read_csv_to_dicts(file_path: str, delimiter: str = ',') -> list[dict[str, str]]:\n    import csv\n    import os\n    if not os.path.isfile(file_path):\n        raise FileNotFoundError(f\"File not found: {file_path}\")\n    with open(file_path, newline='', encoding='utf-8') as f:\n        reader = csv.DictReader(f, delimiter=delimiter)\n        rows = [row for row in reader]\n    if not rows:\n        raise ValueError(\"CSV file is empty or missing header\")\n    return rows"}
{"question":"Provide the documentation for the function according to task description.","answer":"Fetch JSON data from a given URL.\n\nArgs:\n    url: URL to retrieve JSON from\n    timeout: Number of seconds to wait for the response before timing out (default 5.0)\n\nReturns:\n    Dictionary containing the parsed JSON content\n\nRaises:\n    RuntimeError: If the request fails or the response cannot be decoded as JSON\n\nExample:\n    >>> data = fetch_json(\"https:\/\/api.example.com\/data\")\n    >>> isinstance(data, dict)","context":"import json\nimport requests\nfrom typing import Any\ndef fetch_json(url: str, timeout: float = 5.0) -> dict[str, Any]:\n    try:\n        response = requests.get(url, timeout=timeout)\n        response.raise_for_status()\n    except requests.exceptions.RequestException as exc:\n        raise RuntimeError(f\"Failed to fetch JSON from {url}: {exc}\") from exc\n    try:\n        return response.json()\n    except json.JSONDecodeError as exc:\n        raise RuntimeError(f\"Response from {url} is not valid JSON: {exc}\") from exc"}
{"question":"Provide the documentation for the function according to task description.","answer":"Read a CSV file into a list of dictionaries, optionally selecting a subset of columns.\n\nArgs:\n    path: Path to the CSV file\n    delimiter: Character separating fields in the CSV. Defaults to ','\n    columns: Optional list of column names to include. If provided, only these columns are kept and a ValueError is raised if any are missing\n\nReturns:\n    List of dictionaries representing the rows of the CSV\n\nRaises:\n    FileNotFoundError: If the file does not exist\n    ValueError: If any column in `columns` is not found in the CSV header\n\nExample:\n    >>> rows = read_csv_to_dicts('data.csv', delimiter=';', columns=['id', 'name'])\n    >>> rows[0]['id']\n    '123'","context":"import csv\nfrom typing import List, Dict, Optional, Any\n\ndef read_csv_to_dicts(path: str, delimiter: str = ',', columns: Optional[List[str]] = None) -> List[Dict[str, Any]]:\n    try:\n        with open(path, newline='', encoding='utf-8') as f:\n            reader = csv.DictReader(f, delimiter=delimiter)\n            if columns is not None:\n                missing = set(columns) - set(reader.fieldnames or [])\n                if missing:\n                    raise ValueError(f\"Columns {missing} not found in CSV\")\n            rows: List[Dict[str, Any]] = []\n            for row in reader:\n                if columns:\n                    row = {col: row[col] for col in columns}\n                rows.append(row)\n            return rows\n    except FileNotFoundError:\n        raise"}
{"question":"Provide the documentation for the function according to task description.","answer":"Normalize a phone number to the format \"+1-AAA-BBB-CCCC\".\n\nArgs:\n    number: Phone number string that may contain non-digit characters\n\nReturns:\n    Normalized phone number in the format \"+1-AAA-BBB-CCCC\"\n\nRaises:\n    ValueError: If the cleaned number does not contain exactly 10 digits\n\nExample:\n    >>> normalize_phone_number(\"(123) 456-7890\")\n    '+1-123-456-7890'","context":"from typing import List\nimport re\n\ndef normalize_phone_number(number: str) -> str:\n    digits = re.sub(r'\\D', '', number)\n    if len(digits) == 10:\n        return f\"+1-{digits[:3]}-{digits[3:6]}-{digits[6:]}\"\n    raise ValueError(f\"Phone number '{number}' does not contain exactly 10 digits after cleaning\")"}
{"question":"Provide the documentation for the function according to task description.","answer":"Read a JSON file and return its contents as a dictionary.\n\nArgs:\n    filepath: Path to the JSON file\n    encoding: Encoding to use when reading the file (default \"utf-8\")\n\nReturns:\n    dict[str, Any]: Dictionary containing the parsed JSON data\n\nRaises:\n    FileNotFoundError: If the specified file does not exist\n    ValueError: If the JSON content is not an object\n\nExample:\n    >>> data = read_json_file('config.json')\n    >>> isinstance(data, dict)\n    True","context":"from typing import Any\n\ndef read_json_file(filepath: str, encoding: str = \"utf-8\") -> dict[str, Any]:\n    import json, os\n    if not os.path.isfile(filepath):\n        raise FileNotFoundError(filepath)\n    with open(filepath, \"r\", encoding=encoding) as f:\n        data = json.load(f)\n    if not isinstance(data, dict):\n        raise ValueError(\"JSON content must be an object\")\n    return data"}
{"question":"Provide the documentation for the function according to task description.","answer":"Parse a range of dates into a list of date objects.\n\nArgs:\n    start: Start date as a string.\n    end: End date as a string.\n    fmt: Format string to parse the dates. Defaults to \"%Y-%m-%d\".\n\nReturns:\n    List of `date` objects for each day from start to end inclusive.\n\nRaises:\n    ValueError: If the provided strings do not match the format or if start date is after end date.\n\nExample:\n    >>> parse_date_range(\"2023-01-01\", \"2023-01-05\")\n    [date(2023, 1, 1), date(2023, 1, 2), date(2023, 1, 3), date(2023, 1, 4), date(2023, 1, 5)]","context":"from datetime import datetime, timedelta, date\nfrom typing import List\n\ndef parse_date_range(start: str, end: str, fmt: str = \"%Y-%m-%d\") -> List[date]:\n    try:\n        start_date = datetime.strptime(start, fmt).date()\n        end_date = datetime.strptime(end, fmt).date()\n    except ValueError as e:\n        raise ValueError(f\"Date strings must match format {fmt}\") from e\n    if start_date > end_date:\n        raise ValueError(\"Start date must not be after end date\")\n    delta = (end_date - start_date).days\n    return [start_date + timedelta(days=i) for i in range(delta + 1)]"}
{"question":"Provide the documentation for the function according to task description.","answer":"Read a JSON file and return its contents as a dictionary.\n\nArgs:\n    file_path: Path to the JSON file to read\n\nReturns:\n    A dictionary representing the parsed JSON object\n\nRaises:\n    FileNotFoundError: If the file does not exist or is not a regular file\n    json.JSONDecodeError: If the file contains invalid JSON\n\nExample:\n    >>> data = read_json('config.json')\n    >>> isinstance(data, dict)\n    True","context":"def read_json(file_path: str) -> dict[str, object]:\n    import json\n    import os\n    if not os.path.isfile(file_path):\n        raise FileNotFoundError(f\"File not found: {file_path}\")\n    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n        try:\n            return json.load(f)\n        except json.JSONDecodeError as e:\n            raise json.JSONDecodeError(f\"Invalid JSON in {file_path}\", e.doc, e.pos)"}
{"question":"Provide the documentation for the function according to task description.","answer":"Convert a date-time string to a UTC datetime object.\n\nParse the provided date-time string using the given format and interpret it in the specified timezone, then convert it to UTC.\n\nArgs:\n    dt_str: The date-time string to convert\n    fmt: The format used to parse dt_str. Defaults to \"%Y-%m-%d %H:%M:%S\"\n    tz: The name of the timezone for the input string. Defaults to \"UTC\"\n\nReturns:\n    A timezone-aware datetime object representing the input time in UTC\n\nRaises:\n    RuntimeError: If the python-dateutil package is not installed\n    ValueError: If tz does not correspond to a known timezone\n\nExample:\n    >>> convert_to_utc(\"2023-08-15 12:30:00\", tz=\"America\/New_York\")\n    datetime.datetime(2023, 8, 15, 16, 30, tzinfo=tzutc())","context":"def convert_to_utc(dt_str: str, fmt: str = \"%Y-%m-%d %H:%M:%S\", tz: str = \"UTC\") -> datetime.datetime:\n    import datetime\n    try:\n        from dateutil import tz as dateutil_tz\n    except ImportError as e:\n        raise RuntimeError(\"python-dateutil is required\") from e\n    naive = datetime.datetime.strptime(dt_str, fmt)\n    from_zone = dateutil_tz.gettz(tz)\n    if from_zone is None:\n        raise ValueError(f\"Unknown timezone: {tz}\")\n    aware = naive.replace(tzinfo=from_zone)\n    utc = aware.astimezone(dateutil_tz.UTC)\n    return utc"}
{"question":"Provide the documentation for the function according to task description.","answer":"Sum even numbers in a list.\n\nIterates over the provided list and returns the sum of all elements that are divisible by two.\n\nArgs:\n    numbers: List of integers to process\n\nReturns:\n    The sum of even numbers found in the input list","context":"def sum_even(numbers: list[int]) -> int:\n    total = 0\n    for n in numbers:\n        if n % 2 == 0:\n            total += n\n    return total"}
{"question":"Provide the documentation for the function according to task description.","answer":"Read a CSV file and return its rows as dictionaries.\n\nArgs:\n    file_path: Path to the CSV file to read\n    delimiter: Character used to separate fields in the CSV file (default ',')\n\nReturns:\n    List of dictionaries where each dictionary represents a row with column names as keys and cell values as strings\n\nRaises:\n    FileNotFoundError: If `file_path` does not point to an existing file\n    ValueError: If a CSV parsing error occurs\n\nExample:\n    >>> rows = read_csv_as_dicts('data.csv')\n    >>> rows[0]['name']\n    'Alice'","context":"def read_csv_as_dicts(file_path: str, delimiter: str = ',') -> list[dict[str, str]]:\n    import csv, os\n    if not os.path.isfile(file_path):\n        raise FileNotFoundError(f\"{file_path} does not exist\")\n    with open(file_path, newline='', encoding='utf-8') as f:\n        try:\n            reader = csv.DictReader(f, delimiter=delimiter)\n            return [row for row in reader]\n        except csv.Error as e:\n            raise ValueError(f\"CSV parsing error: {e}\")"}
{"question":"Provide the documentation for the function according to task description.","answer":"Fetch JSON data from a URL with retries and exponential backoff.\n\nArgs:\n    url: The target URL to request JSON from\n    headers: Optional HTTP headers to include in the request\n    timeout: The request timeout in seconds. Defaults to 5.0\n    max_retries: The maximum number of retry attempts on failure. Defaults to 3\n    backoff_factor: The factor used to calculate backoff delay (delay = backoff_factor * 2**(attempt-1)). Defaults to 0.5\n\nReturns:\n    A dictionary representing the parsed JSON response\n\nRaises:\n    ConnectionError: If the request fails after the maximum number of retries\n    ValueError: If the response body cannot be decoded as JSON\n\nExample:\n    >>> data = fetch_json(\n    ...     \"https:\/\/api.example.com\/data\",\n    ...     headers={\"Accept\": \"application\/json\"},\n    ...     timeout=10.0,\n    ...     max_retries=5,\n    ...     backoff_factor=1.0,\n    ... )\n    >>> print(data)  # doctest: +SKIP","context":"import time\nfrom typing import Any, Dict, Optional\nimport requests\nfrom requests.exceptions import RequestException, Timeout\n\ndef fetch_json(\n    url: str,\n    headers: Optional[Dict[str, str]] = None,\n    timeout: float = 5.0,\n    max_retries: int = 3,\n    backoff_factor: float = 0.5\n) -> Dict[Any, Any]:\n    attempt = 0\n    while attempt < max_retries:\n        try:\n            response = requests.get(url, headers=headers, timeout=timeout)\n            response.raise_for_status()\n            return response.json()\n        except (RequestException, Timeout) as exc:\n            attempt += 1\n            if attempt >= max_retries:\n                raise ConnectionError(f\"Failed to fetch JSON from {url} after {max_retries} attempts\") from exc\n            sleep_time = backoff_factor * (2 ** (attempt - 1))\n            time.sleep(sleep_time)"}
{"question":"Provide the documentation for the function according to task description.","answer":"Filter a dictionary to include only allowed keys.\n\nArgs:\n    data: Dictionary to filter\n    allowed_keys: List of keys to retain\n    default: Value to use for missing keys (default: None)\n\nReturns:\n    Dictionary containing only the allowed keys with their corresponding values or the default\n\nRaises:\n    TypeError: If data is not a dictionary\n\nExample:\n    >>> data = {'a': 1, 'b': 2, 'c': 3}\n    >>> filter_dict(data, ['a', 'c', 'd'], default=0)\n    {'a': 1, 'c': 3, 'd': 0}","context":"from typing import Any, List, Dict\n\ndef filter_dict(data: Dict[str, Any], allowed_keys: List[str], default: Any = None) -> Dict[str, Any]:\n    if not isinstance(data, dict):\n        raise TypeError(\"data must be a dictionary\")\n    result: Dict[str, Any] = {}\n    for key in allowed_keys:\n        result[key] = data.get(key, default)\n    return result"}
{"question":"Provide the documentation for the function according to task description.","answer":"Read a JSON file and return its contents as a dictionary.\n\nArgs:\n    file_path: Path to the JSON file to read\n    default: Optional dictionary to return if the file does not exist\n\nReturns:\n    A dictionary containing the parsed JSON data\n\nRaises:\n    FileNotFoundError: If the file does not exist and no default is provided\n    ValueError: If the file contains invalid JSON\n\nExample:\n    >>> data = read_json_file('config.json')\n    >>> isinstance(data, dict)\n    True","context":"import json\nimport os\nfrom typing import Any, Optional\n\ndef read_json_file(file_path: str, *, default: Optional[dict[str, Any]] = None) -> dict[str, Any]:\n    if not os.path.isfile(file_path):\n        if default is not None:\n            return default\n        raise FileNotFoundError(f\"File not found: {file_path}\")\n    try:\n        with open(file_path, 'r', encoding='utf-8') as f:\n            return json.load(f)\n    except json.JSONDecodeError as exc:\n        raise ValueError(f\"Invalid JSON in {file_path}: {exc}\") from exc"}
{"question":"Provide the documentation for the function according to task description.","answer":"Group dictionaries by a specified field.\n\n    Args:\n        items: List of dictionaries to be grouped\n        group_by: Key name to group the dictionaries by\n        ignore_missing: If True, items lacking the group_by key are skipped; otherwise a KeyError is raised\n\n    Returns:\n        Dictionary mapping each unique group key to a list of dictionaries that share that value\n\n    Raises:\n        KeyError: If an item does not contain the group_by key and ignore_missing is False\n\n    Example:\n        >>> data = [\n        ...     {'type': 'fruit', 'name': 'apple'},\n        ...     {'type': 'fruit', 'name': 'banana'},\n        ...     {'type': 'vegetable', 'name': 'carrot'}\n        ... ]\n        >>> group_dicts_by_field(data, 'type')\n        {'fruit': [{'type': 'fruit', 'name': 'apple'},\n                   {'type': 'fruit', 'name': 'banana'}],\n         'vegetable': [{'type': 'vegetable', 'name': 'carrot'}]}","context":"from typing import Any, Dict, List\n\ndef group_dicts_by_field(items: List[Dict[str, Any]], group_by: str, ignore_missing: bool = False) -> Dict[str, List[Dict[str, Any]]]:\n    result: Dict[str, List[Dict[str, Any]]] = {}\n    for item in items:\n        if group_by not in item:\n            if ignore_missing:\n                continue\n            raise KeyError(f\"Missing '{group_by}' in item {item}\")\n        key = str(item[group_by])\n        result.setdefault(key, []).append(item)\n    return result"}
{"question":"Provide the documentation for the function according to task description.","answer":"Convert an ISO 8601 datetime string to a specified timezone and format the result.\n\nArgs:\n    iso_str: The ISO 8601 datetime string to convert\n    target_tz: The name of the target timezone (e.g., \"America\/New_York\")\n    output_format: The strftime format for the output string. Defaults to \"%Y-%m-%d %H:%M:%S %Z\"\n\nReturns:\n    A string representing the datetime in the target timezone formatted according to ``output_format``\n\nRaises:\n    TypeError: If ``iso_str`` or ``target_tz`` is not a string\n    ValueError: If ``iso_str`` is not a valid ISO datetime string\n    ValueError: If ``target_tz`` is not a recognized timezone\n\nExample:\n    >>> convert_iso_to_timezone(\"2023-08-01T12:30:00Z\", \"America\/New_York\")\n    '2023-08-01 08:30:00 EDT'","context":"from datetime import datetime\nfrom dateutil import parser\nimport pytz\n\ndef convert_iso_to_timezone(iso_str: str, target_tz: str, output_format: str = \"%Y-%m-%d %H:%M:%S %Z\") -> str:\n    if not isinstance(iso_str, str) or not isinstance(target_tz, str):\n        raise TypeError(\"iso_str and target_tz must be strings\")\n    try:\n        dt = parser.isoparse(iso_str)\n    except (ValueError, TypeError) as exc:\n        raise ValueError(f\"Invalid ISO datetime string: {iso_str}\") from exc\n    if dt.tzinfo is None:\n        dt = dt.replace(tzinfo=pytz.UTC)\n    try:\n        target_zone = pytz.timezone(target_tz)\n    except pytz.UnknownTimeZoneError as exc:\n        raise ValueError(f\"Unknown timezone: {target_tz}\") from exc\n    converted = dt.astimezone(target_zone)\n    return converted.strftime(output_format)"}
{"question":"Provide the documentation for the function according to task description.","answer":"Sum numeric values in a CSV column grouped by key.\n\nArgs:\n    file_path: Path to the CSV file to read\n    column_name: Name of the column whose values should be summed\n    delimiter: Delimiter used in the CSV file. Defaults to \",\"\n\nReturns:\n    A dictionary mapping each unique key from the \"key\" column to the sum of the numeric values in the specified column\n\nRaises:\n    ValueError: If `column_name` is not found in the CSV header\n    ValueError: If a value in `column_name` cannot be converted to a float\n\nExample:\n    >>> import csv, tempfile\n    >>> with tempfile.NamedTemporaryFile(mode='w', newline='', delete=False) as tmp:\n    ...     writer = csv.writer(tmp)\n    ...     writer.writerow(['key', 'value'])\n    ...     writer.writerow(['A', '10'])\n    ...     writer.writerow(['B', '5'])\n    ...     writer.writerow(['A', '3'])\n    ...     file_name = tmp.name\n    >>> sum_csv_column(file_name, 'value')\n    {'A': 13.0, 'B': 5.0}","context":"def sum_csv_column(file_path: str, column_name: str, delimiter: str = \",\") -> dict[str, float]:\n    import csv\n    totals: dict[str, float] = {}\n    with open(file_path, newline=\"\", encoding=\"utf-8\") as f:\n        reader = csv.DictReader(f, delimiter=delimiter)\n        if column_name not in reader.fieldnames:\n            raise ValueError(f\"Column '{column_name}' not found\")\n        for row in reader:\n            key = row.get(\"key\", \"\")\n            try:\n                value = float(row[column_name])\n            except (KeyError, TypeError, ValueError):\n                raise ValueError(f\"Invalid numeric value in column '{column_name}'\")\n            totals[key] = totals.get(key, 0.0) + value\n    return totals"}
{"question":"Provide the documentation for the function according to task description.","answer":"Parse a string of key\u2011value pairs into a dictionary.\n\nArgs:\n    s: The input string containing the pairs.\n    pair_sep: Separator used between pairs (default ';').\n    kv_sep: Separator used between key and value within a pair (default '=').\n\nReturns:\n    dict[str, str]: A dictionary mapping each parsed key to its corresponding value.\n\nRaises:\n    ValueError: If a pair is missing the key\u2011value separator or contains an empty key after stripping.\n\nExample:\n    >>> parse_key_value(\"a=1; b=2; c=3\")\n    {'a': '1', 'b': '2', 'c': '3'}","context":"def parse_key_value(s: str, pair_sep: str = \";\", kv_sep: str = \"=\") -> dict[str, str]:\n    result: dict[str, str] = {}\n    if not s:\n        return result\n    pairs = s.split(pair_sep)\n    for pair in pairs:\n        if kv_sep not in pair:\n            raise ValueError(f\"Missing key-value separator '{kv_sep}' in pair: {pair}\")\n        key, value = pair.split(kv_sep, 1)\n        key = key.strip()\n        value = value.strip()\n        if not key:\n            raise ValueError(f\"Empty key in pair: {pair}\")\n        result[key] = value\n    return result"}
{"question":"Provide the documentation for the function according to task description.","answer":"Convert an ISO\u2011formatted datetime string to a timezone\u2011aware datetime.\n\nArgs:\n    iso_str (str): ISO\u20118601 datetime string to convert.\n    target_tz (str): IANA timezone name to convert the datetime to. Defaults to 'UTC'.\n    fmt (Optional[str]): Optional format string for ``datetime.strptime``. If provided, ``iso_str`` is parsed with this format instead of using ``dateutil``. Defaults to ``None``.\n    keep_microseconds (bool): Whether to preserve microseconds in the result. If ``False``, the microsecond component is set to zero. Defaults to ``True``.\n    raise_on_error (bool): If ``True``, a ``ValueError`` is raised when parsing fails. If ``False``, the function returns ``default_dt`` when provided or re\u2011raises the original exception. Defaults to ``False``.\n    default_dt (Optional[datetime]): Fallback datetime to return when parsing fails and ``raise_on_error`` is ``False``. If ``None`` and parsing fails, the original exception is propagated. Defaults to ``None``.\n\nReturns:\n    datetime: A timezone\u2011aware ``datetime`` object representing ``iso_str`` converted to ``target_tz``.\n\nRaises:\n    ValueError: If ``iso_str`` cannot be parsed and ``raise_on_error`` is ``True``.\n\nExample:\n    >>> from datetime import datetime\n    >>> convert_iso_to_tz('2023-07-21T15:30:00Z', 'America\/New_York')\n    datetime.datetime(2023, 7, 21, 11, 30, tzinfo=zoneinfo.ZoneInfo(key='America\/New_York'))","context":"from datetime import datetime\nfrom zoneinfo import ZoneInfo\nfrom dateutil import parser\nfrom typing import Optional\n\ndef convert_iso_to_tz(\n    iso_str: str,\n    target_tz: str = 'UTC',\n    fmt: Optional[str] = None,\n    keep_microseconds: bool = True,\n    raise_on_error: bool = False,\n    default_dt: Optional[datetime] = None,\n) -> datetime:\n    try:\n        dt = parser.isoparse(iso_str) if fmt is None else datetime.strptime(iso_str, fmt)\n    except (ValueError, TypeError) as exc:\n        if raise_on_error:\n            raise ValueError(f\"Unable to parse datetime string: {iso_str}\") from exc\n        if default_dt is not None:\n            return default_dt\n        raise\n    if dt.tzinfo is None:\n        dt = dt.replace(tzinfo=ZoneInfo('UTC'))\n    dt = dt.astimezone(ZoneInfo(target_tz))\n    if not keep_microseconds:\n        dt = dt.replace(microsecond=0)\n    return dt"}
{"question":"Provide the documentation for the function according to task description.","answer":"Read a CSV file and return its rows as a list of dictionaries.\n\nEach row is represented as a dict mapping column names to their string values.\n\nArgs:\n    filepath: Path to the CSV file to read\n    delimiter: Field delimiter character (default ',')\n    encoding: Text encoding used to open the file (default 'utf-8')\n\nReturns:\n    List of dictionaries, one per CSV row\n\nRaises:\n    FileNotFoundError: If the CSV file does not exist at the given path\n    ValueError: If an error occurs while parsing the CSV file\n\nExample:\n    >>> rows = read_csv_to_dicts('example.csv')\n    >>> rows[0]['name']\n    'Alice'","context":"import csv\nfrom typing import List, Dict\n\ndef read_csv_to_dicts(filepath: str, delimiter: str = ',', encoding: str = 'utf-8') -> List[Dict[str, str]]:\n    try:\n        with open(filepath, newline='', encoding=encoding) as f:\n            reader = csv.DictReader(f, delimiter=delimiter)\n            return [row for row in reader]\n    except FileNotFoundError as e:\n        raise FileNotFoundError(f\"CSV file not found: {filepath}\") from e\n    except csv.Error as e:\n        raise ValueError(f\"Error parsing CSV file: {e}\") from e"}
{"question":"Provide the documentation for the function according to task description.","answer":"Parse a delimited string into a dictionary of key\u2011value pairs.\n\nArgs:\n    s: Input string containing key\/value pairs\n    pair_delim: Delimiter that separates each pair. Defaults to ';'\n    kv_delim: Delimiter that separates key and value within a pair. Defaults to '='\n\nReturns:\n    Dictionary mapping each key to its corresponding value\n\nRaises:\n    ValueError: If the input string is empty\n    ValueError: If a pair is missing the key\/value delimiter\n    ValueError: If a pair contains an empty key\n\nExample:\n    >>> parse_key_value(\"a=1;b=2;c=3\")\n    {'a': '1', 'b': '2', 'c': '3'}","context":"def parse_key_value(s: str, pair_delim: str = ';', kv_delim: str = '=') -> dict[str, str]:\n    if not s:\n        raise ValueError(\"Input string is empty\")\n    result: dict[str, str] = {}\n    pairs = s.split(pair_delim)\n    for pair in pairs:\n        if kv_delim not in pair:\n            raise ValueError(f\"Missing key\/value delimiter in pair: {pair!r}\")\n        key, value = pair.split(kv_delim, 1)\n        key = key.strip()\n        value = value.strip()\n        if not key:\n            raise ValueError(f\"Empty key in pair: {pair!r}\")\n        result[key] = value\n    return result"}
{"question":"Provide the documentation for the function according to task description.","answer":"Read a CSV file and return rows as dictionaries.\n\nOpens the given file, parses it with ``csv.DictReader`` using the specified delimiter, and returns a list where each element is a mapping from column names to string values.\n\nArgs:\n    file_path: Path to the CSV file to read\n    delimiter: Field delimiter character. Defaults to ','\n\nReturns:\n    List of dictionaries representing the CSV rows\n\nRaises:\n    FileNotFoundError: If the file does not exist\n    ValueError: If the CSV file lacks a header row\n\nExample:\n    >>> rows = read_csv_as_dicts('data.csv')\n    >>> rows[0]['name']\n    'Alice'","context":"import csv\nfrom pathlib import Path\nfrom typing import List, Dict\n\ndef read_csv_as_dicts(file_path: str, delimiter: str = ',') -> List[Dict[str, str]]:\n    path = Path(file_path)\n    if not path.is_file():\n        raise FileNotFoundError(f\"No such file: {file_path}\")\n    with path.open(newline='', encoding='utf-8') as csvfile:\n        reader = csv.DictReader(csvfile, delimiter=delimiter)\n        if reader.fieldnames is None:\n            raise ValueError(\"CSV file must contain a header row\")\n        return [row for row in reader]"}
{"question":"Provide the documentation for the function according to task description.","answer":"Aggregate numeric values in a list of records by a specified key.\n\nArgs:\n    records: List of dictionaries representing the data rows\n    group_key: Key whose values are used to group the records\n    sum_field: Key whose numeric value will be summed for each group\n\nReturns:\n    Dictionary mapping each unique group_key value to the summed sum_field as a float\n\nExample:\n    >>> records = [\n    ...     {'category': 'A', 'amount': 10},\n    ...     {'category': 'B', 'amount': 5},\n    ...     {'category': 'A', 'amount': 7},\n    ... ]\n    >>> aggregate_by_key(records, 'category', 'amount')\n    {'A': 17.0, 'B': 5.0}","context":"from typing import Dict, List, Any\n\ndef aggregate_by_key(records: List[Dict[str, Any]], group_key: str, sum_field: str) -> Dict[Any, float]:\n    result: Dict[Any, float] = {}\n    for rec in records:\n        if group_key not in rec or sum_field not in rec:\n            continue\n        key = rec[group_key]\n        try:\n            value = float(rec[sum_field])\n        except (TypeError, ValueError):\n            continue\n        result[key] = result.get(key, 0.0) + value\n    return result"}
{"question":"Provide the documentation for the function according to task description.","answer":"Parse a string into a dictionary of key-value pairs.\n\nArgs:\n    s (str): The input string containing key-value pairs.\n    pair_delim (str): Delimiter that separates individual pairs. Defaults to ';'.\n    kv_delim (str): Delimiter that separates a key from its value. Defaults to '='.\n\nReturns:\n    Dict[str, str]: A dictionary mapping each key to its corresponding value.\n\nRaises:\n    ValueError: If a pair does not contain the key-value delimiter.\n\nExample:\n    >>> parse_key_value_pairs(\"host=localhost;port=5432\")\n    {'host': 'localhost', 'port': '5432'}","context":"from typing import Dict\n\ndef parse_key_value_pairs(s: str, pair_delim: str = ';', kv_delim: str = '=') -> Dict[str, str]:\n    result: Dict[str, str] = {}\n    if not s:\n        return result\n    pairs = s.split(pair_delim)\n    for pair in pairs:\n        if kv_delim not in pair:\n            raise ValueError(f\"Missing delimiter '{kv_delim}' in pair '{pair}'\")\n        key, value = pair.split(kv_delim, 1)\n        result[key.strip()] = value.strip()\n    return result"}
{"question":"Provide the documentation for the function according to task description.","answer":"Normalize whitespace in a string.\n\nReplace runs of whitespace characters with a single space and remove leading and trailing whitespace.\n\nArgs:\n    text: Input string to normalize\n\nReturns:\n    String with normalized whitespace","context":"import re\ndef normalize_whitespace(text: str) -> str:\n    return re.sub(r'\\s+', ' ', text).strip()"}
{"question":"Provide the documentation for the function according to task description.","answer":"Load a JSON configuration file.\n\nArgs:\n    path: Path to the JSON configuration file\n    default: Default dictionary to return if the file is missing; if None, a FileNotFoundError is raised\n\nReturns:\n    Dictionary containing the parsed JSON configuration\n\nRaises:\n    FileNotFoundError: If the file does not exist and no default is provided\n    ValueError: If the file contains invalid JSON\n\nExample:\n    >>> config = load_json_config('settings.json', default={'debug': False})\n    >>> isinstance(config, dict)\n    True","context":"def load_json_config(path: str, default: dict[str, any] | None = None) -> dict[str, any]:\n    import json, os\n    if not os.path.isfile(path):\n        if default is not None:\n            return default\n        raise FileNotFoundError(f\"Config file not found: {path}\")\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        try:\n            return json.load(f)\n        except json.JSONDecodeError as e:\n            raise ValueError(f\"Invalid JSON in {path}: {e}\") from e"}
{"question":"Provide the documentation for the function according to task description.","answer":"Scale even numbers in a list by a factor.\n\nArgs:\n    values: List[int] \u2013 A list of integer values to be processed\n    factor: int \u2013 Multiplicative factor applied to each even number. Must be non-zero.\n\nReturns:\n    List[int] \u2013 A list containing the even numbers from values, each multiplied by factor\n\nRaises:\n    ValueError: If factor is zero\n\nExample:\n    >>> scale_even_numbers([1, 2, 3, 4], 3)\n    [6, 12]","context":"from typing import List\n\ndef scale_even_numbers(values: List[int], factor: int = 1) -> List[int]:\n    if factor == 0:\n        raise ValueError(\"factor must be non-zero\")\n    return [v * factor for v in values if v % 2 == 0]"}
{"question":"Provide the documentation for the function according to task description.","answer":"Filter dictionaries by key and sum numeric values meeting a minimum threshold.\n\nArgs:\n    data: List of dictionaries mapping string keys to int or float values.\n    key: The key whose associated numeric values should be summed.\n    min_value: Minimum value (inclusive) a numeric entry must have to be included in the total. Defaults to 0.0.\n\nRaises:\n    TypeError: If a value associated with `key` is not an int or float.\n\nReturns:\n    The sum of all numeric values for `key` that are greater than or equal to `min_value` as a float.\n\nExample:\n    >>> data = [{'score': 10}, {'score': 7.5}, {'score': 'high'}, {'points': 3}]\n    >>> filter_and_sum(data, 'score')\n    17.5\n    >>> filter_and_sum(data, 'score', min_value=8)\n    10.0","context":"from typing import List, Dict, Union\n\ndef filter_and_sum(data: List[Dict[str, Union[int, float]]], key: str, min_value: float = 0.0) -> float:\n    total = 0.0\n    for entry in data:\n        if key not in entry:\n            continue\n        value = entry[key]\n        if not isinstance(value, (int, float)):\n            raise TypeError(f\"Value for key '{key}' must be numeric, got {type(value)}\")\n        if value >= min_value:\n            total += float(value)\n    return total"}
{"question":"Provide the documentation for the function according to task description.","answer":"Sanitize a filename by replacing illegal characters.\n\nReplace characters that are not allowed in filenames with a given replacement string and strip surrounding whitespace.\n\nArgs:\n    name: str. The original filename to sanitize\n    replacement: str, optional. The string to replace each illegal character with. Defaults to '_' \n\nReturns:\n    str. The sanitized filename\n\nRaises:\n    TypeError: If `name` is not a string\n    ValueError: If the resulting filename is empty after sanitization\n\nExample:\n    >>> sanitize_filename('my<file>:name?.txt')\n    'my_file_name_.txt'","context":"import re\n\ndef sanitize_filename(name: str, replacement: str = '_') -> str:\n    if not isinstance(name, str):\n        raise TypeError(\"name must be a string\")\n    sanitized = re.sub(r'[<>:\"\/\\\\\\\\|?*]', replacement, name)\n    sanitized = sanitized.strip()\n    if not sanitized:\n        raise ValueError(\"Resulting filename is empty\")\n    return sanitized"}
{"question":"Provide the documentation for the function according to task description.","answer":"Parse date strings into datetime objects with optional formats and timezone conversion.\n\nArgs:\n    date_strings: List of date strings to parse\n    formats: Optional list of datetime format strings to try. Defaults to common ISO and date formats if None\n    target_tz: IANA timezone name to which parsed datetimes are converted. Defaults to \"UTC\"\n\nReturns:\n    List of datetime objects corresponding to the input strings, each timezone\u2011aware and converted to target_tz\n\nRaises:\n    ValueError: If a date string cannot be parsed with any of the provided formats\n\nExample:\n    >>> parse_datetimes(\n    ...     [\"2023-05-01T12:30:00+0200\", \"2023-05-01 10:00:00\"],\n    ...     target_tz=\"America\/New_York\",\n    ... )\n    [datetime.datetime(2023, 5, 1, 6, 30, tzinfo=zoneinfo.ZoneInfo(key='America\/New_York')),\n     datetime.datetime(2023, 5, 1, 6, 0, tzinfo=zoneinfo.ZoneInfo(key='America\/New_York'))]","context":"def parse_datetimes(date_strings: list[str], formats: list[str] | None = None, target_tz: str = \"UTC\") -> list[datetime.datetime]:\n    import datetime\n    from zoneinfo import ZoneInfo\n    if formats is None:\n        formats = [\"%Y-%m-%dT%H:%M:%S%z\", \"%Y-%m-%d %H:%M:%S\", \"%Y-%m-%d\"]\n    tzinfo = ZoneInfo(target_tz)\n    result: list[datetime.datetime] = []\n    for ds in date_strings:\n        parsed: datetime.datetime | None = None\n        for fmt in formats:\n            try:\n                parsed = datetime.datetime.strptime(ds, fmt)\n                break\n            except ValueError:\n                continue\n        if parsed is None:\n            raise ValueError(f\"Unable to parse date string: {ds}\")\n        if parsed.tzinfo is None:\n            parsed = parsed.replace(tzinfo=datetime.timezone.utc)\n        result.append(parsed.astimezone(tzinfo))\n    return result"}
{"question":"Provide the documentation for the function according to task description.","answer":"Read a CSV file and return its rows as dictionaries.\n\nArgs:\n    filepath: Path to the CSV file\n    delimiter: Delimiter used to separate fields in the CSV file, default is \",\"\n    encoding: Optional file encoding to use when opening the file\n\nReturns:\n    A list of dictionaries representing each row in the CSV file\n\nRaises:\n    ValueError: If `filepath` is empty or if there is an error parsing the CSV file\n    FileNotFoundError: If the specified CSV file does not exist\n\nExample:\n    >>> rows = read_csv_as_dicts('example.csv')\n    >>> rows[0]['header_name']","context":"import csv\nfrom typing import List, Dict, Optional\n\ndef read_csv_as_dicts(filepath: str, delimiter: str = \",\", encoding: Optional[str] = None) -> List[Dict[str, str]]:\n    if not filepath:\n        raise ValueError(\"filepath cannot be empty\")\n    open_kwargs = {\"newline\": \"\"} \n    if encoding:\n        open_kwargs[\"encoding\"] = encoding\n    try:\n        with open(filepath, mode=\"r\", **open_kwargs) as f:\n            reader = csv.DictReader(f, delimiter=delimiter)\n            rows = list(reader)\n    except FileNotFoundError as e:\n        raise FileNotFoundError(f\"CSV file not found: {filepath}\") from e\n    except csv.Error as e:\n        raise ValueError(f\"Error parsing CSV file: {e}\") from e\n    return rows"}
{"question":"Provide the documentation for the function according to task description.","answer":"Truncate a string to a maximum length, appending a suffix if truncation occurs.\n\nArgs:\n    text: The string to truncate\n    max_len: The maximum allowed length of the result, including the suffix\n    suffix: The suffix to append when truncation is needed. Defaults to \"...\"\n\nReturns:\n    The original string if its length is within max_len, otherwise a truncated version with the suffix appended\n\nRaises:\n    ValueError: If max_len is less than the length of suffix\n\nExample:\n    >>> truncate(\"Hello, world!\", 10)\n    'Hello, ...'","context":"def truncate(text: str, max_len: int, suffix: str = \"...\") -> str:\n    if max_len < len(suffix):\n        raise ValueError(\"max_len must be at least length of suffix\")\n    if len(text) <= max_len:\n        return text\n    return text[: max_len - len(suffix)] + suffix"}
{"question":"Provide the documentation for the function according to task description.","answer":"Filter records and compute the average of a numeric field for records that match a given filter.\n\nArgs:\n    records: List of dictionaries representing the data records\n    filter_key: Key name used to filter records\n    filter_value: Value that `filter_key` must match\n    aggregate_key: Key whose numeric values will be aggregated\n\nReturns:\n    Float representing the average of the aggregate values for matching records\n\nRaises:\n    KeyError: If a matching record does not contain `aggregate_key`\n    ValueError: If a matching record's `aggregate_key` value cannot be converted to float\n    ValueError: If no records match the filter criteria\n\nExample:\n    >>> records = [\n    ...     {'type': 'A', 'value': 10},\n    ...     {'type': 'B', 'value': 20},\n    ...     {'type': 'A', 'value': 30},\n    ... ]\n    >>> filter_and_aggregate(records, 'type', 'A', 'value')\n    20.0","context":"def filter_and_aggregate(records: list[dict[str, Any]], filter_key: str, filter_value: Any, aggregate_key: str) -> float:\n    from typing import Any\n    total = 0.0\n    count = 0\n    for rec in records:\n        if rec.get(filter_key) == filter_value:\n            if aggregate_key not in rec:\n                raise KeyError(f'Missing aggregate_key: {aggregate_key}')\n            try:\n                val = float(rec[aggregate_key])\n            except (TypeError, ValueError):\n                raise ValueError(f'Non-numeric aggregate value: {rec[aggregate_key]}')\n            total += val\n            count += 1\n    if count == 0:\n        raise ValueError('No records match the filter criteria')\n    return total \/ count"}
{"question":"Provide the documentation for the function according to task description.","answer":"Filter rows from a CSV file by a numeric column.\n\nRead the CSV file at *file_path*, ensure the file exists and the specified *column* is present in the header, convert the column values to floats, skip rows with non\u2011numeric values, and return rows where the value is greater than or equal to *min_value*. The CSV delimiter can be customized with *delimiter*.\n\nArgs:\n    file_path: Path to the CSV file.\n    column: Name of the column containing numeric values to filter on.\n    min_value: Minimum numeric value (inclusive) for rows to be included. Defaults to 0.0.\n    delimiter: Delimiter used in the CSV file. Defaults to \",\".\n\nReturns:\n    A list of dictionaries representing rows that meet the threshold. Each dictionary maps column names to their string values.\n\nRaises:\n    FileNotFoundError: If the CSV file does not exist.\n    ValueError: If the specified column is not found in the CSV header.\n\nExample:\n    >>> rows = filter_csv_by_column(\"data.csv\", \"price\", min_value=10.0)\n    >>> len(rows)\n    5","context":"import csv\nfrom pathlib import Path\n\ndef filter_csv_by_column(file_path: str, column: str, min_value: float = 0.0, delimiter: str = \",\") -> list[dict[str, str]]:\n    path = Path(file_path)\n    if not path.is_file():\n        raise FileNotFoundError(f\"CSV file not found: {file_path}\")\n    results: list[dict[str, str]] = []\n    with path.open(newline=\"\", encoding=\"utf-8\") as f:\n        reader = csv.DictReader(f, delimiter=delimiter)\n        if column not in reader.fieldnames:\n            raise ValueError(f\"Column '{column}' not found in CSV header\")\n        for row in reader:\n            try:\n                value = float(row[column])\n            except (ValueError, TypeError):\n                continue\n            if value >= min_value:\n                results.append(row)\n    return results"}
{"question":"Provide the documentation for the function according to task description.","answer":"Parse a CSV file and return its rows as dictionaries keyed by a specified column.\n\nArgs:\n    file_path: Path to the CSV file to read\n    key_column: Column name to use as keys in the resulting dictionary\n\nReturns:\n    A dictionary mapping each key value to a row dictionary containing the CSV fields\n\nRaises:\n    FileNotFoundError: If the CSV file does not exist at file_path\n    ValueError: If key_column is not found in the CSV header\n\nExample:\n    >>> data = parse_csv_to_dict('people.csv', 'id')\n    >>> data['123']['name']\n    'Alice'","context":"def parse_csv_to_dict(file_path: str, key_column: str) -> dict[str, dict]:\n    import csv\n    from pathlib import Path\n    result: dict[str, dict] = {}\n    if not Path(file_path).is_file():\n        raise FileNotFoundError(f\"CSV file not found: {file_path}\")\n    with open(file_path, newline='', encoding='utf-8') as f:\n        reader = csv.DictReader(f)\n        if key_column not in reader.fieldnames:\n            raise ValueError(f\"Key column '{key_column}' not present in CSV headers\")\n        for row in reader:\n            key = row.get(key_column)\n            if key is None:\n                continue\n            result[key] = row\n    return result"}
{"question":"Provide the documentation for the function according to task description.","answer":"Mask an email address.\n\nArgs:\n    email: The email address to mask\n\nReturns:\n    The masked email address with the local part partially obscured\n\nRaises:\n    ValueError: If the email does not contain an '@' character\n\nExample:\n    >>> mask_email('john.doe@example.com')\n    'j******e@example.com'","context":"import re\n\ndef mask_email(email: str) -> str:\n    if '@' not in email:\n        raise ValueError('Invalid email address')\n    local, domain = email.split('@', 1)\n    if len(local) <= 2:\n        masked_local = local\n    else:\n        masked_local = local[0] + '*' * (len(local) - 2) + local[-1]\n    return f\"{masked_local}@{domain}\""}
{"question":"Provide the documentation for the function according to task description.","answer":"Fetch JSON data from a URL with retries and exponential backoff.\n\nRetrieves and parses JSON content from the given HTTP endpoint, optionally retrying on failures using a configurable backoff strategy.\n\nArgs:\n    url: The URL to request\n    timeout: Number of seconds to wait for a response before timing out\n    max_retries: Maximum number of request attempts\n    backoff_factor: Factor used to compute backoff sleep time between retries\n\nReturns:\n    Dictionary parsed from the JSON response\n\nRaises:\n    requests.RequestException: If the request fails after all retries\n\nExample:\n    >>> data = fetch_json('https:\/\/api.example.com\/data')\n    >>> isinstance(data, dict)\n    True","context":"def fetch_json(url: str, timeout: float = 5.0, max_retries: int = 3, backoff_factor: float = 0.5) -> dict[str, any]:\n    import time\n    import requests\n    from typing import Any\n    for attempt in range(max_retries):\n        try:\n            response = requests.get(url, timeout=timeout)\n            response.raise_for_status()\n            return response.json()\n        except requests.RequestException as e:\n            if attempt == max_retries - 1:\n                raise\n            sleep_time = backoff_factor * (2 ** attempt)\n            time.sleep(sleep_time)"}
{"question":"Provide the documentation for the function according to task description.","answer":"Merge two lists and return a sorted list of unique integers.\n\nArgs:\n    a: First list of integers\n    b: Second list of integers\n\nReturns:\n    A new list containing the unique integers from both input lists, sorted in ascending order\n\nExample:\n    >>> merge_sorted_unique([1, 3, 5], [2, 3, 4])\n    [1, 2, 3, 4, 5]","context":"def merge_sorted_unique(a: list[int], b: list[int]) -> list[int]:\n    combined = a + b\n    unique = set(combined)\n    return sorted(unique)"}
{"question":"Provide the documentation for the function according to task description.","answer":"Calculate the sum of positive numbers in a list.\n\nIterate over the list, validate its contents, and add each positive integer to the total.\n\nArgs:\n    numbers: List of integers to process\n\nReturns:\n    The sum of all positive integers in the list\n\nRaises:\n    TypeError: If numbers is not a list\n    ValueError: If any element in numbers is not an int\n\nExample:\n    >>> sum_of_positive_numbers([1, -2, 3, 0])\n    4","context":"def sum_of_positive_numbers(numbers: list[int]) -> int:\n    if not isinstance(numbers, list):\n        raise TypeError(\"Input must be a list of integers\")\n    total = 0\n    for n in numbers:\n        if not isinstance(n, int):\n            raise ValueError(f\"List element is not an int: {n}\")\n        if n > 0:\n            total += n\n    return total"}
{"question":"Provide the documentation for the function according to task description.","answer":"Aggregate scores for each student.\n\n    Compute the average of each student's scores that are greater than or equal to `min_score`. Raises a `ValueError` if a student has no scores meeting the threshold.\n\n    Args:\n        students: A dictionary mapping student names to a list of their scores\n        min_score: Minimum score to include in the average (default 0.0)\n\n    Returns:\n        A dictionary mapping each student name to the average of their filtered scores\n\n    Raises:\n        ValueError: If a student has no scores that meet the minimum threshold\n\n    Example:\n        >>> students = {\"Alice\": [85.0, 92.5, 78.0], \"Bob\": [70.0, 68.5]}\n        >>> aggregate_scores(students, min_score=80.0)\n        {'Alice': 88.75}\n        # Raises ValueError for Bob because no scores \u2265 80.0.","context":"def aggregate_scores(students: dict[str, list[float]], min_score: float = 0.0) -> dict[str, float]:\n    result = {}\n    for name, scores in students.items():\n        filtered = [s for s in scores if s >= min_score]\n        if not filtered:\n            raise ValueError(f\"No scores meet the minimum threshold for student '{name}'.\")\n        result[name] = sum(filtered) \/ len(filtered)\n    return result"}
{"question":"Provide the documentation for the function according to task description.","answer":"Aggregate numeric metrics from a list of records.\n\nArgs:\n    records: List of dictionaries containing data.\n    key: Dictionary key whose numeric values are aggregated.\n    metrics: List of metric names to compute. Supported values are \"sum\", \"mean\", \"max\", and \"min\".\n\nReturns:\n    Mapping from each requested metric name to its computed float value.\n\nRaises:\n    ValueError: If `records` is empty or an unsupported metric is requested.\n    KeyError: If no numeric values are found for the provided `key`.\n\nExample:\n    >>> records = [\n    ...     {\"id\": 1, \"value\": 10},\n    ...     {\"id\": 2, \"value\": 20},\n    ...     {\"id\": 3, \"value\": 5}\n    ... ]\n    >>> aggregate_metrics(records, key=\"value\", metrics=[\"sum\", \"mean\", \"max\"])\n    {'sum': 35, 'mean': 11.666666666666666, 'max': 20}","context":"from typing import Any, Literal, List, Dict\nimport statistics\n\ndef aggregate_metrics(\n    records: List[Dict[str, Any]],\n    *,\n    key: str,\n    metrics: List[Literal[\"sum\", \"mean\", \"max\", \"min\"]]\n) -> Dict[str, float]:\n    if not records:\n        raise ValueError(\"records list cannot be empty\")\n    values = [r[key] for r in records if key in r and isinstance(r[key], (int, float))]\n    if not values:\n        raise KeyError(f\"No numeric values found for key '{key}'\")\n    result: Dict[str, float] = {}\n    for metric in metrics:\n        if metric == \"sum\":\n            result[\"sum\"] = sum(values)\n        elif metric == \"mean\":\n            result[\"mean\"] = statistics.mean(values)\n        elif metric == \"max\":\n            result[\"max\"] = max(values)\n        elif metric == \"min\":\n            result[\"min\"] = min(values)\n        else:\n            raise ValueError(f\"Unsupported metric: {metric}\")\n    return result"}
{"question":"Provide the documentation for the function according to task description.","answer":"Select specified keys from each dictionary in a list.\n\nArgs:\n    records: List of dictionaries to filter\n    keys: List of keys to retain in each dictionary\n\nRaises:\n    ValueError: If the keys list is empty\n\nReturns:\n    A list of dictionaries, each containing only the key\u2011value pairs for the specified keys that were present in the original dictionary\n\nExample:\n    >>> records = [{'a': 1, 'b': 2}, {'a': 3, 'c': 4}]\n    >>> select_keys(records, ['a'])\n    [{'a': 1}, {'a': 3}]","context":"from typing import Any, List, Dict\n\ndef select_keys(records: List[Dict[str, Any]], keys: List[str]) -> List[Dict[str, Any]]:\n    if not keys:\n        raise ValueError(\"keys list must not be empty\")\n    result: List[Dict[str, Any]] = []\n    for record in records:\n        filtered: Dict[str, Any] = {k: record[k] for k in keys if k in record}\n        result.append(filtered)\n    return result"}
{"question":"Provide the documentation for the function according to task description.","answer":"Fetch JSON data from a URL with retry logic.\n\nArgs:\n    url: The URL to send the GET request to.\n    timeout: Number of seconds to wait for a response before timing out. Defaults to 5.\n    max_retries: Maximum number of retry attempts after a failed request. Defaults to 3.\n    backoff_factor: Factor used to calculate the sleep time between retries (sleep = backoff_factor * (2 ** attempt)). Defaults to 0.5.\n\nReturns:\n    dict[str, any]: The parsed JSON content from the response.\n\nRaises:\n    RuntimeError: If the request fails after the specified number of retries. \n\nExample:\n    >>> data = fetch_json_with_retries('https:\/\/api.example.com\/data')\n    >>> print(data)","context":"def fetch_json_with_retries(url: str, timeout: int = 5, max_retries: int = 3, backoff_factor: float = 0.5) -> dict[str, any]:\n    import time\n    import requests\n    attempt = 0\n    while attempt <= max_retries:\n        try:\n            response = requests.get(url, timeout=timeout)\n            response.raise_for_status()\n            return response.json()\n        except requests.exceptions.RequestException:\n            if attempt == max_retries:\n                raise RuntimeError(f\"Failed to fetch {url} after {max_retries} retries\")\n            time.sleep(backoff_factor * (2 ** attempt))\n            attempt += 1"}
{"question":"Provide the documentation for the function according to task description.","answer":"Fetch JSON data from a URL with retries and exponential backoff.\n\nArgs:\n    url: The URL to request\n    timeout: Number of seconds to wait for a response. Defaults to 10\n    max_retries: Maximum number of retry attempts on failure. Defaults to 3\n    backoff_factor: Factor used to calculate sleep time between retries. Defaults to 0.5\n\nReturns:\n    A dictionary representing the parsed JSON response\n\nRaises:\n    ImportError: If the `requests` library is not installed\n    requests.RequestException: If the request fails after all retry attempts\n\nExample:\n    >>> data = fetch_json_with_retries('https:\/\/api.example.com\/data', timeout=5)\n    >>> isinstance(data, dict)\n    True","context":"def fetch_json_with_retries(url: str, timeout: int = 10, max_retries: int = 3, backoff_factor: float = 0.5) -> dict[str, Any]:\n    from typing import Any\n    import json\n    import time\n    try:\n        import requests\n    except ImportError as e:\n        raise e\n    for attempt in range(1, max_retries + 1):\n        try:\n            response = requests.get(url, timeout=timeout)\n            response.raise_for_status()\n            return response.json()\n        except requests.RequestException as e:\n            if attempt == max_retries:\n                raise e\n            time.sleep(backoff_factor * (2 ** (attempt - 1)))"}
{"question":"Provide the documentation for the function according to task description.","answer":"Perform an HTTP GET request with retry logic and exponential backoff.\n\nArgs:\n    url: The URL to retrieve.\n    timeout: Timeout for each request in seconds. Defaults to 5.0.\n    retries: Maximum number of retry attempts after a failure. Defaults to 3.\n    backoff_factor: Factor used to calculate the sleep time between retries. The sleep time is `backoff_factor * (2 ** (attempt - 1))`. Defaults to 0.5.\n\nReturns:\n    The response body decoded as a UTF-8 string.\n\nRaises:\n    urllib.error.HTTPError: If an HTTP error occurs and the retry limit is exceeded.\n    urllib.error.URLError: If a URL error occurs and the retry limit is exceeded.\n\nExample:\n    >>> content = http_get_with_retries('https:\/\/example.com\/api', timeout=10, retries=2)\n    >>> print(content[:100])","context":"def http_get_with_retries(url: str, *, timeout: float = 5.0, retries: int = 3, backoff_factor: float = 0.5) -> str:\n    import urllib.request\n    import urllib.error\n    import time\n    attempt = 0\n    while True:\n        try:\n            with urllib.request.urlopen(url, timeout=timeout) as response:\n                return response.read().decode('utf-8')\n        except (urllib.error.HTTPError, urllib.error.URLError):\n            attempt += 1\n            if attempt > retries:\n                raise\n            time.sleep(backoff_factor * (2 ** (attempt - 1)))"}
{"question":"Provide the documentation for the function according to task description.","answer":"Fetch a URL with automatic retries on transient errors.\n\nArgs:\n    url: The target URL to retrieve\n    timeout: Maximum total time in seconds to wait for the request. Defaults to 10\n    max_retries: Number of retry attempts after a failure. Defaults to 3\n    backoff_factor: Base factor for exponential backoff delays between retries. Defaults to 0.5\n\nReturns:\n    The response body as a string\n\nRaises:\n    RuntimeError: If the request fails after the specified number of retries\n\nExample:\n    >>> import asyncio\n    >>> async def main():\n    ...     html = await fetch_with_retry('https:\/\/example.com')\n    ...     print(html)\n    >>> asyncio.run(main())","context":"import aiohttp\nimport asyncio\nimport time\n\nasync def fetch_with_retry(url: str, *, timeout: int = 10, max_retries: int = 3, backoff_factor: float = 0.5) -> str:\n    attempt = 0\n    while True:\n        try:\n            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=timeout)) as session:\n                async with session.get(url) as response:\n                    response.raise_for_status()\n                    return await response.text()\n        except (aiohttp.ClientError, asyncio.TimeoutError):\n            attempt += 1\n            if attempt > max_retries:\n                raise RuntimeError(f\"Failed to fetch {url} after {max_retries} retries\")\n            await asyncio.sleep(backoff_factor * (2 ** (attempt - 1)))"}
{"question":"Provide the documentation for the function according to task description.","answer":"Filter a dictionary by value range.\n\nArgs:\n    data: Dictionary mapping keys to integer values\n    min_value: Minimum inclusive value to retain. Defaults to 0\n    max_value: Maximum inclusive value to retain, or None for no upper bound. Defaults to None\n\nRaises:\n    ValueError: If min_value is greater than max_value\n\nReturns:\n    A dictionary containing only the items whose values are between min_value and max_value inclusive\n\nExample:\n    >>> data = {'a': 5, 'b': 10, 'c': 15}\n    >>> filter_dict_by_values(data, min_value=6, max_value=12)\n    {'b': 10}","context":"def filter_dict_by_values(data: dict[str, int], min_value: int = 0, max_value: int | None = None) -> dict[str, int]:\n    if max_value is not None and min_value > max_value:\n        raise ValueError(\"min_value cannot be greater than max_value\")\n    result: dict[str, int] = {}\n    for key, value in data.items():\n        if value >= min_value and (max_value is None or value <= max_value):\n            result[key] = value\n    return result"}
{"question":"Provide the documentation for the function according to task description.","answer":"Sanitize a filename by replacing illegal characters with underscores and ensuring a non\u2011empty result.\n\nArgs:\n    name: Original filename to sanitize\n\nReturns:\n    Sanitized filename with illegal characters replaced and trimmed; returns 'untitled' if the result is empty","context":"import re\ndef sanitize_filename(name: str) -> str:\n    sanitized = re.sub(r'[<>:\"\/\\\\|?*]', '_', name)\n    sanitized = sanitized.strip()\n    return sanitized if sanitized else 'untitled'"}
{"question":"Provide the documentation for the function according to task description.","answer":"Read rows from a CSV file into a list of dictionaries.\n\nUses ``csv.DictReader`` to parse the file and return each row as a dictionary.\n\nArgs:\n    file_path: Path to the CSV file to read.\n    delimiter: Single-character delimiter used to separate fields. Defaults to ','.\n    encoding: Text encoding used to open the file. Defaults to 'utf-8'.\n\nReturns:\n    List of dictionaries where each dictionary maps column names to row values.\n\nRaises:\n    ValueError: If ``delimiter`` is not a single character.\n\nExample:\n    >>> rows = read_csv('data.csv')\n    >>> len(rows)\n    10","context":"import csv\nfrom typing import List, Dict\n\ndef read_csv(file_path: str, delimiter: str = ',', encoding: str = 'utf-8') -> List[Dict[str, str]]:\n    if len(delimiter) != 1:\n        raise ValueError(\"delimiter must be a single character\")\n    with open(file_path, mode='r', newline='', encoding=encoding) as f:\n        reader = csv.DictReader(f, delimiter=delimiter)\n        return [row for row in reader]"}
{"question":"Provide the documentation for the function according to task description.","answer":"Filter even numbers from a list.\n\nArgs:\n    numbers: List of integers to filter\n\nReturns:\n    List[int]: A list of the even numbers from the input list","context":"from typing import List\n\ndef filter_even_numbers(numbers: List[int]) -> List[int]:\n    result = []\n    for n in numbers:\n        if n % 2 == 0:\n            result.append(n)\n    return result"}
{"question":"Provide the documentation for the function according to task description.","answer":"Fetch JSON from a URL with retry and exponential backoff.\n\nAttempts to retrieve JSON data from the specified URL, retrying on client errors or timeouts using an exponential backoff strategy.\n\nArgs:\n    url: The URL to request JSON data from\n    retries: Number of retry attempts after a failure. Defaults to 3\n    backoff_factor: Factor used to compute exponential backoff delays in seconds. Defaults to 0.5\n    timeout: Timeout in seconds for each request attempt. Defaults to 10\n\nReturns:\n    A dictionary containing the parsed JSON response\n\nRaises:\n    ValueError: If retries is negative\n    aiohttp.ClientError: For HTTP client errors such as non\u20112xx status codes\n    asyncio.TimeoutError: If the request times out\n    Exception: Propagates the last caught exception after exceeding retries\n\nExample:\n    >>> import asyncio\n    >>> async def main():\n    >>>     data = await fetch_json_with_retry('https:\/\/api.example.com\/data')\n    >>>     print(data)\n    >>> asyncio.run(main())","context":"import aiohttp\nimport asyncio\nimport async_timeout\n\nasync def fetch_json_with_retry(url: str, *, retries: int = 3, backoff_factor: float = 0.5, timeout: int = 10) -> dict:\n    if retries < 0:\n        raise ValueError(\"retries must be non-negative\")\n    attempt = 0\n    while True:\n        try:\n            async with aiohttp.ClientSession() as session:\n                async with async_timeout.timeout(timeout):\n                    async with session.get(url) as response:\n                        response.raise_for_status()\n                        return await response.json()\n        except (aiohttp.ClientError, asyncio.TimeoutError) as exc:\n            attempt += 1\n            if attempt > retries:\n                raise exc\n            await asyncio.sleep(backoff_factor * (2 ** (attempt - 1)))"}
{"question":"Provide the documentation for the function according to task description.","answer":"Compute the average of a list of numbers.\n\nArgs:\n    values: List of numeric values\n\nReturns:\n    The arithmetic mean of the values\n\nRaises:\n    ValueError: If the input list is empty\n\nExample:\n    >>> compute_average([1.0, 2.0, 3.0])\n    2.0","context":"def compute_average(values: list[float]) -> float:\n    if not values:\n        raise ValueError(\"The list of values must not be empty\")\n    return sum(values) \/ len(values)"}
{"question":"Provide the documentation for the function according to task description.","answer":"Read a CSV file and return its contents as a list of dictionaries.\n\n    Args:\n        filepath: Path to the CSV file.\n        delimiter: Character used to separate fields. Defaults to \",\".\n\n    Returns:\n        List of dictionaries where each dictionary represents a row with column names as keys.\n\n    Raises:\n        FileNotFoundError: If the specified file does not exist.\n        ValueError: If a CSV parsing error occurs.\n\n    Example:\n        >>> rows = read_csv(\"data.csv\")\n        >>> len(rows)\n        10","context":"import csv\nfrom pathlib import Path\nfrom typing import List, Dict\n\ndef read_csv(filepath: str, delimiter: str = \",\") -> List[Dict[str, str]]:\n    path = Path(filepath)\n    if not path.is_file():\n        raise FileNotFoundError(f\"File not found: {filepath}\")\n    with path.open(newline=\"\", encoding=\"utf-8\") as f:\n        try:\n            reader = csv.DictReader(f, delimiter=delimiter)\n            return [row for row in reader]\n        except csv.Error as err:\n            raise ValueError(f\"CSV parsing error: {err}\")"}
{"question":"Provide the documentation for the function according to task description.","answer":"Filter records by a specific key-value pair.\n\n    Args:\n        records: List of dictionaries representing the input records\n        key: The key whose value should be matched\n        value: The value to match against the specified key\n\n    Returns:\n        A list of dictionaries containing only the records where `key` equals `value`\n\n    Raises:\n        ValueError: If any record does not contain the specified `key`\n\n    Example:\n        >>> records = [\n        ...     {\"id\": 1, \"status\": \"active\"},\n        ...     {\"id\": 2, \"status\": \"inactive\"},\n        ...     {\"id\": 3, \"status\": \"active\"},\n        ... ]\n        >>> filter_records(records, \"status\", \"active\")\n        [{'id': 1, 'status': 'active'}, {'id': 3, 'status': 'active'}]","context":"from typing import List, Dict, Any\n\ndef filter_records(records: List[Dict[str, Any]], key: str, value: Any) -> List[Dict[str, Any]]:\n    filtered: List[Dict[str, Any]] = []\n    for rec in records:\n        if key not in rec:\n            raise ValueError(f\"Key '{key}' not found in record {rec}\")\n        if rec[key] == value:\n            filtered.append(rec)\n    return filtered"}
{"question":"Provide the documentation for the function according to task description.","answer":"Calculate the sum of positive integers in an iterable.\n\nArgs:\n    numbers: Iterable of integers to process\n\nReturns:\n    The sum of all positive integers in the iterable\n\nRaises:\n    ValueError: If the iterable does not contain at least one number\n\nExample:\n    >>> sum_positive_numbers([1, -2, 3, 0])\n    4","context":"from typing import Iterable\n\ndef sum_positive_numbers(numbers: Iterable[int]) -> int:\n    total = 0\n    has_item = False\n    for n in numbers:\n        has_item = True\n        if n > 0:\n            total += n\n    if not has_item:\n        raise ValueError(\"The iterable must contain at least one number\")\n    return total"}
{"question":"Provide the documentation for the function according to task description.","answer":"Validate that an email address has a proper format.\n\n    This function checks whether the provided email string matches a simple email regular expression. It raises a ValueError if the input string is empty.\n\n    Args:\n        email: The email address to validate\n\n    Returns:\n        bool: True if the email matches the pattern, False otherwise\n\n    Raises:\n        ValueError: If the email string is empty\n\n    Example:\n        >>> is_valid_email(\"user@example.com\")\n        True","context":"import re\nfrom typing import Pattern\n\ndef is_valid_email(email: str) -> bool:\n    if not email:\n        raise ValueError(\"Email string is empty\")\n    pattern: Pattern = re.compile(r\"^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}$\")\n    return bool(pattern.fullmatch(email))"}
{"question":"Provide the documentation for the function according to task description.","answer":"Retrieve JSON data from a URL with retries and exponential backoff.\n\nArgs:\n    url: The URL to fetch JSON from\n    retries: Maximum number of retry attempts after the initial request (default 3)\n    backoff_factor: Factor used to calculate exponential backoff between retries (default 0.5)\n    timeout: Number of seconds to wait for a response before timing out (default 10)\n    session: Optional\u202frequests.Session to reuse; if None, a new session is created\n\nReturns:\n    A dictionary containing the parsed JSON response\n\nRaises:\n    ConnectionError: If all retry attempts fail to retrieve a successful response\n\nExample:\n    >>> from mymodule import get_json_with_retries\n    >>> data = get_json_with_retries(\"https:\/\/api.example.com\/data\", retries=2)\n    >>> print(data)","context":"import time\nfrom typing import Optional, Dict, Any\nimport requests\n\ndef get_json_with_retries(\n    url: str,\n    retries: int = 3,\n    backoff_factor: float = 0.5,\n    timeout: int = 10,\n    session: Optional[requests.Session] = None\n) -> Dict[str, Any]:\n    sess = session or requests.Session()\n    for attempt in range(retries + 1):\n        try:\n            response = sess.get(url, timeout=timeout)\n            response.raise_for_status()\n            return response.json()\n        except requests.exceptions.RequestException as exc:\n            if attempt == retries:\n                raise ConnectionError(f\"Failed to retrieve JSON from {url} after {retries} retries\") from exc\n            sleep_time = backoff_factor * (2 ** attempt)\n            time.sleep(sleep_time)"}
{"question":"Provide the documentation for the function according to task description.","answer":"Filter and return numbers greater than a threshold.\n\nArgs:\n    numbers: List of integers to filter\n    threshold: Non-negative integer threshold\n\nReturns:\n    List of integers greater than the threshold\n\nRaises:\n    ValueError: If `threshold` is negative\n\nExample:\n    >>> filter_positive_numbers([1, -2, 3, 4], 2)\n    [3, 4]","context":"def filter_positive_numbers(numbers: list[int], threshold: int) -> list[int]:\n    if threshold < 0:\n        raise ValueError(\"threshold must be non\u2011negative\")\n    return [n for n in numbers if n > threshold]"}
{"question":"Provide the documentation for the function according to task description.","answer":"Fetch values for a specified key from a JSON file.\n\nArgs:\n    file_path (str): Path to the JSON file\n    key (str): Key whose values should be extracted\n    default (list, optional): List to return when the key is missing; if None, an empty list is used\n\nReturns:\n    list: List of values for the key or the default list if the key is not present\n\nRaises:\n    FileNotFoundError: If the file does not exist\n    ValueError: If the file contains invalid JSON\n\nExample:\n    >>> fetch_key_values('data.json', 'id')\n    [1, 2, 3]","context":"def fetch_key_values(file_path: str, key: str, default: list = None) -> list:\n    if default is None:\n        default = []\n    import json\n    try:\n        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n            data = json.load(f)\n    except FileNotFoundError as e:\n        raise FileNotFoundError(f\"File not found: {file_path}\") from e\n    except json.JSONDecodeError as e:\n        raise ValueError(f\"Invalid JSON in file: {file_path}\") from e\n    if isinstance(data, list):\n        return [item.get(key) for item in data if isinstance(item, dict) and key in item]\n    if isinstance(data, dict):\n        return [data[key]] if key in data else default\n    return default"}
{"question":"Provide the documentation for the function according to task description.","answer":"Filter records by a specific key and value.\n\nReturn a new list containing only the records where the given key exists and its value matches the supplied value. For string values, the comparison can be case\u2011insensitive when `case_sensitive` is False.\n\nArgs:\n    records: List of dictionaries representing the records to filter\n    key: The dictionary key to match in each record\n    value: The value to compare against the record's value for the given key\n    case_sensitive: If False, perform a case\u2011insensitive comparison for string values. Defaults to True\n\nReturns:\n    List of dictionaries that satisfy the filter criteria\n\nExample:\n    >>> records = [\n    ...     {\"name\": \"Alice\", \"age\": 30},\n    ...     {\"name\": \"bob\", \"age\": 25},\n    ...     {\"name\": \"Alice\", \"age\": 22}\n    ... ]\n    >>> filter_records(records, \"name\", \"alice\", case_sensitive=False)\n    [{'name': 'Alice', 'age': 30}, {'name': 'Alice', 'age': 22}]","context":"from typing import Any, List, Dict\n\ndef filter_records(records: List[Dict[str, Any]], key: str, value: Any, *, case_sensitive: bool = True) -> List[Dict[str, Any]]:\n    filtered: List[Dict[str, Any]] = []\n    for record in records:\n        if key not in record:\n            continue\n        record_value = record[key]\n        if isinstance(record_value, str) and isinstance(value, str) and not case_sensitive:\n            if record_value.lower() == value.lower():\n                filtered.append(record)\n        else:\n            if record_value == value:\n                filtered.append(record)\n    return filtered"}
{"question":"Provide the documentation for the function according to task description.","answer":"Read a CSV file and return a list of dictionaries.\n\nArgs:\n    path: Path to the CSV file to read\n    delimiter: Delimiter character used in the CSV file (default \",\")\n\nReturns:\n    A list of dictionaries mapping column names to their string values for each row\n\nRaises:\n    FileNotFoundError: If the file at the given path does not exist\n    OSError: If the file cannot be opened\n    csv.Error: If a parsing error occurs while reading the CSV\n\nExample:\n    >>> rows = read_csv_to_dicts(\"data.csv\")\n    >>> rows[0][\"name\"]\n    'Alice'","context":"import csv\nfrom typing import List, Dict\n\ndef read_csv_to_dicts(path: str, delimiter: str = \",\") -> List[Dict[str, str]]:\n    rows: List[Dict[str, str]] = []\n    with open(path, newline=\"\", encoding=\"utf-8\") as f:\n        reader = csv.DictReader(f, delimiter=delimiter)\n        for row in reader:\n            rows.append(row)\n    return rows"}
{"question":"Provide the documentation for the function according to task description.","answer":"Fetch JSON data from a URL with retry and exponential backoff.\n\nArgs:\n    url: The URL to fetch JSON from\n    timeout: Maximum time in seconds to wait for each request\n    max_retries: Maximum number of retry attempts after a failure\n    backoff_factor: Factor used to calculate the sleep time between retries\n\nReturns:\n    A dictionary containing the parsed JSON response\n\nRaises:\n    ValueError: If `url` is empty or None\n    aiohttp.ClientResponseError: If the response status indicates an error and the maximum retries have been exhausted\n    aiohttp.ClientConnectorError: If a connection error occurs and the maximum retries have been exhausted\n    asyncio.TimeoutError: If the request times out and the maximum retries have been exhausted\n    RuntimeError: If an unexpected code path is reached (should not happen)\n\nExample:\n    >>> import asyncio\n    >>> async def main():\n    ...     result = await fetch_json_with_retries(\"https:\/\/api.example.com\/data\")\n    ...     print(result)\n    >>> asyncio.run(main())","context":"import asyncio\nfrom typing import Any, Dict\nimport aiohttp\n\nasync def fetch_json_with_retries(url: str, timeout: float = 5.0, max_retries: int = 3, backoff_factor: float = 0.5) -> Dict[str, Any]:\n    if not url:\n        raise ValueError(\"url must be provided\")\n    attempt = 0\n    while attempt <= max_retries:\n        try:\n            async with aiohttp.ClientSession() as session:\n                async with session.get(url, timeout=timeout) as response:\n                    response.raise_for_status()\n                    return await response.json()\n        except (aiohttp.ClientResponseError, aiohttp.ClientConnectorError) as e:\n            if attempt == max_retries:\n                raise e\n        except asyncio.TimeoutError:\n            if attempt == max_retries:\n                raise\n        await asyncio.sleep(backoff_factor * (2 ** attempt))\n        attempt += 1\n    raise RuntimeError(\"Unreachable code path\")"}
{"question":"Provide the documentation for the function according to task description.","answer":"Fetch JSON from a URL with retry logic and exponential backoff.\n\n    Args:\n        url: The URL to request JSON from\n        retries: Maximum number of retry attempts (default 3)\n        backoff: Initial backoff interval in seconds (default 0.5)\n        timeout: HTTP request timeout in seconds (default 5.0)\n\n    Returns:\n        A dictionary parsed from the JSON response\n\n    Raises:\n        RuntimeError: If the request fails after the specified number of retries\n\n    Example:\n        >>> data = fetch_json_with_retries('https:\/\/api.example.com\/data', retries=2)\n        >>> isinstance(data, dict)\n        True","context":"import time\nfrom typing import Any, Dict\nimport requests\n\ndef fetch_json_with_retries(url: str, retries: int = 3, backoff: float = 0.5, timeout: float = 5.0) -> Dict[Any, Any]:\n    attempt = 0\n    while attempt <= retries:\n        try:\n            response = requests.get(url, timeout=timeout)\n            response.raise_for_status()\n            return response.json()\n        except (requests.exceptions.RequestException, ValueError) as e:\n            if attempt == retries:\n                raise RuntimeError(f\"Failed to fetch JSON from {url} after {retries} retries\") from e\n            time.sleep(backoff * (2 ** attempt))\n            attempt += 1"}
{"question":"Provide the documentation for the function according to task description.","answer":"Read a CSV file into a list of dictionaries.\n\nArgs:\n    file_path: The path to the CSV file\n    delimiter: The delimiter used to separate fields. Defaults to ','\n\nReturns:\n    A list of dictionaries mapping column names to their string values\n\nRaises:\n    FileNotFoundError: If the file does not exist\n    OSError: If the file cannot be opened\n    csv.Error: If a parsing error occurs\n\nExample:\n    >>> rows = read_csv_to_dicts('example.csv')\n    >>> rows[0]\n    {'column1': 'value1', 'column2': 'value2'}","context":"import csv\nfrom typing import List, Dict\n\ndef read_csv_to_dicts(file_path: str, delimiter: str = ',') -> List[Dict[str, str]]:\n    rows: List[Dict[str, str]] = []\n    with open(file_path, newline='', encoding='utf-8') as f:\n        reader = csv.DictReader(f, delimiter=delimiter)\n        for row in reader:\n            rows.append(dict(row))\n    return rows"}
{"question":"Provide the documentation for the function according to task description.","answer":"Calculate the sum of positive numbers in the given list.\n\nArgs:\n    values: A list of numeric values\n\nReturns:\n    The sum of the positive numbers as a float","context":"def sum_positive_numbers(values: list[float]) -> float:\n    total = 0.0\n    for v in values:\n        if v > 0:\n            total += v\n    return total"}
{"question":"Provide the documentation for the function according to task description.","answer":"Validate an email address.\n\nArgs:\n    email: Email address to validate\n\nReturns:\n    True if the email matches the expected pattern, False otherwise\n\nRaises:\n    ValueError: If email is None\n\nExample:\n    >>> is_valid_email(\"user@example.com\")\n    True","context":"import re\ndef is_valid_email(email: str) -> bool:\n    if email is None:\n        raise ValueError(\"email must not be None\")\n    pattern = re.compile(r\"^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}$\")\n    return bool(pattern.fullmatch(email))"}
{"question":"Provide the documentation for the function according to task description.","answer":"Fetch a JSON document from the given URL with retry and exponential backoff.\n\nAttempts to GET the URL up to ``max_retries + 1`` times, applying exponential backoff between attempts. If no ``session`` is provided, a new ``aiohttp.ClientSession`` is created and closed automatically.\n\nArgs:\n    url: The URL to fetch.\n    max_retries: Maximum number of retry attempts after the initial request. Defaults to 3.\n    timeout: Number of seconds to wait for a response before timing out. Defaults to 5.0.\n    backoff_factor: Factor used to calculate exponential backoff delay (delay = backoff_factor * (2 ** attempt)). Defaults to 0.5.\n    headers: Optional mapping of HTTP headers to include in the request.\n    session: Optional ``aiohttp.ClientSession`` to use for the request. If omitted, a new session is created and closed automatically.\n\nReturns:\n    Mapping[str, Any]: The parsed JSON response.\n\nRaises:\n    aiohttp.ClientError: If the request fails after all retries.\n    asyncio.TimeoutError: If a request times out after all retries.\n\nExample:\n    >>> import asyncio\n    >>> async def main():\n    ...     data = await fetch_json_with_retries('https:\/\/api.example.com\/data')\n    ...     print(data)\n    >>> asyncio.run(main())","context":"import aiohttp\nimport asyncio\nfrom typing import Any, Mapping, Optional\n\nasync def fetch_json_with_retries(\n    url: str,\n    max_retries: int = 3,\n    timeout: float = 5.0,\n    backoff_factor: float = 0.5,\n    headers: Optional[Mapping[str, str]] = None,\n    session: Optional[aiohttp.ClientSession] = None,\n) -> Mapping[str, Any]:\n    own_session = session is None\n    if own_session:\n        session = aiohttp.ClientSession()\n    try:\n        for attempt in range(max_retries + 1):\n            try:\n                async with session.get(url, timeout=timeout, headers=headers) as resp:\n                    resp.raise_for_status()\n                    return await resp.json()\n            except (aiohttp.ClientError, asyncio.TimeoutError) as exc:\n                if attempt == max_retries:\n                    raise exc\n                await asyncio.sleep(backoff_factor * (2 ** attempt))\n    finally:\n        if own_session:\n            await session.close()"}
{"question":"Provide the documentation for the function according to task description.","answer":"Filter a dictionary by a list of keys, returning a new dictionary with those keys and their corresponding values or a default.\n\nArgs:\n    keys: List of keys to include in the result\n    data: Dictionary to filter\n    default: Value to use for keys that are not present in `data`. Defaults to None\n\nReturns:\n    Dictionary containing the specified keys mapped to their values from `data` or the default value\n\nExample:\n    >>> data = {'a': 1, 'b': 2, 'c': 3}\n    >>> filter_dict_by_keys(['a', 'c', 'd'], data, default=0)\n    {'a': 1, 'c': 3, 'd': 0}","context":"from typing import Any, Dict, List\n\ndef filter_dict_by_keys(keys: List[str], data: Dict[str, Any], default: Any = None) -> Dict[str, Any]:\n    if not keys:\n        return {}\n    return {key: data.get(key, default) for key in keys}"}
{"question":"Provide the documentation for the function according to task description.","answer":"Read a CSV file and return its rows as a list of dictionaries.\n\n    Args:\n        file_path: Path to the CSV file to read\n        encoding: Text encoding used to decode the file. Defaults to \"utf-8\"\n        delimiter: Character that separates fields in the CSV. Defaults to \",\"\n        skip_header: If True, skip the first line of the file before parsing. Defaults to True\n\n    Returns:\n        A list of dictionaries where each dictionary represents a row mapping column names to string values\n\n    Raises:\n        FileNotFoundError: If the file does not exist at the given path\n        csv.Error: If an error occurs while parsing the CSV file\n\n    Example:\n        >>> rows = read_csv_to_dicts('data.csv', delimiter=';')\n        >>> rows[0]['name']\n        'Alice'","context":"import csv\nfrom typing import List, Dict\ndef read_csv_to_dicts(file_path: str, encoding: str = \"utf-8\", *, delimiter: str = \",\", skip_header: bool = True) -> List[Dict[str, str]]:\n    try:\n        with open(file_path, newline='', encoding=encoding) as f:\n            if skip_header:\n                next(f, None)\n            dict_reader = csv.DictReader(f, delimiter=delimiter)\n            rows: List[Dict[str, str]] = [dict(row) for row in dict_reader]\n            return rows\n    except FileNotFoundError as e:\n        raise FileNotFoundError(f\"File not found: {file_path}\") from e\n    except csv.Error as e:\n        raise csv.Error(f\"Error parsing CSV: {e}\") from e"}
{"question":"Provide the documentation for the function according to task description.","answer":"Filter a dictionary by a whitelist of keys.\n\nArgs:\n    data: The source dictionary containing key-value pairs\n    allowed_keys: List of keys to retain in the returned dictionary\n\nReturns:\n    A new dictionary containing only the entries from data whose keys are present in allowed_keys\n\nRaises:\n    ValueError: If allowed_keys is empty\n\nExample:\n    >>> data = {'a': 1, 'b': 2, 'c': 3}\n    >>> filter_dict_by_keys(data, ['a', 'c'])\n    {'a': 1, 'c': 3}","context":"from typing import Any\n\ndef filter_dict_by_keys(data: dict[str, Any], allowed_keys: list[str]) -> dict[str, Any]:\n    if not allowed_keys:\n        raise ValueError(\"allowed_keys must not be empty\")\n    return {k: data[k] for k in allowed_keys if k in data}"}
{"question":"Provide the documentation for the function according to task description.","answer":"Read a CSV file into a list of row dictionaries.\n\nEach row is represented as a dict mapping column headers to string values.\n\nArgs:\n    file_path: Path to the CSV file\n    delimiter: Field delimiter character. Defaults to ','\n    encoding: Encoding used to read the file. Defaults to 'utf-8'\n\nReturns:\n    List of dictionaries where each dict corresponds to a CSV row\n\nRaises:\n    FileNotFoundError: If the CSV file does not exist\n    UnicodeError: If the file cannot be decoded with the given encoding\n\nExample:\n    >>> rows = read_csv_to_dicts('data.csv')\n    >>> rows[0]['id']","context":"import csv\nfrom typing import List, Dict\n\ndef read_csv_to_dicts(file_path: str, delimiter: str = ',', *, encoding: str = 'utf-8') -> List[Dict[str, str]]:\n    try:\n        with open(file_path, newline='', encoding=encoding) as f:\n            reader = csv.DictReader(f, delimiter=delimiter)\n            return [row for row in reader]\n    except FileNotFoundError as e:\n        raise FileNotFoundError(f\"CSV file not found: {file_path}\") from e\n    except UnicodeDecodeError as e:\n        raise UnicodeError(f\"Unable to decode file {file_path} with encoding {encoding}\") from e"}
{"question":"Provide the documentation for the function according to task description.","answer":"Filter a dictionary to include only entries with integer values greater than or equal to a minimum.\n\nArgs:\n    data: Dictionary of string keys to integer values\n    min_value: Minimum value required for a key to be kept\n\nReturns:\n    A dictionary containing only the items whose values are integers and at least min_value\n\nRaises:\n    TypeError: If data is not a dictionary\n\nExample:\n    >>> data = {'a': 5, 'b': 2, 'c': 'x', 'd': 10}\n    >>> filter_dict_by_value(data, 5)\n    {'a': 5, 'd': 10}","context":"def filter_dict_by_value(data: dict[str, int], min_value: int) -> dict[str, int]:\n    if not isinstance(data, dict):\n        raise TypeError(\"data must be a dictionary\")\n    return {k: v for k, v in data.items() if isinstance(v, int) and v >= min_value}"}
{"question":"Provide the documentation for the function according to task description.","answer":"Wrap a callable to measure and print its execution time.\n\nThis decorator uses ``time.perf_counter`` to time the wrapped function, prints the elapsed\ntime in seconds, and returns the original result unchanged.\n\nArgs:\n    func: The callable to be wrapped and timed.\n\nReturns:\n    A wrapper function that forwards all positional and keyword arguments to ``func``,\n    prints the execution duration, and returns the result of ``func``.\n\nRaises:\n    TypeError: If ``func`` is not callable.\n\nExample:\n    >>> @timed\n    ... def add(a, b):\n    ...     return a + b\n    ...\n    >>> add(2, 3)\n    add executed in 0.000001s\n    5","context":"import time\nfrom typing import Callable, Any, TypeVar, cast\n\n_R = TypeVar('_R')\n\ndef timed(func: Callable[..., _R]) -> Callable[..., _R]:\n    if not callable(func):\n        raise TypeError(\"func must be callable\")\n    def wrapper(*args: Any, **kwargs: Any) -> _R:\n        start = time.perf_counter()\n        result = func(*args, **kwargs)  # type: ignore\n        end = time.perf_counter()\n        elapsed = end - start\n        print(f\"{func.__name__} executed in {elapsed:.6f}s\")\n        return cast(_R, result)\n    return wrapper"}
{"question":"Provide the documentation for the function according to task description.","answer":"Fetch JSON data from a URL with retries and exponential backoff.\n\nAttempts to retrieve JSON content from the provided URL, retrying on network errors or JSON decoding failures using an exponential backoff strategy.\n\nArgs:\n    url: The URL to request JSON data from\n    timeout: Number of seconds to wait for a response before timing out\n    max_retries: Maximum number of retry attempts after a failed request\n    backoff_factor: Factor used to calculate sleep time between retries (sleep = backoff_factor * 2**attempt)\n\nReturns:\n    A dictionary representing the parsed JSON response\n\nRaises:\n    requests.RequestException: If a network-related error occurs and all retries are exhausted\n    json.JSONDecodeError: If the response cannot be decoded as JSON and all retries are exhausted\n\nExample:\n    >>> data = fetch_json_with_retries('https:\/\/api.example.com\/data')\n    >>> isinstance(data, dict)","context":"import json\nimport time\nimport requests\nfrom typing import Any\ndef fetch_json_with_retries(url: str, timeout: int = 10, max_retries: int = 3, backoff_factor: float = 0.5) -> dict[str, Any]:\n    for attempt in range(max_retries + 1):\n        try:\n            response = requests.get(url, timeout=timeout)\n            response.raise_for_status()\n            return response.json()\n        except (requests.RequestException, json.JSONDecodeError) as exc:\n            if attempt == max_retries:\n                raise\n            time.sleep(backoff_factor * (2 ** attempt))"}
{"question":"Provide the documentation for the function according to task description.","answer":"Read a CSV file and return a list of dictionaries, optionally converting column values.\n\nArgs:\n    file_path: Path to the CSV file\n    delimiter: Field delimiter to use (default ',')\n    converters: Optional mapping of column names to callables that convert string values\n    skip_header: If True, treat the first row as data and generate generic column names\n\nReturns:\n    List of dictionaries representing the CSV rows, with values converted when a converter is provided\n\nRaises:\n    ValueError: If a row's length does not match the header length\n    Any exception raised by a converter function may propagate\n\nExample:\n    >>> converters = {'age': int, 'salary': float}\n    >>> rows = read_csv_with_converters('people.csv', converters=converters)\n    >>> rows[0]\n    {'name': 'Alice', 'age': 30, 'salary': 70000.0}","context":"import csv\nfrom typing import Any, Callable, Dict, List, Optional\ndef read_csv_with_converters(file_path: str, delimiter: str = ',', converters: Optional[Dict[str, Callable[[str], Any]]] = None, skip_header: bool = False) -> List[Dict[str, Any]]:\n    rows: List[Dict[str, Any]] = []\n    with open(file_path, newline='', encoding='utf-8') as f:\n        reader = csv.reader(f, delimiter=delimiter)\n        try:\n            headers = next(reader) if not skip_header else [f'col{i}' for i in range(len(next(reader)))]\n        except StopIteration:\n            return rows\n        for row in reader:\n            if len(row) != len(headers):\n                raise ValueError(f\"Row length {len(row)} does not match header length {len(headers)}\")\n            processed: Dict[str, Any] = {}\n            for header, value in zip(headers, row):\n                if converters and header in converters:\n                    processed[header] = converters[header](value)\n                else:\n                    processed[header] = value\n            rows.append(processed)\n    return rows"}